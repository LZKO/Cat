## Redis

[参考](<https://github.com/CyC2018/CS-Notes/blob/master/notes/Redis.md>)

------

<!-- GFM-TOC -->

- [一、概述](#一概述)
- [二、数据类型](#二数据类型)
  - [STRING](#string)
  - [LIST](#list)
  - [SET](#set)
  - [HASH](#hash)
  - [ZSET](#zset)
- [三、数据结构](#三数据结构)
  - [简单动态字符串](#简单动态字符串)
  - [链表](#链表)
  - [字典](#字典)
  - [跳跃表](#跳跃表)
  - [整数集合](#整数集合)
  - [压缩列表](#压缩列表)
  - [对象](#对象)
- [四、使用场景](#四使用场景)
  - [计数器](#计数器)
  - [缓存](#缓存)
  - [查找表](#查找表)
  - [消息队列](#消息队列)
  - [会话缓存](#会话缓存)
  - [分布式锁实现](#分布式锁实现)
  - [其它](#其它)
- [五、Redis 与 Memcached](#五redis-与-memcached)
  - [数据类型](#数据类型)
  - [数据持久化](#数据持久化)
  - [分布式](#分布式)
  - [内存管理机制](#内存管理机制)
- [六、键的过期时间](#六键的过期时间)
- [七、数据淘汰策略](#七数据淘汰策略)
- [八、持久化](#八持久化)
  - [RDB 持久化](#rdb-持久化)
  - [AOF 持久化](#aof-持久化)
- [九、事务](#九事务)
- [十、事件](#十事件)
  - [文件事件](#文件事件)
  - [时间事件](#时间事件)
  - [事件的调度与执行](#事件的调度与执行)
- [十一、复制](#十一复制)
  - [连接过程](#连接过程)
  - [主从链](#主从链)
- [十二、Sentinel](#十二sentinel)
- [十三、分片](#十三分片)
- [十四、一个简单的论坛系统分析](#十四一个简单的论坛系统分析)
  - [文章信息](#文章信息)
  - [点赞功能](#点赞功能)
  - [对文章进行排序](#对文章进行排序)
- [十五、客户端](#十五客户端)
- [十六、服务端](#十六服务端)
- [[十七、面试题](#十七面试题)
- [参考资料](#参考资料)
  <!-- GFM-TOC -->



### 一、概述

Redis 是速度非常快的非关系型（NoSQL）内存键值数据库，可以存储键和五种不同类型的值之间的映射。

键的类型只能为字符串，值支持五种数据类型：字符串、列表、集合、散列表、有序集合。

Redis 支持很多特性，例如将内存中的数据持久化到硬盘中，使用复制来扩展读性能，使用分片来扩展写性能。

### 二、数据类型

#### 

| 数据类型 | 可以存储的值           | 操作                                                         |
| -------- | ---------------------- | ------------------------------------------------------------ |
| STRING   | 字符串、整数或者浮点数 | 对整个字符串或者字符串的其中一部分执行操作 对整数和浮点数执行自增或者自减操作 |
| LIST     | 列表                   | 从两端压入或者弹出元素 对单个或者多个元素进行修剪， 只保留一个范围内的元素 |
| SET      | 无序集合               | 添加、获取、移除单个元素 检查一个元素是否存在于集合中 计算交集、并集、差集 从集合里面随机获取元素 |
| HASH     | 包含键值对的无序散列表 | 添加、获取、移除单个键值对 获取所有键值对 检查某个键是否存在 |
| ZSET     | 有序集合               | 添加、获取、删除元素 根据分值范围或者成员来获取元素 计算一个键的排名 |

> [What Redis data structures look like](https://redislabs.com/ebook/part-1-getting-started/chapter-1-getting-to-know-redis/1-2-what-redis-data-structures-look-like/)

#### STRING

```
> set hello world
OK
> get hello
"world"
> del hello
(integer) 1
> get hello
(nil)
```

#### LIST

```
> rpush list-key item
(integer) 1
> rpush list-key item2
(integer) 2
> rpush list-key item
(integer) 3

> lrange list-key 0 -1
1) "item"
2) "item2"
3) "item"

> lindex list-key 1
"item2"

> lpop list-key
"item"

> lrange list-key 0 -1
1) "item2"
2) "item"
```

#### SET

```
> sadd set-key item
(integer) 1
> sadd set-key item2
(integer) 1
> sadd set-key item3
(integer) 1
> sadd set-key item
(integer) 0

> smembers set-key
1) "item"
2) "item2"
3) "item3"

> sismember set-key item4
(integer) 0
> sismember set-key item
(integer) 1

> srem set-key item2
(integer) 1
> srem set-key item2
(integer) 0

> smembers set-key
1) "item"
2) "item3"
```

#### HASH

```
> hset hash-key sub-key1 value1
(integer) 1
> hset hash-key sub-key2 value2
(integer) 1
> hset hash-key sub-key1 value1
(integer) 0

> hgetall hash-key
1) "sub-key1"
2) "value1"
3) "sub-key2"
4) "value2"

> hdel hash-key sub-key2
(integer) 1
> hdel hash-key sub-key2
(integer) 0

> hget hash-key sub-key1
"value1"

> hgetall hash-key
1) "sub-key1"
2) "value1"
```

#### ZSET

```
> zadd zset-key 728 member1
(integer) 1
> zadd zset-key 982 member0
(integer) 1
> zadd zset-key 982 member0
(integer) 0

> zrange zset-key 0 -1 withscores
1) "member1"
2) "728"
3) "member0"
4) "982"

> zrangebyscore zset-key 0 800 withscores
1) "member1"
2) "728"

> zrem zset-key member1
(integer) 1
> zrem zset-key member1
(integer) 0

> zrange zset-key 0 -1 withscores
1) "member0"
2) "982"
```

### 三、数据结构

#### 简单动态字符串

Redis里，C字符串只会作为字符串字面量用在一些无需对字符串值进行修改的地方，比如打印日志。Redis构建了 简单动态字符串（simple dynamic string，SDS）来表示字符串值。

在Redis里，包含字符串值的键值对在底层都是由SDS实现的。除此之外，SDS还被用作缓冲区：AOF缓冲区，客户端状态中的输入缓冲区。

##### 1.SDS的定义

每个sds.h/sdshdr结构表示一个SDS值：

```
struct sdshdr {
  // 记录buf数组中已使用字节的数量
  // 等于SDS所保存字符串的长度
  int len;
  
  // 记录buf数组中未使用字节的数量
  int free;
  
  // 字节数组，用于保存字符串
  char buf[];
}
```

SDS遵循C字符串以空字符结尾的管理，空字符不计算在len属性中。这样，SDS可以重用一部分C字符串函数库，如printf。

##### 2.SDS与C字符串的区别

- 常熟复杂度获取字符串长度

  C字符串必须遍历整个字符串才能获得长度，复杂度是O(N)。

  SDS在len属性中记录了SDS的长度，复杂度为O(1)。

- 杜绝缓冲区溢出

  C字符串不记录长度的带来的另一个问题是缓冲区溢出。假设s1和s2是紧邻的两个字符串，对s1的strcat操作，有可能污染s2的内存空间。

  SDS的空间分配策略杜绝了缓冲区溢出的可能性：但SDS API修改SDS时，会先检查SDS的空间是否满足修改所需的要求，不满足的话，API会将SDS的空间扩展至执行修改所需的大小，然后再执行实际的修改操作。

- 减少修改字符串时带来的内存重分配次数

  每次增长或缩短一个C字符串，程序都要对保存这个C字符串的数组进行一次内存重分配操作。

  Redis作为数据库，数据会被频繁修改，如果每次修改字符串都会执行一次内存重分配的话，会对性能造成影响。SDS通过未使用空间解除了字符串长度和底层数组长度之间的关联：在SDS中，buf数组的长度不一定就是字符数量加一，数组里面可以包含未使用的字节，由free属性记录。

  对于未使用空间，SDS使用了空间预分配和惰性空间释放两种优化策略：

  1. 空间预分配：当SDS的API对SDS修改并需要空间扩展时，程序不仅为SDS分配修改所需的空间，还会分配额外的未使用空间（分配的大小取决于长度是否小于1MB）。
  2. 惰性空间释放：当SDS的API需要缩短时，程序不立即触发内存重分配，而是使用free属性将这些字节的数量记录下来，并等待将来使用。与此同时，SDS API也可以让我们真正释放未使用空间，防止内存浪费。

- 二进制安全

  C字符串中的字符必须复合某种编码（如ASCII），且除了字符串末尾之外，字符串里不能包含空字符。这些限制使得C字符串只能保存文本，而不能保存像图片、音频、视频、压缩文件这样的二进制数据。

  SDS API会以处理二进制的方式处理SDS存放在buf数组中的数据，写入时什么样，读取时就是什么样。

  这也是我们将SDS 的buf 属性称为字节数组的原因——Redis 不是用这个数组来保存字符，而是用它来保存一系列二进制数据。

- 兼容部分C 字符串函数

  遵循C字符串以空字符结尾的管理，SDS可以重用<string.h>函数库。

总结：

| C字符串                          | SDS                                |
| -------------------------------- | ---------------------------------- |
| 获取字符串长度的复杂度O(N)       | O(1)                               |
| API不安全，可能会造成缓冲区溢出  | API安全，不会造成缓冲区溢出        |
| 修改字符串长度必然导致内存重分配 | 修改字符串长度不一定导致内存重分配 |
| 只能保存文本数据                 | 可以保存文本或二进制数据           |
| 可使用所有<string.h>库的函数     | 可使用部分<string.h>库的函数       |

##### 3.SDS API

略

#### 链表

Redis构建了自己的链表实现。列表键的底层实现之一就是链表。发布、订阅、慢查询、监视器都用到了链表。Redis服务器还用链表保存多个客户端的状态信息，以及构建客户端输出缓冲区。

##### 1.链表和链表节点的实现

链表节点用adlist.h/listNode结构来表示

```
typedef struct listNode {
  struct listNode *prev;
  struct listNode *next; 
  void *value;
} listNode;
```

adlist.h/list来持有链表:

```
typedef struct list {
  listNode *head;
  listNode *tail;
  unsigned long len;
  void *(dup)(void *ptr); // 节点复制函数
  void (*free)(void *ptr); // 节点释放函数
  int (*match)(void *ptr, void *key); // 节点值对比函数
} list;
```

Redis的链表实现可总结如下：

1. 双向
2. 无环。表头结点的prev和表尾节点的next都指向NULL
3. 带表头指针和表尾指针
4. 带链表长度计数器
5. 多态。使用void*指针来保存节点值，并通过list结构的dup、free。match三个属性为节点值设置类型特定函数

##### 2.链表和链表节点的API

略



#### 字典

Redis的数据库就是使用字典来作为底层实现的，对数据库的增删改查都是构建在字典的操作之上。

字典还是哈希键的底层实现之一，但一个哈希键包含的键值对比较多，又或者键值对中的元素都是较长的字符串时，Redis就会用字典作为哈希键的底层实现。

##### 1.字典的实现

Redis的字典使用**哈希表**作为底层实现，每个哈希表节点就保存了字典中的一个键值对。

Redis字典所用的**哈希表**由dict.h/dictht结构定义：

```
typedef struct dictht {
  // 哈希表数组
  dict Entry **table;
  // 哈希表大小
  unsigned long size;
  // 哈希表大小掩码，用于计算索引值，总是等于size - 1
  unsigned long sizemask;
  // 该哈希表已有节点的数量
  unsigned long used;
} dictht;
```

**哈希表节点**使用dictEntry结构表示，每个dictEntry结构都保存着一个键值对：

```
typedef struct dictEntry {
  void *key; // 键
  
  // 值
  union {
    void *val;
    uint64_t u64;
    int64_t s64;
  } v;
  
  // 指向下个哈希表节点，形成链表。一次解决键冲突的问题
  struct dictEntry *next;
}
```

Redis中的**字典**由dict.h/dict结构表示：

```
typedef struct dict {
  dictType *type; // 类型特定函数
  void *privdata; // 私有数据
  
  /*
  哈希表
  一般情况下，字典只是用ht[0]哈希表，ht[1]只会在对ht[0]哈希表进行rehash时是用
  */
  dictht ht[2]; 
  
  // rehash索引，但rehash不在进行时，值为-1
  // 记录了rehash的进度
  int trehashidx; 
} dict;
```

type和privdata是针对不同类型大家键值对，为创建多态字典而设置的：

- type是一个指向dictType结构的指针，每个dictType都保存了一簇用于操作特定类型键值对的函数，Redis会为用途不同的字典设置不同的类型特定函数。
- privdata保存了需要传给那些类型特定函数的可选参数。

```
typedef struct dictType {
  // 计算哈希值的函数
  unsigned int (*hashFunction) (const void *key);
  
  // 复制键的函数
  void *(*keyDup) (void *privdata, const void *obj);
  
  // 对比键的函数
  void *(*keyCompare) (void *privdata, const void *key1, const void *key2);
  
  // 销毁键的函数
  void (*keyDestructor) (void *privdata, void *key);
  
  // 销毁值的函数
  void (*valDestructor) (void *privdata, void *obj);
} dictType;
```

##### 2.哈希算法

Redis计算哈希值和索引值的方法如下：

```
# 使用字典设置的哈希函数，计算key的哈希值
hash = dict.type.hashFucntion(key)
# 使用哈希表的sizemask属性和哈希值，计算出索引值
# 根据情况的不同，ht[x]可以使ht[0]或ht[1]
index = hash & dict.ht[x].sizemask
```

当字典被用作数据库或哈希键的底层实现时，使用MurmurHash2算法来计算哈希值，即使输入的键是有规律的，算法人能有一个很好的随机分布性，计算速度也很快。

##### 3.解决键冲突

Redis使用链地址法解决键冲突，每个哈希表节点都有个next指针。

##### 4.rehash

随着操作的不断执行，哈希表保存的键值对会增加或减少。为了让哈希表的负载因子维持在合理范围，需要对哈希表的大小进行扩展或收缩，即通过执行rehash（重新散列）来完成：

1. 为字典的ht[1]哈希表分配空间：

   如果执行的是扩展操作，ht[1]的大小为第一个大于等于ht[0].used * 2 的2^n

   如果执行的是收缩操作，ht[1]的大小为第一个大于等于ht[0].used的2^n

2. 将保存在ht[0]中的所有键值对rehash到ht[1]上。rehash是重新设计的计算键的哈希值和索引值

3. 释放ht[0]，将ht[1]设置为ht[0]，并为ht[1]新建一个空白哈希表

**哈希表的扩展与收缩**

满足一下任一条件，程序会自动对哈希表执行扩展操作：

1. 服务器目前没有执行BGSAVE或BGREWRITEAOF，且哈希表负载因子大于等于1
2. 服务器正在执行BGSAVE或BGREWRITEAOF，且负载因子大于5

其中负载因子的计算公式：

```
# 负载因子 = 哈希表已保存节点数量 / 哈希表大小
load_factor = ht[0].used / ht[0].size
```

注：执行BGSAVE或BGREWRITEAOF过程中，Redis需要创建当前服务器进程的子进程，而多数操作系统都是用写时复制来优化子进程的效率，所以在子进程存在期间，服务器会提高执行扩展操作所需的负载因子，从而尽可能地避免在子进程存在期间扩展哈希表，避免不避免的内存写入，节约内存。

##### 5.渐进式rehash

将ht[0]中的键值对rehash到ht[1]中的操作不是一次性完成的，而是分多次渐进式的：

1. 为ht[1]分配空间
2. 在字典中维持一个索引计数器变量rehashidx，设置为0，表示rehash工作正式开始
3. rehash期间，**每次对字典的增删改查操作**，会顺带将ht[0]在rehashidx索引上的所有键值对rehash到ht[1]，rehash完成之后，rehashidx属性的值+1
4. 最终ht[0]会全部rehash到ht[1]，这是将rehashidx设置为-1，表示rehash完成

渐进式rehash过程中，字典会有两个哈希表，字典的增删改查会在两个哈希表上进行。

##### 6.字典API

略



如下为旧版本

dictht 是一个散列表结构，使用拉链法解决哈希冲突。

Redis 的字典 dict 中包含两个哈希表 dictht，这是为了方便进行 rehash 操作。在扩容时，将其中一个 dictht 上的键值对 rehash 到另一个 dictht 上面，完成之后释放空间并交换两个 dictht 的角色。

rehash 操作不是一次性完成，而是采用渐进方式，这是为了避免一次性执行过多的 rehash 操作给服务器带来过大的负担。

渐进式 rehash 通过记录 dict 的 rehashidx 完成，它从 0 开始，然后每执行一次 rehash 都会递增。例如在一次 rehash 中，要把 dict[0] rehash 到 dict[1]，这一次会把 dict[0] 上 table[rehashidx] 的键值对 rehash 到 dict[1] 上，dict[0] 的 table[rehashidx] 指向 null，并令 rehashidx++。

在 rehash 期间，每次对字典执行添加、删除、查找或者更新操作时，都会执行一次渐进式 rehash。

采用渐进式 rehash 会导致字典中的数据分散在两个 dictht 上，因此对字典的查找操作也需要到对应的 dictht 去执行。

#### 跳跃表

跳跃表是一种**有序数据结构**，它通过在每个节点中维持多个指向其他节点的指针，从而达到快速访问的目的。跳跃表支持平均*O(logN)*、最坏*O(N)*的查找，还可以通过顺序性操作来批量处理节点。

Redis使用跳跃表作为有序集合键的底层实现之一，如果有序集合包含的元素数量较多，或者有序集合中元素的成员是比较长的字符串时，Redis使用跳跃表来实现有序集合键。

在集群节点中，跳跃表也被Redis用作内部数据结构。

##### 1.跳跃表的实现

Redis的跳跃表由redis.h/zskiplistNode和redis.h/zskiplist两个结构定义，其中zskiplistNode代表跳跃表节点，zskiplist保存跳跃表节点的相关信息，比如节点数量、以及指向表头/表尾结点的指针等。

```
typedef struct zskiplist {
  struct zskiplistNode *header, *tail;
  unsigned long length;
  int leve;
} zskiplist;
```

zskiplist结构包含：

- header：指向跳跃表的表头结点
- tail：指向跳跃表的表尾节点
- level：记录跳跃表内，层数最大的那个节点的层数（表头结点不计入）
- length：记录跳跃表的长度， 即跳跃表目前包含节点的数量（表头结点不计入）

```
typedef struct zskiplistNode {
  struct zskiplistLevel {
    struct zskiplistNode *forward;
    unsigned int span; // 跨度
  } level[];
  
  struct zskiplistNode *backward;
  double score;
  robj *obj;
} zskiplistNode;
```

```
typedef struct zskiplistNode {
  struct zskiplistLevel {
    struct zskiplistNode *forward;
    unsigned int span; // 跨度
  } level[];
  
  struct zskiplistNode *backward;
  double score;
  robj *obj;
} zskiplistNode;
```

zskiplistNode包含：

- level：节点中用L1、L2、L3来标记节点的各个层，每个层都有两个属性：前进指针和跨度。前进指针用来访问表尾方向的其他节点，跨度记录了前进指针所指向节点和当前节点的距离（图中曲线上的数字）。

  level数组可以包含多个元素，每个元素都有一个指向其他节点的指针，程序可以通过这些层来加快访问其他节点。层数越多，访问速度就越快。没创建一个新节点的时候，根据幂次定律（越大的数出现的概率越小）随机生成一个介于1-32之间的值作为level数组的大小。这个大小就是层的高度。

  跨度用来计算排位（rank）：在查找某个节点的过程中，将沿途访问过的所有层的跨度累计起来，得到就是目标节点的排位。

- 后退指针：BW，指向位于当前节点的前一个节点。只能回退到前一个节点，不可跳跃。

- 分值（score）：节点中的1.0/2.0/3.0保存的分值，节点按照各自保存的分值从小到大排列。节点的分值可以相同。

- 成员对象（obj）：节点中的o1/o2/o3。它指向一个字符串对象，字符串对象保存着一个SDS值。

注：表头结点也有后退指针、分值和成员对象，只是不被用到。

遍历所有节点的路径：

1. 访问跳跃表的表头，然后从第四层的前景指正到表的第二个节点。
2. 在第二个节点时，沿着第二层的前进指针到表中的第三个节点。
3. 在第三个节点时，沿着第二层的前进指针到表中的第四个节点。
4. 但程序沿着第四个程序的前进指针移动时，遇到NULL。结束遍历。

##### 2.跳跃表API

略

##### 3.跳跃表的性质

跳表具有如下性质：
 (1) 由很多层结构组成
 (2) 每一层都是一个有序的链表
 (3) 最底层(Level 1)的链表包含所有元素
 (4) 如果一个元素出现在 Level i 的链表中，则它在 Level i 之下的链表也都会出现。
 (5) 每个节点包含两个指针，一个指向同一链表中的下一个元素，一个指向下面一层的元素。

[参考](#<https://www.jianshu.com/p/c2841d65df4c>)



如下为旧版本

是有序集合的底层实现之一。

跳跃表是基于多指针有序链表实现的，可以看成多个有序链表。

在查找时，从上层指针开始查找，找到对应的区间之后再到下一层去查找。下图演示了查找 22 的过程。

与红黑树等平衡树相比，跳跃表具有以下优点：

- 插入速度非常快速，因为不需要进行旋转等操作来维护平衡性；
- 更容易实现；
- 支持无锁操作。

#### 整数集合

整数集合（intset）是集合键的底层实现之一，当一个集合只包含整数值元素，并且数量不多时，Redis采用整数集合作为集合键的底层实现。

##### 1.整数集合的实现

整数集合，可以保存int16_t、int32_t或者int64_t的整数值，且元素不重复，intset.h/intset结构表示一个整数集合：

```
typedef struct intset {
  uint32_t encoding; // 决定contents保存的真正类型
  uint32_t length;
  int8_t contents[]; // 各项从小到大排序
} inset;
```

##### 2.升级

每当添加一个新元素到整数集合中，且新元素的类型比现有所有元素的类型都要长时，整数集合需要先升级（update），然后才能添加新元素：

1. 根据新元素的类型，扩展底层数组的空间大小，并为新元素分配空间。
2. 将底层数组现有元素转换成与新元素相同的类型，并放置在正确的位置上（从后向前遍历）。放置过程中，维持底层数组的有序性质不变。
3. 将新元素添加到底层数组里。

因为每次升级都可能对所有元素进行类型转换，所以复杂度为*O(N)*。

PS. 因为引发升级的新元素长度比当前元素都大，所以它的值要么大于当前所有元素，要么就小于。前种情况放置在底层数组的末尾，后种情况放置在头部。

##### 3.升级的好处

升级有两个好处

1. **提升整数集合的灵活性**

   我们可以随意地将int16_t、int32_t添加到集合中，不必担心出现类型错误，毕竟C是个静态语言。

2. **尽可能解约内存**

   避免用一个int64_t的数组包含所有元素

##### 4.降级

整数集合不支持降级。

##### 5.整数集合的API

略

#### 压缩列表

压缩列表（ziplist）是列表键和哈希键的底层实现之一。当一个列表键只包含少量列表现，并且每个列表项要么就是小整数值，要么就是长度较短的字符串，那么Redis就会使用压缩列表来实现列表键。

当一个哈希键只包含少量键值对，并且每个键值对要么是小整数值，要么是长度较短的字符串，Redis就会使用压缩列表来实现哈希键。

##### 1.压缩列表的构成

压缩列表是Redis为了节约内存而开发的，由一系列特殊编码的连续内存块组成的顺序型（sequential）数据结构。一个压缩列表可以包含多个节点（entry），每个节点可以保存一个字节数组或者一个整数值。

压缩列表的各组成部分：

> zlbytes | zltail | zllen | entry1 | entry2 | … | entryN | zlend

其中，

| 属性    | 类型     | 长度  | 用途                                                         |
| ------- | -------- | ----- | ------------------------------------------------------------ |
| zlbytes | uint32_t | 4字节 | 记录压缩列表占用的内存字节数：在内存重分配，或计算zlend的位置时使用 |
| zltail  | uint32_t | 4字节 | 记录表尾结点距离起始地址的字节数：通过这个偏移量，程序可以直接确定表尾结点的地址 |
| zllen   | uint16_t | 2字节 | 记录节点数量：但这个属性小于UINT16_MAX（65535）时，这个属性的值就是节点的数量。如果等于UINT16_MAX，节点的真实数量要遍历整个压缩列表才能得到 |
| entryX  | 列表节点 | 不定  | 各个节点，节点的长度由保存的内容决定                         |
| zlend   | uint8_t  | 1字节 | 特殊值0xFF，标记压缩列表的尾端                               |

##### 2.压缩列表节点的构成

压缩列表的节点可以保存一个字节数组或者一个整数值。压缩节点的各个组成部分：

> previous_entry_length | encoding | content

**previous_entry_length**

previous_entry_length以字节为单位，记录前一个节点的长度。previous_entry_length属性的长度可以是1字节或5字节：

1. 若前一节点的长度小于254字节，那么previous_entry_length属性的长度就是1字节。前一节点的长度保存在其中。
2. 若前一节点的长度大于254字节，那么previous_entry_length属性的长度就是5字节：其中属性的第一个字节被设置为0xFE（十进制254），而之后的四个字节则用于保存前一节点的长度。

程序可以通过指针运算，根据当前节点的起始地址来计算出前一个结点的起始地址。压缩列表的从尾向头遍历就是据此实现的。

**encoding**

节点的encoding记录了节点的content属性所保存的数据的类型和长度：

- 1字节、2字节或者5字节长，值的最高位为00、01或10的是字节数组编码：这种编码表示节点的content保存的是字节数组，数组的长度由编码除去最高两位置后的其他位记录。
- 1字节长。值的最高位以11开头的是整数编码：表示content保存着整数值，整数值的类型和长度由编码除去最高两位之后的其他位记录。

**content**

content保存节点的值，可以使字节数组或整数，值的类型和长度由encoding属性决定。

保存字节数组“hello world”的节点：

| previoid_entry_length | encoding | content       |
| --------------------- | -------- | ------------- |
| ...                   | 00001011 | "hello world" |

保存整数10086的节点：

| previoid_entry_length | encoding | content |
| --------------------- | -------- | ------- |
| ...                   | 11000000 | 10086   |

##### 3.连锁更新

因为previoid_entry_length的长度限制，添加或删除节点都有可能引发「连锁更新」。在最坏的情况下，需要执行*N*次重分配操作，而每次空间重分配的最坏复杂度是*O(N)*，合起来就是*O(N^2)*。

尽管如此，连锁更新造成性能问题的概率还是比较低的：

1. 压缩列表里有多个连续的、长度介于250和253字节之间的节点，连锁更新才有可能触发。
2. 即使出现连锁更新，只要需要更新的节点数量不多，性能也不会受影响。

##### 4.压缩列表的API

略

#### 对象

Redis并没有使用SDS、双端链表、字典、压缩列表、整数集合来实现键值对数据库，而是基于这些数据结构创建了一个对象系统。这个系统包含字符串对象、列表对象、哈希对象、集合对象和有序集合对象。

通过这五种类型的对象，Redis可以在执行命令之前，根据对象的类型判断一个对象是否执行给定的命令。使用对象的好处是，可以针对不同的场景，为对象设置多种不同的数据结构的实现，从而优化使用效率。

除此之外，Redis还实现了引用计数的内存回收机制。当程序不再需要某个对象的时候，它所占用的内存会被自动释放。另外，Redis还用引用计数实现了对象共享，让多个数据库键共享同一个对象来节约内存。

最后，Redis的对象带有访问时间记录信息，空转时长较大的键可能被优先删除。

##### 1.对象的类型和编码

Redis使用对象来表示数据库中的键和值。创建一个新键值对时，至少会创建两个对象，一个对象用作键，一个对象用作值。每个对象都由一个redisObject结构表示：

```
typedef struct redisObject {
  unsigned type: 4; // 类型
  unsigned encoding: 4; // 编码
  void *ptr; // 指向底层实现数据结构的指针
  // ...
} robj;
```

###### 类型

对象的type记录了对象的类型，它的值可以是

| type常量     | 对象的名称   |
| ------------ | ------------ |
| REDIS_STRING | 字符串对象   |
| REDIS_LIST   | 列表对象     |
| REDIS_HASH   | 哈希对象     |
| REDIS_SET    | 集合对象     |
| REDIS_ZSET   | 有序集合对象 |

键总是一个字符串对象，值可以是字符串对象、列表对象、哈希对象、集合对象、有序集合对象。

但数据库执行TYPE命令时，返回的结果为数据库键对应的值对象的类型，而不是键对象的类型。

###### 编码和底层实现

对象的ptr指向对象的底层实现数据结构，而这些数据结构由对象的encoding决定，它可以是：

| encoding常量              | 对应的底层数据结构 |
| ------------------------- | ------------------ |
| REDIS_ENCODING_INT        | long类型的整数     |
| REDIS_ENCODING_EMBSTR     | embstr编码的SDS    |
| REDIS_ENCODING_RAW        | SDS                |
| REDIS_ENCODING_HT         | 字典               |
| REDIS_ENCODING_LINKEDLIST | 双端链表           |
| REDIS_ENCODING_ZIPLIST    | 压缩列表           |
| REDIS_ENCODING_INTSET     | 整数集合           |
| REDIS_ENCODING_SKIPLIST   | 跳跃表和字典       |

每种类型的对象至少使用了两种编码。

使用OBJECT ENCODING命令可以查看一个数据库键的值对象的编码。

##### 2.字符串对象

字符串对象的编码可以使int、raw或embstr。

1. 如果字符串对象保存的是整数值，且可以用long类型表示，那么字符串对象会将整数值保存在ptr中（将void* 转换成 long），并将编码设置为int。
2. 如果字符串对象保存到是一个字符串值，且长度大于32字节，那么字符串对象使用SDS来保存这个字符串值，并将编码设置为raw。
3. 如果字符串对象保存到是一个字符串值，且长度小于等于32字节，那么字符串对象使用embstr编码的方式来存储这个字符串值。

embstr编码是专门用来保存短字符串的优化方式。和raw编码一样，都是用redisObject结构和sdshdr结构来表示字符串对象，但raw会调用两次内存分配函数分别创建redisObject结构和sdshdr结构，而embstr则通过一次内存分配一块连续空间，依次包含两个结构：

| redisObject                    | sdshdr             |
| ------------------------------ | ------------------ |
| type \| encoding \| ptr \| ... | free \| len \| buf |

embstr的好处：

1. 内存分配次数降为一次。
2. 释放字符串对象只要一次内存释放函数。
3. 因为内存连续，可以更好地利用缓存。

PS. 用`long double`类型表示的浮点数在Redis中也是作为字符串值存储的。程序会先将浮点数转成字符串值，然后再保存转换的字符串值。

###### 编码的转换

int编码和embstr编码的字符串对象可以被转换为raw编码的字符串对象。

1. 对int编码的字符串对象执行一些命令，可使其不再是整数值，而是字符串值，那么编码也就变为raw了。如APPEND。
2. 对embstr编码的字符串，执行修改命令，也会变成raw对象。如APPEND。

###### 字符串命令的实现

用于字符串键的所有命令都是针对字符串对象来构建的。

| 命令       | int编码的实现方法                                            | embstr编码的实现方法                                         | raw编码的实现方法                                            |
| ---------- | ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ |
| SET        | int编码保存值                                                | embstr编码保存值                                             | raw编码保存值                                                |
| GET        | 拷贝对象所保存的整数值，将这个拷贝转换为字符串值，然后向客户端返回这个字符串值 | 直接向客户端返回字符串值                                     | 直接向客户端返回字符串值                                     |
| APPEND     | 将对象转换为raw编码，然后按raw方式执行此操作                 | 将对象转换为raw编码，然后按raw方式执行此操作                 | 调用sdscatlen函数，将给定字符串追加到现有字符串的末尾        |
| INCBYFLOAT | 取出整数值并将其转换为long double的浮点数，对这个浮点数进行加法计算，然后将结果保存起来 | 取出整数值并将其转换为long double的浮点数，对这个浮点数进行加法计算，然后将结果保存起来。如果字符串值不能被转换为浮点数，那么客户端会报错 | 取出整数值并将其转换为long double的浮点数，对这个浮点数进行加法计算，然后将结果保存起来。如果字符串值不能被转换为浮点数，那么客户端会报错 |
| INCBY      | 对整数值进行加法计算，得出的结果作为整数被保存起来           | 不能执行此命令，客户端报错                                   | 不能执行此命令，客户端报错                                   |
| DECBY      | 对整数值进行减法计算，得出的结果作为整数被保存起来           | 不能执行此命令，客户端报错                                   | 不能执行此命令，客户端报错                                   |
| STRLEN     | 拷贝对象保存的整数值，将这个拷贝转换为字符串值，计算并返回这个字符串值的长度 | 调用sdslen函数，返回字符串的长度                             | 调用sdslen函数，返回字符串的长度                             |
| SETRANGE   | 将对象转换为raw编码，然后按raw方式执行此命令                 | 将对象转换为raw编码，然后按raw方式执行此命令                 | 将字符串特定索引上的值设置为给定的字符                       |
| GETRANGE   | 拷贝对象保存的整数值，将这个拷贝转换为字符串，然后取出返回字符串指定索引上的字符 | 直接取出并返回给定索引上的字符                               | 直接取出并返回给定索引上的字符                               |



##### 3.列表对象

列表对象的编码是ziplist或linkedlist。

使用ziplist时，每个压缩列表的节点保存了一个列表元素。使用linkedlist时，每个链表节点保存了一个字符串对象，而每个字符串对象都保存了一个列表元素。（字符串对象是Redis五种类型的对象中唯一一种会被嵌套的对象）。

###### 编码转换

当列表对象同时满足以下两个条件时，使用ziplist编码：

1. 保存的字符串对象的长度都小于64字节。
2. 保存的元素数量小于512个。

否则就是用linkedlist编码。

> 以上两个条件的上限可以修改，使用list-max-ziplist-value选项和list-max-ziplist-entries选项。

###### 列表命令的实现

| 命令    | ziplist编码的实现                                            | linkedlist编码的实现                                         |
| ------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| LPUSH   | 调用ziplistPush函数，将新元素压入表头                        | 调用listAddNodeHead函数，将新元素压入表头                    |
| RPUSH   | 调用ziplistPush函数，将新元素压入表尾                        | 调用listAddNodeTail函数，将新元素压入表尾                    |
| LPOP    | 调用ziplistIndex定位表头节点，返回节点保存的元素后，调用ziplistDelete删除表头结点 | 调用lsitFrist定位表头节点，返回节点保存的元素后，调用listDelNode删除表头结点 |
| RPOP    | 调用ziplistIndex定位表尾节点，返回节点保存的元素后，调用ziplistDelete删除表尾结点 | 调用listLast定位表尾节点，返回节点保存的元素后，调用listDelNode删除表尾结点 |
| LINDEX  | 调用ziplistIndex                                             | 调用listIndex                                                |
| LLEN    | 调用ziplistLen                                               | 调用listLength                                               |
| LINSERT | 插入新节点到表头或表尾时，使用ziplistPush；其他位置使用ziplistInsert | 调用listInsertNode                                           |
| LREM    | 遍历节点，调用ziplistDelete删除包含给定元素的节点            | 遍历节点，调用listDelNode删除包含给定元素的节点              |
| LTRIM   | 调用ziplistDeleteRange函数删除不再指定索引范围内的节点       | 遍历节点，调用listDelNode                                    |
| LSET    | 调用ziplistDelete，先删除给定索引上的节点，然后调用ziplistInsert插入新节点 | 调用listIndex函数，定位给定索引上的节点，然后通过赋值操作更新节点的值 |

##### 4.哈希对象

哈希对象的编码可以是ziplist或hashtable。

使用ziplist时，每当有新的键值对要加入哈希对象时，程序先保将存了**键**的压缩列表对象推入到表尾，然后再将保存了**值**的节点推入到表尾。因此：

1. 保存了同一键值对的两个节点总是挨在一起。
2. 先添加的键值对会被放在表头，后添加的在表尾。

使用hashtable时，哈希对象中的每个键值对都使用一个字典键值对来保存：

- 字典的每个键都是一个字符串对象，对象中保存了键值对的键。
- 字典的每个值都是一个字符串独显，对象中保存了键值对的值。

###### 编码转换

当哈希对象同时满足以下两个条件时，使用ziplist编码：

1. 哈希对象保存的所有键值对的键和值的字符串长度都小于64字节。
2. 哈希对象保存的键值对数量小于512个。

否则就使用hashtable编码。

> 以上两个条件的上限可以修改，使用hash-max-ziplist-value选项和hash-max-ziplist-entries选项。

###### 哈希命令的实现

| 命令    | ziplist编码的实现                                            | hashtable编码的实现                            |
| ------- | ------------------------------------------------------------ | ---------------------------------------------- |
| HSET    | ziplistPush将元素压入表尾，然后再ziplistPush将值压入表尾     | dictAdd添加新节点                              |
| HGET    | ziplistFind查找指定键对应的节点，再ziplistNext将指针移动到键节点旁边的值节点，返回直值节点 | dictFind查找给定键，然后dictGetVal返回对应的值 |
| HEXISTS | ziplistFind查找指定键对应的节点                              | dictFind                                       |
| HDEL    | ziplistFind，然后删除键节点和值节点                          | dictDelete                                     |
| HLEN    | ziplistLen，然后除以2                                        | dictSize                                       |
| HGETALL | 遍历ziplist，ziplistGet返回所有的键和值                      | 遍历字典，dictGetKey返回键，dictGetVal返回值   |

##### 5.集合对象

集合对象的编码可以使intset或hashtable。

1. inset编码，集合对象的所有元素都被保存在整数集合中。
2. hashtable编码，字典的每个键都是一个字符串对象，每个字符串对象都包含了一个集合元素，字典的值全部为NULL。

###### 编码的转换

当集合对象同时满足一下两个条件时，使用inset编码：

1. 所有元素都是整数值。
2. 元素数量不超过512个。

> 第二个的上限修改，查看set-max-intset-entries选项。

###### 集合命令的实现

| 命令        | intset编码的实现                | hashtable编码的实现              |
| ----------- | ------------------------------- | -------------------------------- |
| SADD        | intsetAdd                       | dictAdd                          |
| SCARD       | intsetLen                       | dictSize                         |
| SISMEMBER   | intsetFind                      | dictFind                         |
| SMEMBERS    | 遍历集合，使用intsetGet返回元素 | 遍历字典，使用dictGetKey返回元素 |
| SRANDMEMBER | intsetRandom随机返回一个元素    | dictGetRandomKey                 |
| SPOP        | intsetRandom，然后intsetRemove  | dictGetRandomKey，然后dictDelete |
| SREM        | intsetRemove                    | dictDelete                       |

##### 6.有序集合对象

有序集合的编码是ziplist或skiplist。

1. ziplist编码：每个集合元素使用两个紧挨在一起的ziplist节点来存储。第一个节点保存元素的成员（member），第二元素保存元素的分值（score）。元素按分值的从小到大排序。
2. skiplist编码：一个zset结构同时包含一个字典和一个跳跃表。跳跃表按分值从小到大保存了所有集合元素，每个跳跃表节点都保存了一个集合元素，节点的object保存了元素的成员，score保存了元素的分值。字典为有序集合创建了一个从成员到分值的映射，字典中的每个键值对都保存了一个集合元素，键保存了元素的成员，值保存了元素的分值。

###### 编码的转换

有序集合满足以下两个条件时，使用ziplist编码：

1. 元素数量小于128。
2. 元素成员的长度小于64个字节。

> 两个条件的上限参考zset-max-ziplist-entries和zset-max-ziplist-value选项。
>
> ###### 有序集合命令的实现
>
> | 命令      | ziplist编码的实现                                | zset编码的实现                                               |
> | --------- | ------------------------------------------------ | ------------------------------------------------------------ |
> | ZADD      | ziplistInsert将成员和分值两个节点分别插入        | zslInsert，将新元素插入跳跃表，然后dictAdd将新元素关联到字典 |
> | ZCARD     | ziplistLen，然后除以2                            | 访问跳跃表的length                                           |
> | ZCOUNT    | 遍历列表，统计分值在给定范围内的节点的数量       | 遍历跳跃表                                                   |
> | ZRANGE    | 从头到尾遍历                                     | 从头到尾遍历跳跃表                                           |
> | ZREVRANGE | 从尾向头遍历                                     | 从尾向头遍历                                                 |
> | ZRANK     | 从头到尾遍历，查找给定成员，并记录经过节点的数量 | 从头到尾遍历，查找给定成员，并记录经过节点的数量             |
> | ZREVRANK  | 从尾向头遍历，查找给定成员，并记录经过节点的数量 | 从尾向头遍历，查找给定成员，并记录经过节点的数量             |
> | ZREM      | 遍历，删除包含给定成员的节点及旁边的分值节点     | 遍历跳跃表，删除节点，并在字典中解除被删除元素的成员和分值的关联 |
> | ZSCORE    | 遍历查找成员节点，返回旁边的分值节点             | 从字典中取出给定成员的分值                                   |

##### 7.类型检查与命令多态

在执行一个类型特定的命令之前，Redis会先检查输入键的类型是否正确，然后再决定是否执行。类型检查是通过redisObject的type属性来的。

除此之外，Redis还会根据值对象的编码方式，选择正确的实现命令来执行。这就是多态。

##### 8.内存回事

Redis为对象系统构建了一个引用计数垃圾回收。每个对象的引用计数由redisObject结构的refcount保存。

| 操作                   | 引用计数的变化 |
| ---------------------- | -------------- |
| 创建一个新对象         | 初始化为1      |
| 对象被一个新程序使用   | +1             |
| 对象不再被一个程序使用 | -1             |

当计数变为0时，对象占用的内存就会被释放。

##### 9.对象共享

refcount还可用于对象共享：

1. 将数据库键的值指向现有的值对象。
2. refcount++。

Redis在初始化服务器时，创建了10000个字符串对象，包含0 ~ 9999的所有整数值，用于共享。

> 数量通过redis.h/REDIS_SHARED_INTSETGERS常量控制。

使用OBJECT REFCOUNT可查看值对象的引用计数。

**但Redis只对包含整数值的字符串对象共享**。即只有共享对象和目标对象完全相同的情况下。一个共享对象保存的值越复杂，验证共享对象和目标对象是否相同的操作也就越复杂。

##### 10.对象的空转时长

redisObject最后一个属性lru，记录了对象最后一次被访问的时间，用OBJECT IDLETIME可查看。

如果服务器打开了maxmemory属性，lru对象可用于回收内存。

### 四、使用场景

#### 计数器

可以对 String 进行自增自减运算，从而实现计数器功能。

Redis 这种内存型数据库的读写性能非常高，很适合存储频繁读写的计数量。

#### 缓存

将热点数据放到内存中，设置内存的最大使用量以及淘汰策略来保证缓存的命中率。

#### 查找表

例如 DNS 记录就很适合使用 Redis 进行存储。

查找表和缓存类似，也是利用了 Redis 快速的查找特性。但是查找表的内容不能失效，而缓存的内容可以失效，因为缓存不作为可靠的数据来源。

#### 消息队列

List 是一个双向链表，可以通过 lpush 和 rpop 写入和读取消息

不过最好使用 Kafka、RabbitMQ 等消息中间件。

#### 会话缓存

可以使用 Redis 来统一存储多台应用服务器的会话信息。

当应用服务器不再存储用户的会话信息，也就不再具有状态，一个用户可以请求任意一个应用服务器，从而更容易实现高可用性以及可伸缩性。

#### 分布式锁实现

在分布式场景下，无法使用单机环境下的锁来对多个节点上的进程进行同步。

可以使用 Redis 自带的 SETNX 命令实现分布式锁，除此之外，还可以使用官方提供的 RedLock 分布式锁实现。

#### 其它

Set 可以实现交集、并集等操作，从而实现共同好友等功能。

ZSet 可以实现有序性操作，从而实现排行榜等功能。

### 五、Redis 与 Memcached

两者都是非关系型内存键值数据库，主要有以下不同：

#### 数据类型

Memcached 仅支持字符串类型，而 Redis 支持五种不同的数据类型，可以更灵活地解决问题。

#### 数据持久化

Redis 支持两种持久化策略：RDB 快照和 AOF 日志，而 Memcached 不支持持久化。

#### 分布式

Memcached 不支持分布式，只能通过在客户端使用一致性哈希来实现分布式存储，这种方式在存储和查询时都需要先在客户端计算一次数据所在的节点。

Redis Cluster 实现了分布式的支持。

#### 内存管理机制

- 在 Redis 中，并不是所有数据都一直存储在内存中，可以将一些很久没用的 value 交换到磁盘，而 Memcached 的数据则会一直在内存中。
- Memcached 将内存分割成特定长度的块来存储数据，以完全解决内存碎片的问题。但是这种方式会使得内存的利用率不高，例如块的大小为 128 bytes，只存储 100 bytes 的数据，那么剩下的 28 bytes 就浪费掉了。

### 六、键的过期时间

Redis 可以为每个键设置过期时间，当键过期时，会自动删除该键。

对于散列表这种容器，只能为整个键设置过期时间（整个散列表），而不能为键里面的单个元素设置过期时间。

##### 1.过期键的删除策略

有三种不同的键删除策略：

| 策略     | 操作                                                         | 优点                             | 缺点                         |
| -------- | ------------------------------------------------------------ | -------------------------------- | ---------------------------- |
| 定时删除 | 设置键的过期时间的同时，创建一个定时器，让定时器在键的过期时间来临时立即执行删除操作。 | 对内存最友好，保证会尽快释放内存 | 对CPU时间不友好              |
| 惰性删除 | 每次从键空间获取键时，检查其是否过期，过期则删除；否则就返回该键。 | 对CPU时间最友好                  | 对内存不友好                 |
| 定期删除 | 每隔一段时间，对数据库进行一次检查，删除所有的过期键。       | 上述两种策略的整合和折中         | 难点在于确定删除的时长和频率 |

##### 2.Redis过期键的删除策略

Redis服务器使用的是惰性删除和定期删除两种策略。

##### 3.AOF、RDB和复制功能对过期键的处理

###### RDB文件生成和载入

执行SAVE或BGSAVE命令时会创建一个新的RDB文件，已过期的键不会保存到RDB中。

在启动服务器时，如果开启了RDB功能，服务器会载入RDB文件：

- 如果服务器以主服务器模式运行，那么载入RDB时，会检查文件中的键，过期键会被忽略。
- 如果服务器以从服务器模式运行，那么载入RDB时，不管键是否过期，一律载入。其后，在主从服务器同步时，从服务器的数据库就会被清空。

###### AOF文件写入和重写

服务器以AOF持久化模式运行时，如果某个键已过期，但还没有被删除，那么AOF文件不会因为这个过期键而产生任何影响。但过期键被删除后，程序会向AOF文件追加一条DEL命令，显式记录该键已被删除。

AOF重写过程中，程序会对键进行检查，已过期的键不会被保存到重写后的AOF文件中。

###### 复制

当服务器处于复制模式下时，过期键删除动作由主服务器控制，这就保证了一致性：

- 主服务器删除一个过期键后，显式向从服务器发送DEL命令
- 从服务器执行客户端发送的读命令时，即使碰到过期键也不会删除，而是像处理未过期的键一样
- 从服务器接到主服务器的DEL命令后，才会删除过期键

### 七、数据淘汰策略

可以设置内存最大使用量，当内存使用量超出时，会施行数据淘汰策略。

Redis 具体有 6 种淘汰策略：

| 策略            | 描述                                                 |
| --------------- | ---------------------------------------------------- |
| volatile-lru    | 从已设置过期时间的数据集中挑选最近最少使用的数据淘汰 |
| volatile-ttl    | 从已设置过期时间的数据集中挑选将要过期的数据淘汰     |
| volatile-random | 从已设置过期时间的数据集中任意选择数据淘汰           |
| allkeys-lru     | 从所有数据集中挑选最近最少使用的数据淘汰             |
| allkeys-random  | 从所有数据集中任意选择数据进行淘汰                   |
| noeviction      | 禁止驱逐数据                                         |

作为内存数据库，出于对性能和内存消耗的考虑，Redis 的淘汰算法实际实现上并非针对所有 key，而是抽样一小部分并且从中选出被淘汰的 key。

使用 Redis 缓存数据时，为了提高缓存命中率，需要保证缓存数据都是热点数据。可以将内存最大使用量设置为热点数据占用的内存量，然后启用 allkeys-lru 淘汰策略，将最近最少使用的数据淘汰。

Redis 4.0 引入了 volatile-lfu 和 allkeys-lfu 淘汰策略，LFU 策略通过统计访问频率，将访问频率最少的键值对淘汰。

### 八、持久化

Redis 是内存型数据库，为了保证数据在断电后不会丢失，需要将内存中的数据持久化到硬盘上。

#### RDB 持久化

将某个时间点的所有数据都存放到硬盘上。

可以将快照复制到其它服务器从而创建具有相同数据的服务器副本。

如果系统发生故障，将会丢失最后一次创建快照之后的数据。

如果数据量很大，保存快照的时间会很长。



持久化可以手动，也可以根据服务器配置选项定期执行。

RDB持久化生成的RDB文件是一个压缩过的二进制文件，通过该文件可以还原生成RDB文件时的数据库状态。

##### 1.RDB文件的创建和载入

有两个命令可以生成RDB文件：

1. SAVE。该命令会阻塞Redis服务器进程，直到RDB文件创建完毕，期间拒绝任何命令请求。
2. BGSAVE。派生出一个子进程来创建RDB文件，服务器进程（父进程）继续处理命令请求。

在BGSAVE命令执行期间，服务器处理SAVE、BGSAVE命令会被拒绝执行；处理BGREWRITEAOF命令和平时有所不同：

- 若BGSAVE命令正在执行，客户端的BGREWRITEAOF命令会延迟到BGSAVE命令执行完毕后执行。
- 若BGREWRITEAOF正在执行，客户端的BGSAVE命令会被拒绝执行。

创建RDB文件的操作由`rdb.c/rdbSave`函数完成。

RDB文件的载入工作在服务器启动时自动执行。

另外，AOF文件的更新频率比RDB文件要高，所以：

- 如果服务器开启了AOF，那么优先用AOF来还原数据库。
- 只有在AOF关闭时，服务器才会用RDB来还原数据库。

载入RDB文件的工作由`rdb.c/rdbLoad`函数完成。载入RDB文件期间，服务器一直处于阻塞状态。

##### 2.自动间隔性保存

Redis允许用户通过设置服务器配置的save选项，每隔一段时间执行一次BGSAVE命令。配置如下：

> save 900 1
>
> save 300 10
>
> save 60 10000

那么上述三个条件只要满足任意一个，BGSAVE命令就会被执行：

1. 服务器在900秒内，对服务器进行了至少1次修改。
2. 服务器在300秒内，对服务器进行了至少10次修改。
3. 服务器在60秒内，对服务器进行了至少10000次修改。

当Redis服务器启动时，用户可以指定配置文件或者传入启动参数的方式设置save选项。如果没有主动设置，服务器默认使用上述三个条件。接着，服务器会根据save的条件，设置`redisServer`结构的`saveParams`属性。

```
struct redisServer {
  // ...
  struct saveparam *saveparams; // 保存条件的数组
  long long dirty;
  time_t lastsave;
  //...
}

struct saveparam {
  time_t seconds; // 秒数
  int changes; // 修改数
}
```

除此之外，服务器还维持着一个dirty计数器，以及一个lastsave属性。

- dirty记录上一次成功`SAVE`或`BGSAVE`之后，服务器对数据库状态进行了多少次修改。
- lastsave是一个UNIX时间戳，记录了服务器上一次成功`SAVE`或`BGSAVE`的时间。

###### 检查保存条件是否满足

服务器的周期性操作函数`serverCron`默认每个100毫秒就会执行一次，其中一项工作是检查save选项所设置的保存条件是否满足。

##### 3.RDB文件结构

RDB文件的各个部分包括：

> REDIS | db_version | databases | EOF | check_sum

###### REDIS

开头是REDIS部分，长度为5。保存了五个字符，以便载入时确认是否为RDB文件。

###### db_version

db_version长4字节，是一个字符串表示的整数，记录了RDB文件的版本号。

###### databases

databases部分包含了0个或多个数据库，以及各个数据库中的键值对数据。一个保存了0号和3号数据库的RDB文件如下：

> REDIS | db_version | database 0 | databse 3 | EOF | check_sum

每个非空数据库在RDB文件中都可保存为以下三部分：

> SELECTDB | db_number | key_value_pairs

- SELECTEDB。1字节。但程序遇到这个值的时候，它就知道接下来要读入的将是一个数据库号码。
- db_number。读取号码之后，服务器会调用`SELECT`命令切换数据库。
- key_value_pairs。不带过期时间的键值对在RDB文件中包括TYPE、key、value。TYPE的值决定了如何读入和解释value的数据。带过期时间的键值对增加了EXPIRETIME_MS和ms。前者告知程序接下来要读入一个UNIX时间戳。

###### EOF

长度为1字节，标识RDB文件结束。

###### check_sum

8字节的无符号整数，保存着一个前面四个部分的校验和。

##### 4.分析RDB文件

od命令分析RDB文件。-c参数可以以ASCII编码打印文件。

Redis自带的文件检查工具是redis-check-dump。

#### AOF 持久化

AOF（Append Only File）持久化，与RDB持久化通过保存数据库中的键值对来记录数据库状态不同，AOF保存Redis所执行的写命令来记录数据库状态。被写入AOF文件的命令都是以Redis的命令请求协议格式保存的，纯文本格式，打开即可查看。

##### 1.AOF持久化的实现

AOF持久化功能的实现可分为命令追加（append）、文件写入、文件同步（sync）三个步骤。

###### 命令追加

如果打开AOF功能，服务器在执行完一个写命令后，会以协议格式将被执行的命令追加到服务器状态的`aof_buf`缓冲区的末尾。

```
struct redisServer {
  // ...
  sds aof_buf;
  // ...
};
```

###### 文件的写入与同步

Redis的服务器进程就是一个事件循环（loop），这个循环中的文件事件负责接受客户端的请求，并向客户端发送回复，而时间事件则负责执行像`serverCron`函数这样的定时任务。

服务器在处理文件任务时可能会执行写命令，追加内容到`aof_buf`缓冲区，所以服务器在每次结束一个事件循环前，都会调用`flushAppendOnlyFile`，考虑是否将缓冲区的内容写入到AOF文件中。

> flushAppendOnlyFile函数的行为由服务器配置的`appendfsync`选项的值来决定：always、everysec（默认）、no。

##### 2.AOF文件的载入与数据还原

服务器只要读入并重新执行一遍AOF文件中的写命令，就可以还原服务器关闭之前的数据库状态：

1. 创建一个不带连接的**伪客户端**。
2. 从AOF文件中分析并读取一条写命令。
3. 使用伪客户端执行被读出的命令
4. 一直执行步骤2和3，直到AOF文件中的所有命令都被处理完为止。

##### 3.AOF重写

为了解决AOF文件体积膨胀的问题，Redis提供了AOF重写功能。通过该功能，Redis可以创建一个新的AOF文件来替代现有的AOF文件，新文件不会包含冗余命令，体积也会小很多。

###### 实现

AOF文件重写不需要对现有AOF文件做任何读取、分析或写入操作，而是通过读取服务器当前的数据库状态实现的。首先从数据库中读取现在的键，然后用一条命令去记录键值对，代替之前记录这个键值对的多条命令。这就是AOF重写的实现原理。

Redis服务器采用单个线程来处理命令请求，所以将AOF重写程序放到子进程中，这样父进程可以继续处理请求。父子进程会出现数据不一致的问题，Redis服务器设置了一个AOF重写缓冲区，这个缓冲区在创建子进程之后开始使用，但Redis服务器执行完一个写命令后，会通知将写命令发送给AOF缓冲区和AOF重写缓冲区。子进程完成AOF重写操作后，向父进程发送一个信号，父进程将执行以下操作：

1. 将AOF重写缓冲区的内容写入新AOF文件。
2. 对新的AOF文件改名，覆盖现有的AOF文件。



如下为旧版本

将写命令添加到 AOF 文件（Append Only File）的末尾。

使用 AOF 持久化需要设置同步选项，从而确保写命令同步到磁盘文件上的时机。这是因为对文件进行写入并不会马上将内容同步到磁盘上，而是先存储到缓冲区，然后由操作系统决定什么时候同步到磁盘。有以下同步选项：

| 选项     | 同步频率                 |
| -------- | ------------------------ |
| always   | 每个写命令都同步         |
| everysec | 每秒同步一次             |
| no       | 让操作系统来决定何时同步 |

- always 选项会严重减低服务器的性能；
- everysec 选项比较合适，可以保证系统崩溃时只会丢失一秒左右的数据，并且 Redis 每秒执行一次同步对服务器性能几乎没有任何影响；
- no 选项并不能给服务器性能带来多大的提升，而且也会增加系统崩溃时数据丢失的数量。

随着服务器写请求的增多，AOF 文件会越来越大。Redis 提供了一种将 AOF 重写的特性，能够去除 AOF 文件中的冗余写命令。

### 九、事务

一个事务包含了多个命令，服务器在执行事务期间，不会改去执行其它客户端的命令请求。

事务中的多个命令被一次性发送给服务器，而不是一条一条发送，这种方式被称为流水线，它可以减少客户端与服务器之间的网络通信次数从而提升性能。

Redis 最简单的事务实现方式是使用 MULTI 和 EXEC 命令将事务操作包围起来。



Redis通过`MULTI`、`EXEC`、`WATCH`等命令实现事务（transaction）功能。事务提供一种将多个命令请求打包，然后一次性、按顺序地执行多个命令的机制。在事务执行期间，服务器不会中断事务去执行其他客户端的命令请求。

事务以`MULTI`开始，接着是多个命令放入事务之中，最后由`EXEC`将这个事务提交（commit）到服务器执行。

#### 1.事务的实现

一个事务从开始到结束经历三个阶段：

1. 事务开始
2. 命令入队
3. 事务执行

#### 2.WATCH 命令的实现

`WATCH`命令是个乐观锁，它可以再`EXEC`执行之前，监视任意数量的数据库键，并在`EXEC`执行时，检查被监视的键是否至少有一个已经被修改过了。如果是，服务器将拒绝执行事务，并返回客户端事务执行失败的空回复。

#### 3.事务的ACID性质

Redis的事务总是具有原子性（atomicity）、一致性（consistency）、隔离性（isolation），且当Redis运行在某种特定的持久化模式下，事务也具有耐久性（durability）。

##### 原子性

事务的原子性是指，事务中的多个操作当做一个整体来执行，要么执行所有，要么一个也不执行。

Redis的事务与传统关系型数据库事务的区别在于，Redis不支持事务的回滚机制（rollback），即使事务队列中的某个命令执行出现错误，整个事务也会继续执行下去，直到所有命令执行完毕。

##### 一致性

事务的一致性是指，如果数据库在事务执行前是一致的，那么执行后，无论事务是否执行成功，数据库也应该是一致的。「一致」是数据符合数据库本身的定义和要求，没有包含非法或无效的错误数据。

Redis通过谨慎的错误检测和简单的设计来保证事务的一致性。

1. 入队错误

   如果事务在入队命令的过程中，出现了命令不存在，或者命令格式不正确等情况，Redis会拒绝执行该事务。

2. 执行错误

   执行过程中的错误是不能再入队时被服务器发现的，这些错误只会在命令实际执行时被触发。事务的执行过程中出现错误，服务器也不会中断事务的执行，而是继续执行其他命令，一致性的命令不会被出错的命令影响。

3. 服务器停机

   执行事务的过程中停机，不管服务器使用的何种持久化模式，Redis总能保持重启后的数据库一致性。

##### 隔离性

事务的隔离性是指，即使数据库中有多个事务并发执行，各个事务之间不会相互影响，且与串行执行的结果相同。

Redis采用单线程执行事务，所以事务总是以串行的方式执行，也当然具有隔离性。

##### 持久性

事务的持久性是指，一个事务执行完毕后，结果已经被保存到永久性存储介质中。即使服务器停机，执行事务所得的结果也不会丢失。

Redis没有为事务提供额外的持久化功能，事务的持久化由Redis使用的持久化模式决定的：

- 无持久化：事务不具持久性，一旦停机，所有服务器的数据都将丢失。
- RDB持久化：只有执行`BGSAVE`才会对数据库进行保存，且异步执行的`BGSAVE`不能保证事务数据在第一时间被保存。因此RDB持久化也不能保证事务的持久性。
- AOF持久化，且`appendfsync`选项为`always`时：程序执行命令后会调用同步操作，将命令数据保存到硬盘。这时事务是有持久性的。
- AOF持久化，且`appendfsync`选项为`everysec`时：每秒一次同步命令数据到硬盘，事务也不具有持久性。
- AOF持久化，且`appendfsync`选项为`no`时：程序交由操作系统来决定何时同步到硬盘，事务也不具有持久性。

### 十、事件

Redis 服务器是一个事件驱动程序。

需要处理以下两类事件：

- 文件事件（file event）：Redis服务器通过socket与客户端连接，文件事件就是对套接字操作的抽象。服务器与客户端的通信会产生相应的文件事件，服务器监听并处理这些事件来完成一系列的网络通信操作。
- 时间事件（time event）：Redis服务器的一些操作（如`serverCron`函数）需要在特定时间点执行，时间事件就是对这类定时任务的抽象。

#### 重点综述

- Redis 服务器是一个事件驱动程序，服务器处理的事件分为文件事件和时间时间两类。
- 文件事件处理器基于Reactor模式（反应器模式）实现网络通信程序。
- 文件事件是对套接字操作的抽象：每次套接字变为可应答（acceptable）、可写（writable）或者可读（readable）时，相应的文件事件就会产生。
- 文件事件分为AE_READABLE事件（读事件）和AE_WRITABLE事件（写事件）两类。
- 时间事件分为定时事件和周期性事件：定时事件只在指定的时间到达一次，而周期性事件则每隔一段时间到达一次。
- 服务器一般情况下只执行serverCron函数一个时间事件，且该事件是周期性事件。
- 文件事件和时间事件是合作关系，服务器会轮流处理这两种事件，且处理过程中不会进行抢占。
- 时间事件的实际处理时间通常比设定的到达时间晚一些。

#### 文件事件

服务器通过套接字与客户端或者其它服务器进行通信，文件事件就是对套接字操作的抽象。

Redis 基于 Reactor 模式开发了自己的网络事件处理器，使用 I/O 多路复用程序来同时监听多个套接字，并将到达的事件传送给文件事件分派器，分派器会根据套接字产生的事件类型调用相应的事件处理器。

Redis基于Reactor模式开发了自己的网络事件处理器，称为『文件事件处理器』，文件事件处理器以单线程方式运行。

文件事件处理器的四个组成部分：

- 套接字。

  当被监听的套接字准备好执行accept、read、write、close等操作时，与操作相对应的文件事件就会产生。

- I/O多路复用程序。

  使用I/O多路复用程序同时监听多个套接字，并向文件分派器传送那些产生了事件的套接字（使用队列）。

- 文件事件分派器

  根据套接字的事件类型，调用相应的事件处理器。

- 事件处理器

##### 1.I/O多路复用程序的实现

Redis的I/O多路复用包装了常见的select、poll、evport和kqueue等函数库来实现的，每个函数库的在Redis源码中都有一个独立的文件。

##### 2.事件的类型

I/O多路复用程序可以监听多个套接字的ae.h/AE_READABLE和ae.h/AE_WRITABLE事件。两种事件可以同时监听，但会优先处理AE_READABLE事件。

##### 3.API

略

##### 4.文件事件的处理器

Redis为文件事件编写了多个处理器，分别用于实现不同的网络通信需求：

- 连接应答处理器：监听客户端的套接字，并应答。

  networking.c/acceptTcpHandler函数，具体实现为sys/socket.h/accept函数的包装。服务器初始化时，会将这个处理器与套接字的AE_READABLE事件关联起来。

- 命令请求处理器：接受来自客户端的命令请求。

  networking.c/readQueryFromClient函数，具体实现为unistd.h/read函数的包装。

- 命令回复处理器：向客户端返回命令的执行结果。

  networking.c/sendReplyToClient函数，具体实现为unistd.h/write函数的包装。

- 复制处理器：主从服务器的复制操作。

#### 时间事件

服务器有一些操作需要在给定的时间点执行，时间事件是对这类定时操作的抽象。

Redis 将所有时间事件都放在一个无序链表中，通过遍历整个链表查找出已到达的时间事件，并调用相应的事件处理器。

Redis的时间事件分为两类：

- 定时事件：是让一段程序在指定的时间之内执行一次；
- 周期性事件：是让一段程序每隔指定时间就执行一次。

时间事件主要有三个属性：

- id：服务器为时间事件创建的全局唯一ID（标识号）。ID号按从小到大的顺序递增，新事件的ID号比旧事件的ID号要大。
- when：毫秒进度的UNIX时间戳，事件的到达时间。
- timeProc：时间事件处理器，事件到达时，负责处理事件。

一个事件是定时事件还是周期性事件，取决于时间事件处理器的返回值：

- 返回ae.h/AE_NOMORE就是定时事件，到达一次后就删除
- 返回非AE_NOMORE的整数值就是周期性事件，事件到达后，根据返回值对when属性进行更新。

##### 1.实现

服务器的所有时间事件存放在一个无序链表（*不按when属性排序*）中，每当时间事件处理器运行时，遍历整个链表，找到已到达的事件，调用相应的事件处理器。

##### 2.API

略

##### 3.serverCron函数

serverCron函数的工作包括：

- 更新服务器的统计信息，如时间、内存占用、数据库占用
- 清理过期的键值对
- 关闭和清理失效的连接
- 尝试AOF或RDB持久化
- 如果是主服务器，对从服务器定期同步
- 如果是集群模式，对集群进行同步和测试连接

#### 事件的调度与执行

服务器需要不断监听文件事件的套接字才能得到待处理的文件事件，但是不能一直监听，否则时间事件无法在规定的时间内执行，因此监听时间应该根据距离现在最近的时间事件来决定。

事件调度与执行由 aeProcessEvents 函数负责，伪代码如下：

```
def aeProcessEvents():
    # 获取到达时间离当前时间最接近的时间事件
    time_event = aeSearchNearestTimer()
    # 计算最接近的时间事件距离到达还有多少毫秒
    remaind_ms = time_event.when - unix_ts_now()
    # 如果事件已到达，那么 remaind_ms 的值可能为负数，将它设为 0
    if remaind_ms < 0:
        remaind_ms = 0
    # 根据 remaind_ms 的值，创建 timeval
    timeval = create_timeval_with_ms(remaind_ms)
    # 阻塞并等待文件事件产生，最大阻塞时间由传入的 timeval 决定
    aeApiPoll(timeval)
    # 处理所有已产生的文件事件
    procesFileEvents()
    # 处理所有已到达的时间事件
    processTimeEvents()
```

将 aeProcessEvents 函数置于一个循环里面，加上初始化和清理函数，就构成了 Redis 服务器的主函数，伪代码如下：

```
def main():
    # 初始化服务器
    init_server()
    # 一直处理事件，直到服务器关闭为止
    while server_is_not_shutdown():
        aeProcessEvents()
    # 服务器关闭，执行清理操作
    clean_server()
```

调度和执行的规则如下：

- aeApiPoll函数的最大阻塞时间由到达时间最接近当前时间的事件决定，避免服务器的频繁轮询。
- 如果处理完一次文件事件后，未有时间事件到达，则再次处理文件事件。
- 对事件的处理都是同步、有序、原子地执行。不会中断、抢占事件处理。
- 时间事件的处理时间，通常比其设定的到达时间晚一些，因为时间事件是在文件事件之后执行的，且事件之间不会出现抢占。

### 十一、复制

Redis中，用户可以执行`SAVEOF`命令或设置`saveof`选项，让一个服务器去复制（replicate）另一个服务器。被复制的服务器叫做master，对master进行复制的服务器叫做slave。

进行复制中的master和slave应该保存相同的数据，这称作“数据库状态一致”。

#### 1.旧版复制功能的实现

Redis的复制功能分为同步（sync）和命令传播（command propagate）两个操作：

- 同步用于将slave的数据库状态更新至master当前所处的数据库状态。
- 命令传播用于master的数据块状态被修改，导致和lsave的数据库状态不一致时，让两者的数据库重回一致状态。

##### 同步

复制开始时，slave会先执行同步操作，步骤如下：

- slave对master发送`SYNC`命令
- master收到`SYNC`执行`BGSAVE`，在后台生成一个RDB文件，并使用一个缓冲区记录从现在开始执行的所有写命令。
- master的`BGSAVE`执行完毕后，将生成的RDB文件发送给slave，slave接收并载入这个RDB，更新自己的数据库状态
- master将记录在缓冲区中的所有写命令发送给slave，后者执行这些操作，再次更新自己的数据库状态

##### 命令传播

同步完成后，主从服务器的一致状态仍有可能改变，每当master执行写命令时，主从服务器的状态就会不一致。为此，master执行写命令，并将其发送给slave一并执行。

#### 2.旧版复制功能的缺陷

Redis的复制可以分为两种情况：

- 初次复制：slave没有复制过，或者slave要复制的master和上一次复制的master不同。
- 断线后重复制：处于命令传播阶段的master和slave中断了复制，但重连后，slave继续复制master。

对于初次复制，旧版复制功能可以很好完成。但是断线后复制，效率却很低，因为重连后会浪费一次`SYNC`操作。

#### 3,.新版复制功能的实现

为了解决旧版复制功能在断线后的低效问题，Redis从2.8之后，使用`PSYNC`代替`SYNC`执行复制时的同步操作。`PSYNC`具有完整重同步（full resynchronization)和部分重同步（partial resynchronization）两种模式：

- 完整重同步用于处理初次复制，执行步骤和`SYNC`命令基本一样。
- 部分重同步用于处理断线后重复制，重连后，如果条件允许，master可以将断开期间的谢明令发送给slave执行。

#### 4.部分重同步的实现

部分重同步功能有三个部分组成：

- master和slave的复制偏移量（replication offset）
- master的复制积压缓冲区（replication backlog）
- 服务器的运行ID（run ID）

##### 复制偏移量

master和slave分别维护一个复制偏移量：

- master每次向slave传播N个字节的数据时，就将自己的复制偏移量+N。
- slave每次收到master的N个字节数据时，就将自己的复制偏移量+N。

对比两者的复制偏移量，就知道它们是否处于一致状态。

##### 复制积压缓冲区

复制积压缓冲区是master维护的一个固定长度的FIFO队列，默认大小为1MB。当服务器进行命令传播时，不仅会将命令发送给所有slave，还会入队到积压缓冲区。因此，积压缓冲区保存了最近被传播的写命令，且为队列中的每个字节记录相应的复制偏移量。

slave重连上master时，slave通过`PSYNC`将自己的复制偏移量offset发送给master，master会根据这个offset决定slave执行何种同步操作：

- 如果offset之后的数据仍在复制积压缓冲区中，执行部分重同步操作。
- 否则，执行完整重同步操作。

##### 服务器运行ID

部分重同步还要用到服务器运行ID，主从服务器都有自己的ID。初次复制时，master将自己的ID传给slave，后者将其保存。

断线重连后，slave向当前连接的master发送之前保存的ID：

- master发现接收的ID和自己的相同，那么说明断线之前复制的就是自己，继续执行部分重同步。
- 如果不同，完整重同步啦！

#### 5.PSYNC命令的实现

`PSYNC`的调用方式有两种：

- slave没有复制过任何master，则在开始一个新的复制时向master发送`PSYNC ? -1`命令，请求完整重同步。
- slave复制过某个master，则发送`PSYNC <runid> <offset>`命令，接收到这个命令的master会根据`runid`和`offset`来判断执行哪种同步。

#### 6.复制的实现

通过向slave发送`SLAVEOF`命令，可以让slave复制master

##### 步骤1：设置master的地址和端口

命令`slave 127.0.0.1 6379`会设置服务器状态的以下两个属性：

```
struct redisServer {
  char *masterhost;
  int masterport;
};
```

##### 步骤2：建立套接字连接

如果slave的套接字能成功连接到master，那么slave会为这个套接字关联一个专门用于处理复制工作的文件事件处理器，它将负责处理后续的复制工作。

master接收到客户端的套接字连接之后，为其创建相应的客户端状态，这时slave同时有server和client两个身份。

##### 步骤3：发送PING命令

slave成为master的客户端之后，紧接着就向其发送`PING`命令，那么：

##### 步骤4：身份验证

收到master的“PONG”回复后，slave要检查自己的`masterauth`选项决定是否进行身份验证。如果需要验证，slave会向master发送一条`AUTH`命令，参数为`masterauth`选项的值，接下来： 

##### 步骤5：发送端口信息

身份验证之后，slave将执行`REPLCONF listening-port <port-number>`，向master发送slave的监听端口号。master收到后，会将端口号放到客户端状态的`slave_listening_por`t属性中该属性的唯一作用就是master执行`INFO replication`命令时打印slave的端口号。

```
typdef struct redisClient {
  int slave_listening_port;
} redisClient;
```

##### 步骤6：同步

这一步，slave发送`PSYNC`，执行同步操作。执行同步之后，master也成了slave的客户端，master发送写命令来改变slave的数据库状态。

##### 步骤7：命令传播

完成同步之后，主从服务器就进入命令传播阶段，master将自己执行写命令发送给slave，slave接到后就执行，这样两者的状态就一直保持一致了。

#### 7.心跳检测

命令传播阶段，slave默认每秒给master发送一次命令：`REPLCONF ACK <replication_offset>`，其中replication_offset对应当前slave的复制偏移量。该命令有三个作用：

- 检测网络连接状态

- 辅助实现min-slaves选项

  该选项防止master在不安全的情况下执行写命令，比如slave数量小于3的时候。

- 检测命令丢失

  这个根据复制偏移量来判断，如果两者不一致，master就会把复制积压缓冲区的命令重新发送。



如下为旧版本笔记

通过使用 slaveof host port 命令来让一个服务器成为另一个服务器的从服务器。

一个从服务器只能有一个主服务器，并且不支持主主复制。

#### 连接过程

1. 主服务器创建快照文件，发送给从服务器，并在发送期间使用缓冲区记录执行的写命令。快照文件发送完毕之后，开始向从服务器发送存储在缓冲区中的写命令；
2. 从服务器丢弃所有旧数据，载入主服务器发来的快照文件，之后从服务器开始接受主服务器发来的写命令；
3. 主服务器每执行一次写命令，就向从服务器发送相同的写命令。

#### 主从链

随着负载不断上升，主服务器可能无法很快地更新所有从服务器，或者重新连接和重新同步从服务器将导致系统超载。为了解决这个问题，可以创建一个中间层来分担主服务器的复制工作。中间层的服务器是最上层服务器的从服务器，又是最下层服务器的主服务器。

### 十二、Sentinel

Sentinel（哨兵）可以监听集群中的服务器，并在主服务器进入下线状态时，自动从从服务器中选举出新的主服务器。

Sentinel（哨兵）是Redis的高可用性解决方案，由一个或多个Sentinel实例组成的Sentinel系统可以监视任意多个master以及属下的所有slave。Sentinel在被监视的master下线后，自动将其属下的某个slave升级为新的master，然后由新的master继续处理命令请求。

#### 1.启动并初始化Sentinel

启动一个Sentinel可以使用命令：

> redis-sentinel sentinel.conf

或者

> redis-server sentnel.conf —sentinel

当一个Sentinel启动时，会执行以下几步：

1. 初始化服务器
2. 将普通Redis服务器使用的代码替换成Sentinel专用代码
3. 初始化Sentinel状态
4. 根据配置文件，初始化监视的master列表
5. 创建与master的网络连接

##### 初始化服务器

l哦

##### 使用Sentinel专用代码

略

##### 初始化Sentinel状态

略

##### 初始化Sentinel状态的masters属性

略

##### 创建与master的网络连接

连接建立后，Sentinel将成为master的客户端，可以向其发送命令。对于被监视的master来说，Sentinel会创建两个异步网络连接：

- 命令连接，用于发送和接收命令。
- 订阅连接。用于订阅master的`__sentinel__:hello`频道。

#### 2.获取master信息

Sentinel以默认10秒一次的频率，向master发送`INFO`命令，获取其当前信息：

- master本身的信息，包括运行ID、role等。据此，Sentinel更新master实例的结构。
- master的slave信息。据此，Sentinel更新master实例的slaves字典。

#### 3.获取slave信息

Sentinel发现master有新的slave时，除了会为这个slave创建相应的实例结构外，还会创建到它的命令连接和订阅连接。

通过命令连接，Sentinel会向slave每10秒发送一次`INFO`命令，根据回复更新slave的实例结构：

- slave的运行ID
- slave的角色role
- master的地址和端口
- 主从的连接状态
- slave的优先级
- slave的复制偏移量

#### 4.向master和slave发送信息

#### 5.接收来自master和slave的频道信息

#### 6.检测主观下线状态

#### 7.检查客观下线时长

#### 8.选举领头Sentinel

master被判定为客观下线后，监视这个master的所有Sentinel会进行协商，选举一个领头Sentinel，并由其对该master执行故障转移。选举的规则如下：

- 所有Sentinel都可以成为领头。
- 每次进行领头Sentinel选举后，不论选举是否成功，所有Sentinel的配置纪元都会+1。这个配置纪元就是一个计数器。
- 一个配置纪元里，所有Sentinel都有一次将某个Sentinel设置为局部领头Sentinel的机会，且局部领头一旦设定，在这个配置纪元内就不可修改。
- 每个发现master进入客观下线的Sentinel都会要求其他Sentinel将自己设为局部领头Sentinel。
- 当一个Sentinel向另一个Sentinel发送`SENTINEL is-master-down-by-addr`，且命令中的runid参数是自己的运行ID，这表明源Sentinel要求目标Sentinel将他设置为局部领头。
- Sentinel设置局部领头的规则是先到先得。
- 目标Sentinel收到`SENTINEL is-master-down-by-addr`后，会返回一条命令回复，恢复中的`leader_runid`和`leader_epoch`参数分别记录了目标Sentinel的局部领头Sentinel的运行ID和配置纪元。
- 源Sentinel收到目标Sentinel的回复后，检查回复中的`leader_runid`和`leader_epoch`是否和自己相同。
- 如果某个Sentinel被半数以上的Sentinel设置为局部领头，那么这个Sentinel就成为领头Sentinel。
- 因为领头Sentinel需要半数以上的支持，且每个Sentinel在每个配置纪元里只设置一次局部领头，所以一个配置纪元里，只能有一个领头。
- 如果给定时限内，没有产生领头Sentinel，那么各个Sentinel过段时间再次选举，知道选出领头为止。

#### 9.故障转移

领头Sentinel会对已下线的master执行故障转移，包括以下三个步骤：

- 从已下线master属下的所有slave选出一个新的master。
- 让已下线master属下的所有slave改为新复制新的master。
- 让已下线master成为新master的slave，重新上线后就是新slave。

### 十三、集群

分片是将数据划分为多个部分的方法，可以将数据存储到多台机器里面，这种方法在解决某些问题时可以获得线性级别的性能提升。

假设有 4 个 Redis 实例 R0，R1，R2，R3，还有很多表示用户的键 user:1，user:2，... ，有不同的方式来选择一个指定的键存储在哪个实例中。

- 最简单的方式是范围分片，例如用户 id 从 0~1000 的存储到实例 R0 中，用户 id 从 1001~2000 的存储到实例 R1 中，等等。但是这样需要维护一张映射范围表，维护操作代价很高。
- 还有一种方式是哈希分片，使用 CRC32 哈希函数将键转换为一个数字，再对实例数量求模就能知道应该存储的实例。

根据执行分片的位置，可以分为三种分片方式：

- 客户端分片：客户端使用一致性哈希等算法决定键应当分布到哪个节点。
- 代理分片：将客户端请求发送到代理上，由代理转发请求到正确的节点上。
- 服务器分片：Redis Cluster。



Redis集群是分布式的数据库方案，通过分片（sharing）来进行数据共享，并提供复制或故障转移功能。

#### 1.节点

一个Redis集群通常由多个节点（node）组成。开始时每个node都是独立的，要将其连接起来：

> CLUSTER MEET

#### 2.槽指派

Redis集群通过分片的方式保存数据库中的键值对：集群中的整个数据库被分为16384个槽（slot），数据库中的每个键都属于其中的一个，集群中的每个节点可以处理0个或最多16384个槽。

当数据库中的16384个槽都有节点在处理时，集群处于上线状态（ok），如果任何一个槽都没有得到处理，就处于下线状态（fail）。

`CLUSTER MEET`只是将节点连接起来，集群仍处于下线状态，通过向节点发送`CLUSTER ADDSLOTS`，可以为一个或多个槽指派（assign）给节点负责。

> CLUSTER ADDSLOTS [slot ...]

#### 3.在集群中执行命令

客户端向节点发送与数据库键有关的命令时，接收命令的节点会计算出命令要处理的键属于哪个槽，并检查这个槽是否被指派给了自己：

- 如果指派给了自己，节点直接执行命令。
- 否则，节点向客户端返回一个`MOVED`错误，指引客户端转向（redirect）到正确的节点，再次发送命令。

#### 4.重新分片

Redis集群的重新分片指的是将任意数量已经指派给某个节点的槽改为指派给另一个节点，且相关槽所属的键也从源节点移动到目标节点。重新分片可以在线（online）进行，分片过程中，集群不需要下线，且源节点和目标节点都可以继续处理命令请求。

重新分片是由Redis的集群管理软件`redis-trib`负责的，Redis提供了重新分片所需的所有命令，`redis-trib`则通过向源节点和目标节点发送命令来实现重新分片：

1. 向目标节点发送`CLUSTER SETSLOT <slot> IMPORTING <source_id>`命令，让目标节点准备好导入源节点中属于槽slot的键值对。
2. 向源节点发送`CLUSTER SETSLOT <slot> MIGRATING <target_id>`命令，让源节点准备好迁移键值对。
3. 向源节点发送`CLUSTER GETKEYINSLOT <slot> <count>`命令，获得最多count个属于槽slot的键值对的键名。
4. 对于步骤3获得的每个键名，向源节点发送一个`MIGRATE <target_ip> <target_port> <key_name> 0 <timeout>`命令，将选中的键原子地从原籍诶单迁移到目标节点。
5. 充分执行步骤3和4，知道所有键值对都被迁移至目标及诶单
6. 向集群中的任一节点发送`CLUSTER SETSLOT <slot> NODE <target_id>`命令，将槽slot指派给目标节点，这一指派信息通过消息传送至整个集群。

#### 5.ASK 错误

在重新分片期间，源节点向目标节点迁移一个槽的过程中，可能会出现：属于被迁移槽的一部分键值对保存在源节点中，而另一部分保存在目标节点中。

当客户端向源节点发送一个与数据库键有关的命令，且要处理的键恰好就属于正在被迁移的槽时：

- 源节点先在自己的数据库中查找键，如果找到，直接执行命令。
- 否则，源节点向客户端返回`ASK`错误，指引客户端转向正在导入槽的目标节点，再次发送命令。

#### 6.复制与故障转移

Redis集群中的master用于处理槽，slave用于复制某个master，并在被复制的master下线时，代替master继续处理命令请求。

#### 7.消息

集群中的节点通过消息来通信，消息主要分为以下5种：

- `MEET`消息：加入当前集群
- `PING`消息：检测在线
- `PONG`消息：回复`MEET`和`PING`
- `FAIL`消息：进入`FAIL`状态
- `PUBLISH`消息：节点接收到`PUBLISH`消息，会执行这个命令，并向集群广播一条`PUBLISH`消息，所有接收到这条`PUBLISH`消息的节点都会执行相同的`PUBLISH`命令。

一个消息由消息头（header）和消息正文（body）组成。

### 十四、一个简单的论坛系统分析

该论坛系统功能如下：

- 可以发布文章；
- 可以对文章进行点赞；
- 在首页可以按文章的发布时间或者文章的点赞数进行排序显示。

#### 文章信息

文章包括标题、作者、赞数等信息，在关系型数据库中很容易构建一张表来存储这些信息，在 Redis 中可以使用 HASH 来存储每种信息以及其对应的值的映射。

Redis 没有关系型数据库中的表这一概念来将同种类型的数据存放在一起，而是使用命名空间的方式来实现这一功能。键名的前面部分存储命名空间，后面部分的内容存储 ID，通常使用 : 来进行分隔。例如下面的 HASH 的键名为 article:92617，其中 article 为命名空间，ID 为 92617。

#### 点赞功能

当有用户为一篇文章点赞时，除了要对该文章的 votes 字段进行加 1 操作，还必须记录该用户已经对该文章进行了点赞，防止用户点赞次数超过 1。可以建立文章的已投票用户集合来进行记录。

为了节约内存，规定一篇文章发布满一周之后，就不能再对它进行投票，而文章的已投票集合也会被删除，可以为文章的已投票集合设置一个一周的过期时间就能实现这个规定。

#### 对文章进行排序

为了按发布时间和点赞数进行排序，可以建立一个文章发布时间的有序集合和一个文章点赞数的有序集合。（下图中的 score 就是这里所说的点赞数；下面所示的有序集合分值并不直接是时间和点赞数，而是根据时间和点赞数间接计算出来的）



### 十五、客户端

#### 重点综述

- 服务器状态结构使用clients链表连接起多个客户端状态，新添加的客户端状态会被添加到链表的末尾。
- 客户端状态的flag属性使用不同标志来表示客户端角色，及客户端当前所处的状态。
- 输入缓冲区记录了客户端发送的命令请求，缓冲区大小不能超过1GB。
- 命令的参数和个数会被记录在客户端状态的argv和argc属性中，cmd属性记录了客户端要执行命令的实现函数。
- 客户端有固定大小缓冲区和可变大小缓冲区，固定大小缓冲区最大为16KB，可变大小缓冲区最大不能超过服务器设置的硬性限制值。
- 输出缓冲区限制值有两种，若输出缓冲区的大小超过了服务器设置的硬性限制，客户端会被立即关闭；若客户端在一定时间内，一直超过服务器设置的软性限制，，客户端也会被关闭。
- 当一个客户端通过网络连接连上服务器时，服务器会为这个客户端创建相应的客户端状态。网络连接关闭、发送不符合协议格式的命令请求、成为CLIENT KILL命令的目标、空转时间超时，输出缓冲区大小超出限制，以上这些原因会造成客户端被关闭。

#### 客户端的创建于关闭

##### 1.创建客户端

客户端使用connect函数连接到服务器，服务器就会调用连接事件处理器，为客户端创建相应的客户端状态，并添加到链表的末尾。

##### 2.关闭客户端

一个普通客户端可因为多种原因关闭：

- 客户端进程被杀死

- 发送的协议不符合格式

- 客户端成了`CLIENT KILL`命令的目标

- 服务器配置了timeout选项，客户端空转被断开

- 超出输入/输出缓冲区限制

  > 输出缓冲区的限制包括：硬性限制、软性限制。超过软性限制一段时间，客户端也会被关闭。

### 十六、服务端

Redis服务器负责与多个客户端建立连接，处理客户端的命令请求，在数据库中保存命令产生的数据，并通过资源管理来维持服务器自身的运转。

#### 1.命令请求的执行过程

`SET KEY VALUE`命令的执行过程：

1. 客户端向服务器发送命令请求`SET KEY VALUE`。
2. 服务器接收并处理命令请求，在数据库中设置操作，并产生命令回复`OK`。
3. 服务器将`OK`发送给客户端。
4. 客户端接收服务器返回的命令`OK`，并打印给用户。

##### 发送命令请求

用户：键入命令请求

客户端：将命令请求转换为协议格式然后发送给服务器

##### 读取命令请求

当连接套接字因为客户端的写入而变得可读时，服务器将调用命令请求处理器执行以下操作：

1. 读取套接字协议格式中的命令请求，并将其保存在客户端状态的输入缓冲区里。
2. 对输入缓冲区的命令请求进行分析，提取命令参数及其个数，保存到客户端状态的argv和argc属性。
3. 调用命令执行器，执行指定的命令。

##### 命令执行器（1）：查找命令实现

命令执行器要做的第一件事是根据客户端状态的`argv[0]`参数，在命令表（command table）中查找参数指定的命令，并将其保存到客户端状态的`cmd`属性里。

命令表是一个字典，键是命令名字，值是一个`redisCommand`结构。命令表使用的是**大小写无关**的查找算法。

##### 命令执行器（2）：执行预备操作

有了执行命令所需的命令实现函数、参数、参数个数，但程序还需要一些预备操作：

- 检查客户端状态的`cmd`指针是否为`NULL`。
- 根据`cmd`属性指向`redisCommand`结构的`arity`属性，检查命令请求的参数个数是否正确。
- 检查客户端是否通过了身份验证，未通过必须使用`AUTH`命令。
- 如果服务器打开了`maxmemory`功能，检查内存占用情况，有需要时进行内存回收。
- 如果上一次`BGSAVE`出错，且服务器打开了`stop-writes-on-bgsave-error`功能，且服务器要执行一个写命令，拒绝执行。
- 如果客户端正在用`SUBSCRIBE`订阅频道，服务器只会执行订阅相关的命令。
- 如果服务器正在进行输入载入，那么客户端发送的命令必须带有1标识才能被执行。
- 如果服务器因为Lua脚本而超时阻塞，那么服务器只会执行客户端发来的`SHUTDOWN nosave`和`SCRIPT KILL`命令。
- 如果客户端正在执行事务，那么服务器只会执行客户端发来的`EXEC`、 `DISCARD`、 `MULTI`、 `WATCH`命令，其余命令进入事务队列。
- 如果服务器打开监视器功能，要将执行的命令和参数等信息发给监视器，其后才真正执行命令。

##### 命令执行器（3）：调用命令的实现函数

> client->cmd->proc(client);

相当于执行语句：

> sendCommand(client);

命令回复会保存在输出缓冲区，之后实现函数还会为套接字关联命令回复处理器，将回复返回给客户端。

##### 命令执行器（5）：执行后续工作

- 如果开启了慢查询，添加新的日志。
- `redisCommand`结构的`calls`计数器+1。
- 写入AOF缓冲区。
- 同步从服务器。

##### 将命令回复发送给客户端

当客户端套接字变为可写时，服务器将输出缓冲区的命令发送给客户端。发送完毕后，清空输出缓冲区。

##### 客户端接收并打印命令回复

服务器：回复处理器将协议格式的命令返回给客户端。

客户端：将回复格式化成人类可读的格式，打印。

#### 2.serverCron函数

##### 更新服务器时间缓存

每次获取系统的当前时间都要执行一次系统调用，为了减少系统调用，服务器状态中保存了当前时间的缓存：

```
struct redisServer {
  // 秒级的系统当前UNIX时间戳
  time_t unixtime;
  // 毫秒级的系统当前UNIX时间戳
  long long mstime;
};
```

`serverCron`默认会100毫秒更新一次这两个属性，所以它们的精确度并不高。对于一些高精度要求的操作，还是会再次执行系统调用。

##### 更新LRU时钟

```
struct redisServer {
  // 默认10秒更新一次的时钟缓存，用于计算键的空转时长
  // INFO server可查看
  unsigned lruclock:22;
};

// 每个Redis对象都有一个lru属性，计算键的空转时长，就是用服务器的lruclock减去对象的lru时间
typedef struct redisObject {
  unsigned lru:22;
} robj;
```

##### 更新服务器每秒执行命令次数

`serverCron`函数中的`trackOperationPerSecond`函数以每100毫秒一次的频率执行，该函数以抽样计算的方式，估算并记录服务器在最近一秒内处理的命令请求数量，这个值可以用过`INFO status`命令查看。

```
struct redisServer {
  // 上一次抽样的时间
  long long ops_sec_last_sample_time;
  
  // 上一次抽样时，服务器已执行命令的数量
  long long ops_sec_last_sample_ops;
  
  // REDIS_OPS_SEC_SAMPLES 大小默认16
  // 环形数组中的每个项记录了一次抽样结果
  long long ops_sec_samples[REDIS_OPS_SEC_SAMPLES];
  
  // ops_sec_samples 数组的索引值，每次抽样后自动+1
  // 让 ops_sec_samples 数组构成一个环形数组
  int ops_sec_idx;
};
```

客户端执行`INFO`命令，服务器会调用`getOperationsPerSecond`函数，根据`ops_sec_samples`中的抽样结果，计算出`instantaneous_ops_per_sec`属性的值。

##### 更新服务器内存峰值记录

```
struct redisServer {
  // 已使用内存峰值
  size_t stat_peak_memory;
};
```

每次`serverCron`执行，程序都会查看当前的内存数量，更新`stat_peak_memory`。`INFO memory`可查看。

##### 处理SIGTERM信号

启动时，Redis会为服务器进程的`SIGTERM`信号关联处理器`sigtermHandler`函数。它在接到该信号后，打开服务器状态的`shutdown_asap`标识。每次`serverCron`执行，程序都会检查该标识，并决定是否关闭服务器。

```
struct redisServer {
  // 关闭服务器的标识：1，关闭；2，不做操作。
  int shutdown_asap;
};
```

##### 管理客户端资源

`serverCron`每次都会调用`clientsCron`函数，后者会对一定数量的客户端作如下检查：

- 连接是否超时
- 输入缓冲区是否超过长度，如果是，新建缓冲区

##### 管理数据库资源

`serverCron`每次都会调用`databasesCron`函数，检查一部分的数据库，删除过期键，对字典进行收缩等。

##### 执行被延迟的BGREWRITEAOF

服务器执行`BGSAVE`期间，会阻塞`BGREWRITEAOF`命令。

```
struct redisServer {
  // 记录是否有BGREWRITEAOF被延迟
  int aof_rewrite_scheduled;
};
```

##### 检查持久化操作的运行状态

```
struct redisServer {
  // 记录执行BGSAVE命令的子进程ID
  // 如果服务器没有执行BGSAVE，值为-1
  pid_t rdb_child_pid;
  
  // 记录执行BGREWRITEAOF命令的子进程ID
  pid_t aof_child_pid;
};
```

`serverCron`执行时，只要两个属性有一个为-1，则执行wait3函数，检查是否有信号发来服务器进程：

- 如果有信号达到，表明新的RDB文件生成完毕，或AOF文件重写完毕，服务器需要执行相应命令的后续操作
- 没有信号就不做操作

如果两个属性都不为-1，表明服务器没有再做持久化操作，则：

![1588563952745](E:\project_workspace\Cat\src\main\notes\interview\pic\%5CUsers%5Cadmin.admin-PC%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5C1588563952745.png)

##### serverCron的其他操作：

- 将AOF缓冲区的内容写入AOF文件
- 关闭异步客户端（超出输入缓冲区限制）
- 增加cronloops计数器（它的唯一作用就是复制模块中实现『每执行`serverCron`函数N次就执行一次指定代码』的功能”）

##### 3.初始化服务器

##### 初始化服务器状态结构

初始化服务器的第一步就是创建一个`redisServer`类型的实例变量`server`，并为结构中的各个属性设置默认值。这个工作由`redis.c/initServerConfig`函数完成：

- 设置服务器运行id
- 为id加上结尾字符
- 设置默认的配置文件路径
- 设置默认服务器频率
- 设置服务器的运行架构，64位 or 32位
- 设置服务器的默认端口
- 设置服务器的默认RDB和AOF持久化条件
- 初始化服务器的LRU时钟
- 创建命令表

##### 载入配置选项

启动服务器时，用户可以通过配置参数或者配置文件来修改服务器的默认配置。

`redis.c/initServerConfig`函数初始化完`server`变量后，开始载入用户给定的配置。

##### 初始化服务器数据结构

载入用户的配置选项之后，才能正确地初始化数据结构，由`initServer`函数负责：

- `server.clients`链表
- `server.db`数组
- `server.pubsub_channels`字典
- `server.lua`Lua环境
- `server.slowlog`

除此之外，`initServer`还：

- 为服务器设置进程信号处理器
- 创建共享对象
- 打开服务器的监听端口，并为套接字关联应答事件处理器
- 为`serverCron`函数创建时间事件
- 打开或创建的AOF文件
- 初始化后台I/O模块

##### 还原数据库状态

初始化完`server`后，服务器要载入RDB或AOF文件，还原数据库状态

##### 执行事件循环

开始执行服务器的loop。

### 十七、面试题

##### 1、讲讲你都怎么使用Redis的?



##### 2、单线程的Redis为什么快

1.纯内存操作

2.单线程操作，避免了频繁的上下文切换

3.合理高效的数据结构

4.采用了非阻塞的I/O多路复用机制

##### 3、如何解决Redis缓存雪崩的问题

1.使用Redis高可用架构：使用Redis集群来保证Redis服务不会挂掉。

2.缓存时间不一致，给缓存的失效时间加上一个随机值，避免集体失效。

3.限流降级策略：有一定的备案，比如个性推荐服务不可用了，换成热点数据推荐服务。

##### 4、如何解决Redis缓存穿透问题

1.在接口做校验

2.存null值（缓存击穿加锁）

3.布隆过滤器拦截：将所有可能的查询key先映射到布隆过滤器中，查询时先判断key是否存在布隆过滤器中，存在才继续向下执行，若不存在，则直接返回。布隆过滤器将值进行多次哈希bit存储，布隆过滤器说某个元素存在，可能会被误判，布隆过滤器说某个元素不存在，则一定不存在。

##### 5、Redis与MySQL双写一致性方案

先更新数据库，再删除缓存。数据库的读操作，要远快于写操作，所以脏数据很难出现。可以对异步延时删除策略，保证读请求完成以后，再进行删除操作。（TODO需要继续完善）

##### 6、Redis的管道pipeline

对于单线程阻塞式的Redis，pipeline可以满足批量的操作，把多个命令连续的发送给Redis Server，然后一一解析响应结果。Pipelining可以提高批量处理性能，提升原因主要是TCP连接中减少了“交互往返”的时间。pipeline底层是通过把所有的操作封装成流，redis有定义自己的输入输出流。在sync()方法执行操作，每次请求放在队列里面，解析响应包。

##### 7、Redis的底层数据结构

【TODO待补充其他数据结构】

1.字典：

dictht是一个散列表结构，使用拉链法解决哈希冲突。

Redis的字典dict中包含两个哈希表dictht，这是为了方便进行rehash操作。在扩容时，将其中一个dictht上的键值对rehash到另一个dictht上面，完成之后释放空间并交换两个dictht的角色。

rehash操作不是一次性完成的，而是采用渐进放手，这是为了避免一次性执行过多的rehash操作给服务器带来过大的负担。

渐进式rehash通过记录dict的rehashidx完成，他从0开始，然后每执行一次rehash都会递增。如在一次rehash中，要把dict[0] rehash到dict[1]。这一次会把dict[0]上的table[rehashidx]的键值对rehash到dct[1]上，dict[0]的table[rehashidx]指向null，并领rehashidx++。

在rehash期间，每次对字典执行添加、删除、查找或者更新操作时，都会执行一次渐进式rehash。

采用渐进式rehas会导致字典中的数据分散在两个dictht上，因此对字典的查找操作也需要到对应的dictht去执行。

什么叫渐进式 rehash？也就是说扩容和收缩操作不是一次性、集中式完成的，而是分多次、渐进式完成的。如果保存在Redis中的键值对只有几个几十个，那么 rehash 操作可以瞬间完成，但是如果键值对有几百万，几千万甚至几亿，那么要一次性的进行 rehash，势必会造成Redis一段时间内不能进行别的操作。所以Redis采用渐进式 rehash,这样在进行渐进式rehash期间，字典的删除查找更新等操作可能会在两个哈希表上进行，第一个哈希表没有找到，就会去第二个哈希表上进行查找。但是进行 增加操作，一定是在新的哈希表上进行的。

2、跳跃表

是有序集合的底层实现之一。

跳跃表是基于多指针有序链表实现的，可以看成多个有序链表。

[![img](https://camo.githubusercontent.com/76b125fdcb217feda6c273553f86a8a511f775de/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f62656261363132652d646335622d346663322d383639642d3062323334303861633930612e706e67)](https://camo.githubusercontent.com/76b125fdcb217feda6c273553f86a8a511f775de/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f62656261363132652d646335622d346663322d383639642d3062323334303861633930612e706e67)

在查找时，从上层指针开始查找，找到对应的区间后再到下一层去查找。如图所示（TODO 图挂掉了）

[![img](https://camo.githubusercontent.com/32d233eb4df5ca3c027bdf1f84fc51a3b9287f52/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f30656133376565322d633232342d346337392d623839352d6531333163363830356334302e706e67)](https://camo.githubusercontent.com/32d233eb4df5ca3c027bdf1f84fc51a3b9287f52/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f30656133376565322d633232342d346337392d623839352d6531333163363830356334302e706e67)

跳跃表具有如下性质：
 (1) 由很多层结构组成
 (2) 每一层都是一个有序的链表
 (3) 最底层(Level 1)的链表包含所有元素
 (4) 如果一个元素出现在 Level i 的链表中，则它在 Level i 之下的链表也都会出现。
 (5) 每个节点包含两个指针，一个指向同一链表中的下一个元素，一个指向下面一层的元素。

与红黑树等平衡树相比，跳跃表具有以下优点：

- 插入速度非常快，因为不需要进行旋转灯操作来维护平衡性；
- 易实现；
- 支持无锁操作。

##### 8、Redis的同步机制

主从同步。配置好slave服务器连接的master后，slave会建立和master的连接，然后发送sync命令。无论是第一次同步建立的连接还是连接断开后的重新连接，master都会启动一个后台进程，将数据库快照保存到文件中.同时master主进程会开始收集新的写命令并缓存起来。当后台进程完成写文件后，master就将快照文件发送给slave，slave将文件保存到磁盘上，然后加载到内存将数据库快照恢复到slave上。slave完成快照文件的恢复后，master就会把缓存的命令都转发给slave，slave更新内存数据库。后续master收到的写命令都会通过开始建立的连接发送给slave。从master到slave的同步数据的命令和从 client到master发送的命令使用相同的协议格式。当master和slave的连接断开时，slave可以自动重新建立连接。如果master同时收到多个slave发来的同步连接命令，只会使用启动一个进程来写数据库镜像，然后发送给所有slave。

##### 9、Redis的数据过期策略

Redis中数据过期策略采用定期删除+惰性删除策略

- 定期删除策略：Redis启用一个定时器定时监视所有的key，判断key是否过期，过期的话就删除。这种策略可以保证过期的key最终都会被删除，但是也存在严重的缺点：每次都遍历内存中所有的数据，非常消耗CPU资源，并且当key已过期，但是定时器还处于未唤起状态，这段时间内key仍然可以用。

- 惰性删除策略：在获取key是时，先判断key是否过期，如果过期则删除。缺点：如果这个key一直未被使用，那么它一直在内存中，其实它已经过期了，会浪费大量的空间。

- 这两种策略天然的互补，结合起来之后，定时删除策略就发生了一些改变，不再是每次扫描全部的key了，而是随机抽取一部分key进行检查，这样就降低了对CPU资源的损耗，惰性删除策略互补了为检查到的key，基本上满足了所有要求（语句不太通顺？）。但有时候比较巧，既没有被定时器抽取到，又没有被使用，只写数据如何从内存中消失？此时我们有内存淘汰机制，当内存不够用时，内存淘汰机制就会上场。淘汰策略分为：

  ​	当内存不足以容纳新写入数据时，

  - 新写入操作会报错（Redis默认策略）
  - 在键空间中，移除最近最少使用的Key。（LRU推荐使用）
  - 在键空间中，随机移除某个Key。
  - 在设置了过期时间的键空间中，移除最近最少使用的Key。这种情况一般是把Redis即当缓存，又做持久化存储时才用。
  - 在设置了过期时间的键空间中，随机移除某个Key。
  - 在设置了过期时间的键空间中，有更早过期时间的Key优先移除

[可参考七数据淘汰策略](#七数据淘汰策略)

##### 10、Redis Cluster集群模式，如何发现节点挂掉?

通过ping/pong实现故障发现。

ping/pong不仅能传递节点与槽的对应消息，也能传递其他状态，如：节点主从状态、节点故障等。



### 参考资料

- Carlson J L. Redis in Action[J]. Media.johnwiley.com.au, 2013.
- [黄健宏. Redis 设计与实现 [M\]. 机械工业出版社, 2014.](http://redisbook.com/index.html)
- [REDIS IN ACTION](https://redislabs.com/ebook/foreword/)
- [Skip Lists: Done Right](http://ticki.github.io/blog/skip-lists-done-right/)
- [论述 Redis 和 Memcached 的差异](http://www.cnblogs.com/loveincode/p/7411911.html)
- [Redis 3.0 中文版- 分片](http://wiki.jikexueyuan.com/project/redis-guide)
- [Redis 应用场景](http://www.scienjus.com/redis-use-case/)
- [Using Redis as an LRU cache](https://redis.io/topics/lru-cache)