## 计算机操作系统

[参考](https://github.com/CyC2018/CS-Notes/blob/master/notes/%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%20-%20%E7%9B%AE%E5%BD%95.md)



### 一、操作系统引论

#### 1.操作系统的目标和功能

**目标：**

方便性

有效性

- 提高系统资源利用率
- 提高系统吞吐量

可扩充性

开放性

**作用：**

OS作为用户与计算机硬件系统之间的接口

- 命令方式
- 系统调用方式
- 图标–窗口方式

OS实现了对计算机资源的抽象

#### 2.操作系统的发展过程

2.1.未配置操作系统的计算机系统

人工操作方式：用户独占全机 CPU等待人工操作 严重降低了计算机资源的利用率

脱机输入/输出(Off–Line I/O)方式：减少了CPU的空闲时间，提高了I/O速度，效率仍然不理想

2.2.单道批处理系统

2,3.多道批处理系统

1.资源利用率高 2.系统吞吐量大 3.平均周转时间长 4.无交互能力

(宏观并行，微观串行)

2,4.分时系统

特征: 1.多路性 2.独立性 3.及时性 4.交互性

2.5.实时系统

2.6.集群系统–超算~云计算

2.7.微机操作系统的发展

#### 3.操作系统的基本特性

##### 3.1.并发(Concurrence)

并发是指宏观上在一段时间内能同时运行多个程序，而并行则指同一时刻能运行多个指令。

并行需要硬件支持，如多流水线、多核处理器或者分布式计算系统。

操作系统通过引入进程和线程，使得程序能够并发运行。

并行性是指两个或多个事件在同一时刻发生。

并发性是指两个或多个事件在同一时间间隔内发生。

进程是指在系统中能独立运行并作为资源分配的基本单位，它是由一组机器指令，数据和堆栈等组成的，是一个能独立运行的活动实体。

##### 3.2.共享(Sharing)

OS环境下的资源共享是指系统中的资源可供内存中多个并发进程共同使用。

有两种共享方式：互斥共享和同时共享。

互斥共享的资源称为临界资源，例如打印机等，在同一时刻只允许一个进程访问，需要用同步机制来实现互斥访问。

并发和共享是多用户(多任务)OS的两个最基本的特征。它们又是互为存在的条件。

##### 3.3.虚拟(Virtual)

虚拟技术把一个物理实体转换为多个逻辑实体。

主要有两种虚拟技术：时（时间）分复用技术和空（空间）分复用技术。

多个进程能在同一个处理器上并发执行使用了时分复用技术，让每个进程轮流占用处理器，每次只执行一小个时间片并快速切换。

虚拟内存使用了空分复用技术，它将物理内存抽象为地址空间，每个进程都有各自的地址空间。地址空间的页被映射到物理内存，地址空间的页并不需要全部在物理内存中，当使用到一个没有在物理内存的页时，执行页面置换算法，将该页置换到内存中。

##### 3.4.异步(Asynchronism)

异步指进程不是一次性执行完毕，而是走走停停，以不可知的速度向前推进。

#### 4.操作系统的主要功能

##### 4.1.处理机管理功能

进程控制

进程同步

- 进程互斥方式
- 进程同步方式(协同)

进程通信

调度

- 作业调度
- 进程调度

死锁处理

##### 4.2.存储器管理功能

内存分配

- 静态分配
- 动态分配

内存保护

地址映射

内存扩充

- 请求调入功能
- 置换功能

##### 4.3.设备管理功能

缓冲管理

设备分配

设备处理：设备处理程序又称设备驱动程序

##### 4.4.文件管理功能

文件存储空间的管理

目录管理

文件的读写管理和保护

##### 4.5.操作系统与用户之间的接口

用户接口

- 联机用户接口
- 脱机用户接口
- 图形用户接口

程序接口

##### 4.6.现代操作系统的新功能

系统安全

网络的功能和服务

支持多媒体

#### 5.OS结构设计

##### 5.1.传统操作系统结构

无结构操作系统

模块化OS

分层式结构OS

##### 5.2.微内核os结构

**大内核**

大内核是将操作系统功能作为一个紧密结合的整体放到内核。

由于各模块共享信息，因此有很高的性能。

**微内核**

由于操作系统不断复杂，因此将一部分操作系统功能移出内核，从而降低内核的复杂性。移出的部分根据分层的原则划分成若干服务，相互独立。

在微内核结构下，操作系统被划分成小的、定义良好的模块，只有微内核这一个模块运行在内核态，其余模块运行在用户态。

因为需要频繁地在用户态和核心态之间进行切换，所以会有一定的性能损失。

功能：进程（线程）管理、低级存储器管理、中断和陷入管理

**系统调用**：

如果一个进程在用户态需要使用内核态的功能，就进行系统调用从而陷入内核，由操作系统代为完成。

Linux 的系统调用主要有以下这些：

| Task     | Commands                    |
| -------- | --------------------------- |
| 进程控制 | fork(); exit(); wait();     |
| 进程通信 | pipe(); shmget(); mmap();   |
| 文件操作 | open(); read(); write();    |
| 设备操作 | ioctl(); read(); write();   |
| 信息维护 | getpid(); alarm(); sleep(); |
| 安全     | chmod(); umask(); chown();  |

**中断分类**

外中断：

由 CPU 执行指令以外的事件引起，如 I/O 完成中断，表示设备输入/输出处理已经完成，处理器能够发送下一个输入/输出请求。此外还有时钟中断、控制台中断等。

异常：

由 CPU 执行指令的内部事件引起，如非法操作码、地址越界、算术溢出等。

陷入：

在用户程序中使用系统调用。

以下为旧版本内容

### 概述

#### 基本功能

##### 2.内存管理

内存分配、地址映射、内存保护与共享、虚拟内存等。

##### 3.文件管理

##### 4.设备管理

完成用户的 I/O 请求，方便用户使用各种设备，并提高设备的利用率。

主要包括缓冲管理、设备分配、设备处理、虛拟设备等。

### 二、进程的描述与控制

#### 1.前驱图和程序执行

##### 前驱图

指一个有向无循环图，用于描述进程之间执行的先后顺序。

##### 程序顺序执行

三个特征：

- 顺序性
- 封闭性
- 可再现性

##### 程序并发执行

特征：

- 间断性
- 失去封闭性
- 不可再现性

##### 进程和程序的区别

- 进程是动态概念，而程序则是静态概念
- 程序是指令的有序集合，永远存在；进程强调是程序在数据集上的一次执行，有创建有撤销，存在是暂时的；
- 进程具有并发性，而程序没有
- 进程可创建其他进程，而程序并不能形成新的程序
- 进程是竞争计算机资源的基本单位，程序不是

##### 进程和程序的联系

- 进程是程序在数据集上的一次执行
- 程序是构成进程的组成部分，一个程序可对应多个进程，一个进程可包括多个程序
- 进程的运行目标是执行所对应的程序
- 从静态看，进程由程序、数据和进程控制块（PCB）组成

#### 2.进程的描述

**进程的定义**：进程是进程实体的运行过程

进程是资源分配的基本单位。

进程控制块 (Process Control Block, PCB) 描述进程的基本信息和运行状态，所谓的创建进程和撤销进程，都是指对 PCB 的操作。

进程的特征：

- 动态性
- 并发性
- 独立性
- 异步性

**进程的三种基本状态**：

- 就绪状态（ready）：等待被调度
- 运行状态（running）
- 阻塞状态（waiting）：等待资源

应该注意以下内容：

- 只有就绪态和运行态可以相互转换，其它的都是单向转换。就绪状态的进程通过调度算法从而获得 CPU 时间，转为运行状态；而运行状态的进程，在分配给它的 CPU 时间片用完之后就会转为就绪状态，等待下一次调度。
- 阻塞状态是缺少需要的资源从而由运行状态转换而来，但是该资源不包括 CPU 时间，缺少 CPU 时间会从运行态转换为就绪态。

除了三种基本状态，进程还有创建状态和终止状态，以及挂起操作。

**进程管理中的数据结构**

进程控制块PCB的作用：

- 作为独立运行基本单位的标志
- 能实现间断性运行方式
- 提供进程管理所需要的信息
- 提供进程调度所需要的信息
- 实现与其他进程的同步与通信

进程控制块的信息：

- 进程标识符：用于唯一的标识一个进程
  - 外部标识符PID
  - 内部标识符(端口)
- 处理机状态：也称为处理机的上下文，主要由处理机寄存器中的内容组成，这些寄存器包括：
  - 通用寄存器
  - 指令计数器
  - 程序状态字PSW
  - 用户栈指针
- 进程调度信息
  - 进程状态：作为进程调度和对换时的依据
  - 进程优先级：描述继承使用处理机的优先级别的一个整数，优先级越高的进程应优先获得处理机
  - 进程调度所需的其他信息：与所采用的进程调度算法有关，如进程已等待CPU时间的总和、进程已执行时间的总和等。
  - 事件：指进程由执行状态转变为阻塞状态所等待发生的事件，即阻塞原因。
- 进程控制信息
  - 程序和数据的地址
  - 进程同步和通信机制
  - 资源清单
  - 链接指针
- 进程控制块的组织方式
  - 线性方式
  - 链接方式
  - 索引方式

#### 3.进程控制

##### 3.1.操作系统内核

**两大功能：**

支撑功能

- 中断管理
- 时钟管理
- 原语操作
  - 进程的管理，由若干原语（primitive）来执行

资源管理功能

- 进程管理
- 存储器管理
- 设备管理

**进程状态**：

- 系统态：又称管态、内核态，具有较高的特权，能执行一切指令，访问所以寄存器和存储区，传统的OS都在系统态允许。
- 用户态：又称目态，具有较低特权的执行状态，仅能执行规定的指令，访问指定的寄存器和存储区。

##### 3.2.进程的创建

进程的层次结构：父进程、子进程、进程家族（组）。

进程图：描述一个进程的家族关系。

引起创建进程的事件：

- 用户登录
- 作业调度
- 提供服务
- 应用请求

进程的创建：

- 1.申请空白PCB，为新金城申请获得唯一的数字标识符，并从PCB集合中索取一个空白PCB。
- 2.为新进程分配其运行所需的资源，包括各种物理和逻辑资源，如内存、文件、I/O设备和CPU事件等。
- 3.初始化进程块(PCB)。PCB的初始化包括：
  - 初始化标识信息，将系统分配的标识符合父进程的标识符重新填入新的PCB中；
  - 初始化处理机状态信息：使程序计数器指向程序的入口地址，使栈指针指向栈顶；
  - 初始化处理机控制信息，将进程的状态设置为就绪状态或静止就绪状态，对于优先级，通常设置为最低优先级，除非用户显式提出高优先级要求。
- 4.如果进程就绪队列能够接纳新进程，便将新进程插入就绪队列。

##### 3.3.进程的终止

引起进程终止的事件：

- 1.正常结束
- 2.异常结束
- 3.外界干预

 进程的终止过程 ：

- 跟进被终止进程的标识符，从PCB集合中检索出该进程的PCB，从中读出该进程的状态；
- 若被终止进程正处于执行状态，应立即终止该进程的执行，并置调度标志为真，用于指示该进程被终止后应重新进行调度；
- 若该进程还有子孙进程，还应将其所有子孙进程都予以终止，以防他们成为不可控的进程；
- 将被终止进程所拥有的全部资源或归还给其父进程，或归还给系统；
- 将被终止进程(PCB)从所在队列（或链表）中移除，等待其他程序来搜集信息。

##### 3.4.进程的阻塞与唤醒

引起进程阻塞和唤醒的事件

- 请求系统服务而未满足

  - 启动某种操作而阻塞当前进程
  - 新数据尚未到达
  - 等待新任务到达

  进程阻塞过程：阻塞是进程自身的主动行为，阻塞原语：block。

  进程唤醒过程：唤醒原语:wakeup。

##### 3.5.进程的激活与挂起

挂起原语：suspend

激活原语：active

#### 4.进程同步

##### 4.1.进程同步的基本概念

**两种形式的制约关系：**

- 间接相互制约关系
- 直接相互制约关系

**临界资源：**

对临界资源进行访问的那段代码称为临界区。

为了互斥访问临界资源，每个进程在进入临界区之前，需要先进行检查。

**临界区：**

- 进入区enter section
- 临界区critical section
- 退出区exit section
- 剩余区remainder section

对临界资源进行访问的那段代码称为临界区。

为了互斥访问临界资源，每个进程在进入临界区之前，需要先进行检查。

**同步机制应遵循的规则：**

- 1.空闲让进
- 2.忙则等待
- 3.有限等待
- 4.让权等待

**同步与互斥**

- 同步：多个进程因为合作产生的直接制约关系，使得进程有一定的先后执行关系。
- 互斥：多个进程在同一时刻只有一个进程能进入临界区。

##### 4.2.硬件同步机制

- 关中断
- 利用Test-and-Set指令实现互斥
- 利用swap指令实现进程互斥

##### 4.3.信号量机制

信号量（Semaphore）是一个整型变量。

整型信号量

记录型信号量

- 由于整型信号量没有遵循让权等待原则，记录型允许负数，即阻塞链表

AND型信号量

信号量集

- 理解:AND信号量的wait和signal仅能对信号施以加1或减1操作，意味着每次只能对某类临界资源进行一个单位的申请或释放。当一次需要N个单位时，便要进行N次wait操作，这显然是低效的，甚至会增加死锁的概率。此外，在有些情况下，为确保系统的安全性，当所申请的资源数量低于某一下限值时，还必须进行管制，不予以分配。因此，当进程申请某类临界资源时，在每次分配前，都必须测试资源数量，判断是否大于可分配的下限值，决定是否予以分配
- 操作
  - Swait(S1，t1，d1…Sn，tn，dn)
  - Ssignal(S1，d1…Sn，dn)
- 特殊情况：略

##### 4.4.信号量的应用

利用信号量实现进程互斥；

利用信号量实现前趋关系；

##### 4.5.管程机制

定义：代表共享资源的数据结构及由对该共享数据结构实施操作的一组过程所组成的资源管理程序共同构成了一个操作系统的资源管理模块，我们称之为管程。

管程的组成：

- 管程的名称
- 局部于管程的共享数据结构说明
- 对该数据结构进行操作的一组过程
- 对局部于管程的共享数据设置初始值的语句

#### 5.经典进程的同步问题

##### 5.1.生产者-消费者问题

##### 5.2.哲学家进餐问题

##### 5.3.读者-写者问题

#### 6.进程通信

定义：进程通信是指进程之间的信息交换。

进程同步与进程通信很容易混淆，它们的区别在于：

- 进程同步：控制多个进程按一定顺序执行；
- 进程通信：进程间传输信息。

进程通信是一种手段，而进程同步是一种目的。也可以说，为了能够达到进程同步的目的，需要让进程进行通信，传输一些进程同步所需要的信息。

##### 6.1.进程通信的类型

**共享存储器系统：**相互通信的进程共享某些数据结构或共享存储区，进程之间能够通过这些空间进行通信。

- 基于共享数据结构的通信方式
  - 如：生产者和消费者问题中的有界缓冲区
- 基于共享存储区的通信方式

允许多个进程共享一个给定的存储区。因为数据不需要在进程之间复制，所以这是最快的一种 IPC。

需要使用信号量用来同步对共享存储的访问。

多个进程可以将同一个文件映射到它们的地址空间从而实现共享内存。另外 XSI 共享内存不是使用文件，而是使用内存的匿名段。

**管道(pipe)通信系统：**管道指用于连接一个读进程和一个写进程以实现他们之间通信的一个共享文件，又名pipe文件。

**消息传递系统：**进程不必借助任何共享存储区和数据结构，而是以格式化的消息(message)为单位，将通信的数据封装在消息中，并利用操作系统提供的一组通信命令（原语），在进程间进行消息传递，完成进程间的数据交换。

当前应用最广泛的一类进程间通信机制。

- 直接通信方式：发送进程利用OS提供的发送原语，直接把消息发送给目标进程。
- 间接通信方式：发送和接收进程，都通过共享中间实体（称为邮箱）的方式进行消息的发送和接收，完成进程间的通信。

**客服机–服务器系统：**

套接字(Socket)：

- 基于文件型
- 基于网络型

远程过程（函数）调用RPC（Remote Procedure Call）：是一个通信协议，用于通过网络连接的系统。若涉及的软件采用面向对象编程，远程调用过程又称远程方法调用。

套接字可用于不同机器间的进程通信。

##### 6.2.消息传递通信的实现方式

- 直接消息传递系统：采用直接通信方式
- 信箱通信：间接通信方式

##### 6.3.直接消息传递系统实例

略

#### 7.线程(Threads)的基本概念

##### 7.1.线程的基本概念

线程：作为调度和分派的基本单位。

线程是独立调度的基本单位。

一个进程中可以有多个线程，它们共享进程资源。

QQ 和浏览器是两个进程，浏览器进程里面有很多线程，例如 HTTP 请求线程、事件响应线程、渲染线程等等，线程的并发执行使得在浏览器中点击一个新链接从而发起 HTTP 请求时，浏览器还可以响应用户的其它事件。

##### 7.2.线程与进程的比较

调度性：线程是调度的基本单位；进程调度需要上下文切换，开销较大。

并发性：线程支持并发；同一个进程的不同线程可并发，不同进程的不同线程也能并发执行。

拥有资源：进程是系统中拥有资源的基本单位；线程本身不拥有系统资源，而是仅有一点必不可少的、能保证独立运行的资源（如TCB/程序计数器/寄存器和堆栈）。

独立性：

系统开销：进程的创建和撤销系统开销大，线程的创建和撤销系统开销小；进程的切换、同步、通信与线程的切换、同步、通信同理。

- 不同点
  - 调度的基本单位
  - 并发性
- 相似点
  - 状态：运行、阻塞、就绪
  - 线程具有一定的生命期
  - 进程可创建线程，一个线程可创建另一个子线程
  - 多个线程并发执行时仍然存在互斥与同步

##### 7.3.线程的状态和线程控制块

线程运行的三个状态：执行、就绪、阻塞状态。

线程控制块（TCB）：记录所有控制和管理线程的信息，包括

- 线程标识符
- 一组寄存器
- 线程运行状态
- 优先级
- 线程专有存储区
- 信号屏蔽
- 堆栈指针

多线程OS中的进程属性：

- 进程是一个可拥有资源的基本单位
- 多个线程可并发执行
- 进程已不是可执行的实体

#### 8.线程的实现

##### 8.1.线程的实现方式

**内核支持线程KST：**

优点：

- 在多处理器系统中，内核能同时调度同一进程中的多个线程并行执行；
- 若进程中的一个线程被阻塞了，内核可以调度该进程中的其他线程占有处理器运行，也可以运行其他进程中的线程；
- 内核支持线程具有很小的数据结构和堆栈，线程切换快，切换开销小；
- 内核本身亦可以采用多线程技术，提高系统的执行速度和效率。

缺点：对于用户线程的切换而言，其模式切换的开销较大，在同一个进程中，从一个线程切换到另一个线程时，需从用户态转到核心态进行，因为用户进程的线程的在用户态运行，而线程的管理和调度在内核事项，系统开销较大。

**用户级线程ULT：**

优点：

- 线程切换不需要转换到内核空间；
- 调度算法可以是进程专用的；
- 用户级线程的实现与OS平台无关；

缺点：

- 系统调用的阻塞问题。当线程执行一个系统调用时，不仅该线程被阻塞，且进程内的所有线程都会被阻塞，而在内核支持的线程方式中，进程中的其他线程仍然可运行。
- 多线程应用不能利用多处理及进行多重处理，内核每次分配给一个进程仅一个CPU，故进程中仅有一个线程能执行，在放弃CPU之前，其他线程只能等待。

**组合方式：**

- 多对一模型
- 一对一模型
- 多对多模型

##### 8.2.线程的实现

**内核支持线程的实现：**

**用户级线程的实现：**

- 运行时系统(Runtime System)
- 内核控制系统

##### 8.3.线程的创建和终止

略

### 三、处理机调度与死锁

#### 1.处理机调度的层次和调度算法的目标

##### 1.1.处理机调度的层次

高级调度：又称长程调度或作业调度，它的调度对象是作业。

- 分时系统无需作业调度，因为需要交互
- 批处理系统需要作业调度

低级调度：又称进程调度或短程调度，其调度对象是进程（或内核级线程）。

中级调度：又称内存调度。

##### 1.2.处理机调度算法的目标

处理机调度算法的共同目标：

- 资源利用率：提高资源利用率；CPU的利用率=CPU有效工作时间/(CPU有效工作时间+CPU空闲等待时间)。
- 公平性：指使各进程都都获得合理的CPU时间。不会发生进程饥饿现象。
- 平衡性：为使CPU和各种外部设备都处于忙碌状态。
- 策略强制执行

批处理系统的目标：

- 平均周转时间短：周转时间指从作业呗提交给系统开始，到作业完成为止的这段时间间隔（称为作业周转时间）。
- 系统吞吐量高：吞吐量指单位之间内系统完成的作业数，与批处理作业的平均长度有关。
- 处理机利用率高。

分时系统的目标：

- 响应时间快
- 均衡性

实时系统的目标：

- 截止时间的保证
- 可预测性

#### 2.作业与作业调度

##### 2.1.批处理中的作业

作业：作业不仅包含程序和数据，还配有一份作业说明书，系统根据说明书对程序的运行进行控制。批处理系统是以作业为基本单位从外存掉入内存的。

作业步：作业步，每个作业都必须经过若干相对独立，有相互关联的顺序步骤才能得到结果。每一个步骤就是一个作业步。

作业控制块（JCB）：为每个作业设置一个JCB，保存了对作业管理调度的全部信息。是作业存在的标志。

作业运行的三个阶段：收容阶段、运行阶段、完成阶段。

作业运行的三个状态：后备状态、运行状态、完成状态。

##### 2.2.作业调度的主要任务

- 接纳多少个作业
- 接纳哪些作业

##### 2.3.先来先服务（FCFS）和短作业优先（SJF）调度算法

先来先服务（FCFS）：

- 比较有利于长作业，而不利于短作业，因为短作业必须一直等待前面的长作业执行完毕才能执行，而长作业又需要执行很长时间，造成了短作业等待时间过长。
- 有利于CPU繁忙的作业，而不利于I/O繁忙的作业。
- 可用于作业调度和进程调度。
- 非抢占式的调度算法，按照请求的顺序进行调度。
- 算法简单，但效率低。

短作业优先（SJF）：

非抢占式的调度算法，按估计运行时间最短的顺序进行调度。

可用于作业调度和进程调度。

优点：

- 比FCFS改善平均周转时间和平均带权周转时间，缩短作业的等待时间；
- 提高系统的吞吐量；

缺点：

- 必须预知作业的运行时间
- 对长作业非常不利，长作业的周转时间会明显地增长
- 在采用SJF算法时，人–机无法实现交互
- 该调度算法完全未考虑作业的紧迫程度，故不能保证紧迫性作业能得到及时处理

长作业有可能会饿死，处于一直等待短作业执行完毕的状态。因为如果一直有短作业到来，那么长作业永远得不到调度；该算法未开率作业的紧迫程度，不能保证紧迫作业被及时处理。

注意：短作业优先调度算法的平均等待时间、平均周转时间最少。

**最短剩余时间优先 shortest remaining time next（SRTN）**

最短作业优先的抢占式版本，按剩余运行时间的顺序进行调度。 当一个新的作业到达时，其整个运行时间与当前进程的剩余时间作比较。如果新的进程需要的时间更少，则挂起当前进程，运行新的进程。否则新的进程等待。

##### 2.4.优先级调度算法和高响应比优先调度算法

优先级调度算法（PSA）：略。

高响应比优先（HRRN）：

在每次选择作业投入运行时，先计算此时后备作业队列中每个作业的响应比RP然后选择其值最大的作业投入运行

优先权=(等待时间+要求服务时间)/要求服务时间=响应时间/要求服务时间=1+等待时间/要求服务时间

特点

- 如果作业的等待时间相同，则要求服务的时间愈短，其优先权愈高，因而类似于SJF算法，有利于短作业
- 当要求服务的时间相同时，作业的优先权又决定于其等待时间，因而该算法又类似于FCFS算法
- 对于长时间的优先级，可以为随等待时间的增加而提高，当等待时间足够长时，也可获得处理机

#### 3.进程调度

##### 3.1.进程调度的任务、机制和方式

任务：

- 保存处理机的现场信息；
- 按某种算法选取进程；
- 把处理器分配给进程。

机制：

- 排队器；
- 分派器；
- 上下文切换器。

调度方式：

- 非抢占式
- 抢占式
  - 优先权原则
  - 短进程优先原则
  - 时间片原则

**时间片轮转**

将所有就绪进程按 FCFS 的原则排成一个队列，每次调度时，把 CPU 时间分配给队首进程，该进程可以执行一个时间片。当时间片用完时，由计时器发出时钟中断，调度程序便停止该进程的执行，并将它送往就绪队列的末尾，同时继续把 CPU 时间分配给队首的进程。

时间片轮转算法的效率和时间片的大小有很大关系：

- 因为进程切换都要保存进程的信息并且载入新进程的信息，如果时间片太小，会导致进程切换得太频繁，在进程切换上就会花过多时间。
- 而如果时间片过长，那么实时性就不能得到保证。

##### 3.2.轮转调度算法

基本原理：在轮转(RR)法中，系统根据FCFS策略，将所有的就绪进程排成一个就绪队列，并可设置每隔一定时间间隔(如30ms)即产生一次中断，激活系统中的进程调度程序，完成一次调度，将CPU分配给队首进程，令其执行。

进程切换时机：

- 时间片未用完，进程完成
- 时间片到，进程未完成

时间片大小的确定：

- 太小利于短作业，增加系统切换开销
- 太长就退化为FCFS算法
- 一般选择: q略大于一次交互所需要的时间，使大多数进程在一个时间片内完成

一般来说，平均周转时间将比SJF长，但是有较好的响应时间

##### 3.3.优先级调度算法

优先级调度算法的类型：

- 非抢占式优先级调度算法
  - 等当前进程执行完以后，再执行另一个优先权最高的进程
  - 这种调度算法主要用于批处理系统中；也可用于某些对实时性要求不严的实时系统中。
- 抢占式优先级调度算法
  - 不等当前进程结束，直接抢处理机
  - 常用于要求比较严格的实时系统中， 以及对性能要求较高的批处理和分时系统中。

优先级的类型：

- 静态优先级
  - 优先权是在创建进程时确定的，且在进程的整个运行期间保持不变。一般地，优先权是利用某一范围内的一个整数来表示的，如0~255中的某一整数， 又把该整数称为优先数。
  - 可以参考BIOS系统中设置boot的优先级
- 动态优先级
  - 在创建进程时所赋予的优先权，是可以随进程的推进或随其等待时间的增加而改变的，以便获得更好的调度性能。

为每个进程分配一个优先级，按优先级进行调度。

为了防止低优先级的进程永远等不到调度，可以随着时间的推移增加等待进程的优先级。

##### 3.4.多队列调度算法

略

##### 3.5.多级反馈队列调度算法

调度机制

- 设置多个就绪队列
- 每个队列都采用FCFS算法
- 按照队列优先级调度，在第n队列中采取按时间片轮转的方式运行

调度算法的性能

- 对于终端型用户，由于作业小，感觉满意
- 对于短批处理作业用户，周转时间也较小
- 长批处理作业用户，也能够得到执行

一个进程需要执行 100 个时间片，如果采用时间片轮转调度算法，那么需要交换 100 次。

多级队列是为这种需要连续执行多个时间片的进程考虑，它设置了多个队列，每个队列时间片大小都不同，例如 1,2,4,8,..。进程在第一个队列没执行完，就会被移到下一个队列。这种方式下，之前的进程只需要交换 7 次。

每个队列优先权也不同，最上面的优先权最高。因此只有上一个队列没有进程在排队，才能调度当前队列上的进程。

可以将这种调度算法看成是时间片轮转调度算法和优先级调度算法的结合。

##### 3.6.基于公平原则的调度算法

- 保证调度算法
- 公平分享调度算法

#### 4.实时调度

实时系统要求一个请求在一个确定时间内得到响应。

分为硬实时和软实时，前者必须满足绝对的截止时间，后者可以容忍一定的超时。

##### 4.1.实现实时调度的基本条件

提供必要的信息：

- 就绪时间
- 开始截止时间和完成截止时间
- 处理时间
- 资源要求
- 优先级

系统处理能力强；

采用抢占式调度机制；

具有快速切换机制：

- 对中断的快速响应能力。
- 快速的任务分派能力。

##### 4.2.实时调度算法分类

非抢占式调度算法：

- 非抢占式轮转调度算法。
- 非抢占式优先调度算法。

抢占式调度算法：

- 基于时钟中断的抢占式优先级调度算法
- 立即抢占的优先级调度算法

##### 4.3.最早截止时间优先EDF算法

根据任务的开始截至时间来确定任务的优先级，截至时间越早，优先级越高，具有最早截止时间的任务排在队列首部。

非抢占式调度方式用于非周期实时任务；

抢占式调度方式用于周期实时任务；

##### 4.4.最低松弛度优先LLF算法

算法根据任务紧急(或松弛)的程度，来确定任务的优先级。任务的紧急程度愈高，为该任务所赋予的优先级就愈高， 以使之优先执行。

##### 4.5.优先级倒置

优先级倒置的形成：高优先级进程被低优先级进程延迟或阻塞。

解决方法：

- 简单的：假如进程P3在进入临界区后P3所占用的处理机就不允许被抢占
- 实用的：建立在动态优先级继承基础上的

#### 5.死锁概述

##### 5.1.资源问题

可重用性资源

- 计算机外设

消耗性资源

- 数据，消息

可抢占性资源

- 不会引起死锁
- CPU，内存

不可抢占性资源

- 光驱，打印机

##### 5.2.计算机系统中的死锁

- 竞争不可抢占性资源引起死锁
- 竞争可消耗资源引起死锁
- 进程推进顺序不当引起死锁

##### 5.3.死锁的定义、必要条件和处理方法

定义：如果一组进程中的每一个进程都在等待仅由该进程中的其他进程才能引发的事件，那么该组进程是死锁的。

产生死锁的必要条件：

- 互斥条件：每个资源要么已经分配给了一个进程，要么就是可用的。
- 请求和保持条件：已经得到了某个资源的进程可以再请求新的资源。
- 不可抢占条件：已经分配给一个进程的资源不能强制性地被抢占，它只能被占有它的进程显式地释放。
- 循环等待条件：有两个或者两个以上的进程组成一条环路，该环路中的每个进程都在等待下一个进程所占有的资源。

处理死锁的方法：

- 预防死锁
- 避免死锁
- 检测死锁
- 解除死锁

#### 6.预防死锁

预防的方法：通过破坏产生死锁的四个必要条件中的一个或几个，以避免发生死锁。

##### 6.1.破坏“请求和保持”条件

第一种协议：所有进程在开始运行之前，必须一次性地申请其在整个运行过程中所需的全部资源。

优点：简单，易行，安全。

缺点：

- 资源被严重浪费，严重地恶化了资源的利用率。
- 使进程经常会发生饥饿现象。

第二种协议：它允许一个进程只获得运行初期所需的资源后，便开始运行。进程运行过程中再逐步释放已分配给自己的，且已用毕的全部资源，然后再请求新的所需资源。

##### 6.2.破坏“不可抢占“条件

当一个已经保存了某些不可被抢占资源的进程，提出新的资源请求而不能得到满足时，它必须释放已经保持的所有资源，待以后需要时再重新申请。

##### 6.3.破坏“循环等待”条件

对系统所有资源类型进行线性排序，并赋予不同的序号。

例如令输入机的序号为1，打印机序号为2，磁盘机序号为3等。所有进程对资源的请求必须严格按资源序号递增的次序提出。

#### 7.避免死锁

##### 7.1.系统安全状态

安全状态：某时刻，对于并发执行的n个进程，若系统能够按照某种顺序如<p1,p2…pn>来为每个进程分配所需资源，直至最大需求，从而使每个进程都可顺利完成，则认为该时刻系统处于安全状态，这样的序列为安全序列。

安全状态例子：略。

由安全状态向不安全状态的转换：略。

##### 7.2.利用银行家算法避免死锁

含义：每一个新进程在进入系统时，它必须申明在运行过程中，可能需要每种资源类型的最大单元数目，其数目不应超过系统所拥有的资源总量。当进程请求一组资源时，系统必须首先确定是否有足够的资源分配给该进程。若有，再进一步计算在将这些资源分配给进程后，是否会使系统处于不安全状态。如果不会，才将资源分配给它，否则让进程等待

银行家算法中的数据结构：

- 可用资源向量 Available[m]：m为系统中资源种类数，Available[j]=k表示系统中第j类资源数为k个。
- 最大需求矩阵 Max[n,m]：n为系统中进程数，Max[i,j]=k表示进程i对j类资源的最大需求数为中k。
- 分配矩阵 Allocation[n，m]:它定义了系统中每一类资源当前已分配给每一进程资源数， Allocation[i,j] = k表示进程i已分得j类资源的数目为k个。
- 需求矩阵 Need[n,m]：它表示每个进程尚需的各类资源数，Need[i,j]=k 表示进程i 还需要j类资源k个。Need[i,j]=Max[i,j] - Allocation[i,j]

银行家算法：设如果Requesti是进程Pi的请求相量, 若Requesti[j] = K，表示进程Pi需要K个Ri类型的资源。当Pi发出资源请求后，系统按如下步骤进行检查：

- (1)、若Requesti[j] <= Need[i,j]，便转向步骤2；否则任务出错，因为它所需要的资源数已超过它所宣布的最大值。
- (2)、若Requesti[j] <= Available[j]，便转向步骤3；否则表示尚无足够资源，Pi须等待。
- (3)、系统试探着把资源分配给进程Pi，并修改下面数据结构中的数值：
  - Available[j] = Available[j] - Requesti[j];
  - Allocation[i,j] = Allocation[i,j] + Requesti[j];
  - Need[i,j] = Need[i,j] - Requesti[j];

- (4)、系统执行安全性算法，检查此次资源分配后系统是否处于安全状态；若安全，才正式将资源分配给进程Pi，以完成本次分配；否则，将本次的试探分配作废，回复原来的资源分配状态，让进程Pi等待。

安全性算法：略。

银行家算法之例：略。

#### 8.死锁的检测与解除

死锁检测算法：用于检测系统状态，以确定系统中是否发生了死锁。

死锁解除算法：该算法可将系统从死锁状态中解脱出来。

##### 8.1.死锁的检测

资源分配图：略。

S为死锁状态的充分条件是：当且仅当S状态的资源分配图是不可完全简化的。即死锁定理。

资源图完全简化：在经过一系列简化后，若能消除资源图中的索引边，使所有的进程节点都成为孤立节点，则称该图是可完全简化的。

死锁检测中的数据结构：略。

##### 8.2.死锁的解除

常采用的方法：

- 抢占资源：从一个或多个进程中抢占足够数量的资源，分配给死锁进程。以解除死锁状态。
- 终止（撤销）进程：终止（或撤销）系统中的一个或多个死锁进程，直至打破循环环路，使系统从死锁状态解脱出来。

终止进程的方法：

- 终止所有死锁进程
- 逐个终止进程：“代价最小”
  - 进程的优先级的大小
  - 进程已执行了多少时间，还需时间
  - 进程在运行中已经使用资源的多少，还需多少资源
  - 进程的性质是交互式还是批处理的

- 付出代价最小的死锁解除算法
  - 是使用一个有效的挂起和解除来挂起一些死锁的进程

### 四、存储器管理

#### 1.存储器的结构层次

##### 1.1,.多层结构的存储器系统

存储器的剁成结构：

- CPU寄存器
- 主存
- 辅存

可执行存储器：

- 寄存器和主存被称为可执行存储器
- 访问速度快，进程可以在很少的时钟周期内用一条load或store指令完成存取。

##### 1.2.主存储器与寄存器

略。

##### 1.3.告诉缓存和计算机磁盘缓存

略。

#### 2.程序的装入和链接

程序--->装入内存--->转换为可执行程序的步骤：

- 编译：编译程序（Compiler）执行。源程序 ->目标模块（Object modules）
  - 由编译程序对用户源程序进行编译，形成若干个目标模块
- 链接：链接程序（Linker）执行。一组目标模块 及库函数->装入模块 （Load Module）
  - 由链接程序将编译后形成的一组目标模板以及它们所需要的库函数链接在一起，形成一个完整的装入模块
- 装入：装入模块 ->内存 --------Loader
  - 由装入程序将装入模块装入内存

##### 2.1.程序的接入

绝对装入方式：用户程序经编译后，将产生绝对地址（即物理地址）的目标代码，绝对装入程序可按照装入模块中的地址，将程序和数据装入内存。

可重定位装入方式：在可执行文件中，列出各个需要重定位的地址单元和相对地址值。当用户程序被装入内存时，一次性实现逻辑地址到物理地址的转换，以后不再转换(一般在装入内存时由软件完成)。

动态运行时的装入方式：动态运行时的装入程序在把装入模块装入内存后，并不立即把装入模块中的逻辑地址转换为物理地址，而是把这种地址转换推迟到程序真正要执行时才进行.

##### 2.2..程序的链接

- 静态链接方式

- 装入时动态链接

- 运行时动态链接

#### 3.连续分配存储管理方式

##### 3.1.单一连续分配

##### 3.2.固定分区分配

##### 3.3.动态分区分配

##### 3.4.基于顺序搜索的动态分区分配算法

- 首次适应算法（first fit,FF）
- 循环首次适应算法（next fit，NF）
- 最佳适应算法（best fit，BF）
- 最坏适应算法（worst fit，WF）

##### 3.5.基于索引搜素的动态分区分配算法

- 快速适应算法（quick fit）
- 伙伴系统（buddy system）
- 哈希算法

##### 3.6.动态可重定位分区分配

#### 4.对换

系统把所有的作业放在外存，每次只调用一个作业进入内存运行，当时间片用完时，将它调至外存后备队列上等待，在从后备队列调入另一个作业进入内存运行。

#### 5.分页存储管理方式

##### 5.1.分页存储管理的基本方法

页面：将一个进程的逻辑地址空间分成若干个大小相等的片。

页框（frame）：内存空间分成与页面相同大小的存储块。

内存碎片：由于进程的最后一页经常装不满一块而形成了不可利用的碎片，称之为“页内碎片”

地址结构：页号P+位移量W(0-31)

页表：

- 在分页系统中，允许将进程的各个页离散地存储在内存在内存的任一物理块中，为保证进程仍然能够正确地运行，即能在内存中找到每一个页面所对应的物理块，系统又为每个进程建立了一张页面映像表，简称页表
- 页表的作用是实现从页面号到物理块号的地址映射

##### 5.2.地址变换机构

基本的地址变换机构

- 要访问两次内存
- 页表大都驻留在内存中
- 为了实现地址变换功能，在系统中设置页表寄存器（PTR），用来存放页表的始址和页表的长度。
- 在进程未执行时，每个进程对应的页表的始址和长度存放在进程的PCB中，当该进程被调度时，就将它们装入页表寄存器。

具有快表的地址变换机构

- 提高了效率，此处会有计算题
- 如果页表存放在内存中，则每次访问内存时，都要先访问内存中的页表，然后根据所形成的物理地址再访问内存。这样CPU存一个数据必须访问两次内存，从而使计算机的处理速度降低了1/2。
- 为了提高地址变换的速度，在地址变换机构中增设了一个具有并行查询功能的特殊的高速缓冲存储器，称为“联想存储器”或“快表”，用以存放当前访问的那些页表项。
- 地址变换过程为：
  - 1、CPU给出有效地址
  - 2、地址变换机构自动地将页号送入高速缓存，确定所需要的页是否在快表中。
  - 3、若是，则直接读出该页所对应的物理块号，送入物理地址寄存器；
  - 4、若快表中未找到对应的页表项，则需再访问内存中的页表
  - 5、找到后，把从页表中读出的页表项存入快表中的一个寄存器单元中，以取代一个旧的页表项。

##### 5.3.访问内存的有效时间

##### 5.4.两级和多级页表

- 主要是有的时候页表太多了，要化简
- 格式：外层页号P1+外层页内地址P2+页内地址d
- 基本方法：将页表进行分页，每个页面的大小与内存物理块的大小相同，并为它们进行编号，可以离散地将各个页面分别存放在不同的物理块中。

##### 5.5.反置页表

反置页表为每一个物理块（页框）设置一个页表项，并按物理块排序，其内容则是页号和其所属进程的标识。

#### 6.分段存储管理方式

##### 6.1.分段存储管理方式的引入

- 方便编程
- 信息共享
- 动态增长
- 动态链接

在分段存储管理方式中，作业的地址空间被划分为若干个段，每个段是一组完整的逻辑信息，每个段都有自己的名字，都是从零开始编址的一段连续的地址空间，各段长度是不等的。

内存空间被动态的划分为若干个长度不相同的区域，称为物理段，每个物理段由起始地址和长度确定

##### 6.2.分段系统的基本原理

- 分段：格式：段号+段内地址
- 段表：段表实现了从逻辑段到物理内存区的映射。
- 地址变换机构

和分页的区别：

- 页是信息的物理单位
- 页的大小固定且由系统固定
- 分页的用户程序地址空间是一维的
- 通常段比页大，因而段表比页表短，可以缩短查找时间，提高访问速度。
- 分页是系统管理的需要，分段是用户应用的需要。一条指令或一个操作数可能会跨越两个页的分界处，而不会跨越两个段的分界处。

##### 6.3.信息共享

这是分段最重要的优点

##### 6.4.段页式存储管理

- 基本原理：格式：段号（S）+段内页号（P）+页内地址（W）
- 地址变换过程：需要三次访问过程
- 在段页式系统中，为了获得一条指令或数据，需三次访问内存：第一次访问内存中的段表，从中取得页表始址；第二次访问内存中的页表，从中取出该页所在的物理块号，并将该块号与页内地址一起形成指令或数据的物理地址；第三次访问才是真正根据所得的物理地址取出指令或数据。

### 五、虚拟存储器

#### 1、虚拟存储器概述

##### 1.1.常规存储器管理方式的特征和局部性原理

特征：

- 一次性
- 驻留性

局部性原理：程序在执行时将呈现出局部性特征，即在一较短的时间内，程序的执行仅局限于某个部分，相应地，它所访问的存储空间也局限于某个区域。

- 时间局限性：如果程序中的某条指令一旦执行， 则不久以后该指令可能再次执行；如果某数据被访问过， 则不久以后该数据可能再次被访问。产生时间局限性的典型原因，是由于在程序中存在着大量的循环操作
- 空间局限性：一旦程序访问了某个存储单元，在不久之后，其附近的存储单元也将被访问，即程序在一段时间内所访问的地址，可能集中在一定的范围之内，其典型情况便是程序的顺序执行。

##### 1.2.虚拟存储器的定义和特征

定义：指具有请求调入功能和置换功能，能从逻辑上对内存容量加以扩充的一种存储器系统

特征：

- 多次性
- 对换性
- 虚拟性

##### 1.3.虚拟存储器的实现方法

- 分页请求系统
- 请求分段系统

#### 2、请求分页存储管理方式

##### 2.1.硬件支持

请求页表机制：格式：页号+物理块号+状态位P+访问字段A+修改位M+外存地址。

缺页中断机构。

地址变换机构（过程图很关键）。

##### 2.2.内存分配

最小物理块数的确定：即能保证进程正常运行所需的最小物理块数。

内存分配策略：

- 固定分配局部置换（国王的大儿子）
- 可变分配全局置换（国王的二儿子）
- 可变分配局部置换（国王的小儿子）

物理块分配算法：

- 平均分配算法
- 按比例分配算法
- 考虑优先权的分配算法

##### 2.3.页面调入策略

何时调入页面：

- 预调页策略（未实现）
- 请求调页策略（需要才给）

从何处调入页面：

- 对换区
- 文件区

页面调入过程：略。

缺页率：f=F/A。F为访问页面失败的次数，A=S+F，S为访问页面成功的次数。

#### 3、页面置换算法

##### 3.1.最佳置换算法和先进先出置换算法

**最佳置换算法**：

> OPT, Optimal replacement algorithm

所选择的被换出的页面将是最长时间内不再被访问，通常可以保证获得最低的缺页率。

是一种理论上的算法，因为无法知道一个页面多长时间不再被访问。

**先进先出（FIFO）页面置换算法**：选择在内存中驻留时间最久的页面予以淘汰。

##### 3.2.最近最久未使用和最少使用置换算法

**最近最久未使用置换算法**（LRU）：

> LRU, Least Recently Used

虽然无法知道将来要使用的页面情况，但是可以知道过去使用页面的情况。LRU 将最近最久未使用的页面换出。

为了实现 LRU，需要在内存中维护一个所有页面的链表。当一个页面被访问时，将这个页面移到链表表头。这样就能保证链表表尾的页面是最近最久未访问的。

因为每次访问都需要更新链表，因此这种方式实现的 LRU 代价很高。

**最少使用置换算法**（LFU）

##### 3.3.Clock算法

LRU的近似算法。

##### 3.4.页面缓冲算法（PBA)

##### 3.5.访问内存的有效时间

#### 4、“抖动”与工作集

抖动的概念：即刚被换出的页很快又要被访问，需要将它重新调入，此时又需要再选一页调出。

#### 5、请求分段存储管理方式

##### 5.1.硬件支持

- 段表机制
- 缺段中断机构
- 地址变换机构

##### 5.2.分段的共享与保护

共享段表

### 六、输入输出系统

#### 1、I/O系统的功能、模型和接口

I/O系统管理的对象是I/O设备和相应的设备控制器。

##### 1.1.基本功能

- 隐藏物理设备的细节
- 与设备的无关性
- 提高处理机和I/O设备的利用率
- 对I/O设备进行控制
- 确保对设备的正确共享
- 错误处理

##### 1.2.层次结构和模型

层次结构：

- 用户层I/O软件
- 设备独立性软件
- 设备驱动程序（厂家开发）
- 中断处理程序
- 硬件

I/O系统的分层：

- 中断处理程序：I/O系统的底层，直接与硬件交互。
- 设备驱动程序：I/O系统的次底层，是进程和设备控制器之间的通信程序。
- 设备独立性软件

##### 1.3.接口

块设备接口：指以数据块为单位来组织和传送数据信息的设备，典型的块设备是磁盘、光盘。

流设备接口：又称字符设备指以单个字符为单位来传送数据信息的设备，这类设备一般用于数据的输入和输出，有交互式终端、打印机。

网络通信接口：提供网络接入功能，使计算机能通过网络与其他计算机进行通信或上网浏览。

#### 2、I/O设备和设备控制器

##### 2.1.I/O设备

类型：

- 按使用特性分类：
  - 存储设备：也称外存、辅存，存储信息的主要设备。
  - I/O设备。
- 传输速率分类：
  - 低速设备：（几字节——几百字节），典型的设备有键盘、鼠标、语音的输入。
  - 中速设备：（数千——数万字节），典型的设备有行式打印机、激光打印机。
  - 高速设备：（数十万——千兆字节），典型的设备有磁带机、磁盘机、光盘机。

通常，设备并不是直接与CPU进行通信，而是与设备控制器通信。在设备与设备控制器之间应该有一个接口。

##### 2.2.设备控制器

主要功能：控制一个或多个I/O设备，以实现I/O设备和计算机之间的数据交换。

基本功能：

- 接收和识别命令：控制寄存器、命令译码器
- 数据交换：实现CPU与控制器，控制器与设备间的数据交换
- 标识和报告设备的状态
- 地址识别：配置地址译码器，识别不同的设备
- 数据缓冲区
- 差错控制

设备控制器的组成：

- 设备控制器与处理机（CPU）的接口：实现CPU与设备控制器之间的通信。
- 设备控制器与设备的接口：控制器可连接多个设备。
- I/O逻辑
  - 实现对设备的控制
  - CPU利用该逻辑向控制器发送I/O命令
  - 命令、地址译码

##### 2.3.内存映像I/O

驱动程序将抽象I/O命令转换出的一系列具体的命令，参数等数据装入设备控制器的相应寄存器，由控制器来执行这些命令，具体实施对I/O设备的操作。

##### 2.4.I/O通道

目的：建立独立的I/O操作(组织, 管理和结束)，使由CPU处理的I/O工作转由通道完成（解放CPU，实现并行）。

什么是I/O通道？

- 是一种特殊的处理机，具有通过执行通道程序完成I/O操作的指令
- 特点：指令单一(局限于与I/O操作相关的指令)，与CPU共享内存

基本过程：CPU向通道发出I/O指令->通道接收指令->从内存取出通道程序处理I/O->向CPU发出中断

通道类型：

- 字节多路通道
  - 低中速连接子通道时间片轮转方式共享主通道
  - 字节多路通道不适于连接高速设备，这推动了按数组方式进行数据传送的数组选择通道的形成。
- 数组选择通道
  - 这种通道可以连接多台高速设备，但只含有一个分配型子通道，在一段时间内只能执行一道通道程序， 控制一台设备进行数据传送， 直至该设备传送完毕释放该通道。这种通道的利用率很低。
- 数组多路通道
  - 含有多个非分配型子通道，前两种通道的组合，通道利用率较好

瓶颈问题

- 原因;通道不足
- 解决办法：增加设备到主机间的通路，而不增加通道（结果类似RS触发器）

#### 3、中断机构和中断处理程序

##### 3.1.中断简介

中断：指CPU对I/O设备发来的中断信号的一种响应。由于中断是外部设备引起的，故又称为外中断。

陷入：CPU内部事件所引起的中断。

中断向量表：中断程序的入口地址表。

中断优先级：对紧急程度不同的中断处理方式。

对多中断源的处理方式：

- 屏蔽中断
- 嵌套中断

##### 3.2.中断处理程序

中断处理程序的处理过程：

- 测定是否有未响应的中断信号
- 保护被中断进程的CPU环境
- 转入相应的设备处理程序
- 中断处理
- 恢复CPU 的现场并退出中断

#### 4、设备驱动程序

是I/O进程与设备控制器之间的通信程序，又由于它常以进程的形式存在，故以后就简称为设备驱动进程

主要任务是接受来自它上一层的与设备无关软件的抽象请求，并执行这个请求。

##### 4.1.概述

设备驱动程序的功能：

- 接收由I/O进程发来的命令和参数， 并将命令中的抽象要求转换为具体要求。例如，将磁盘块号转换为磁盘的盘面、 磁道号及扇区号。
- 检查用户I/O请求的合法性，了解I/O设备的状态，传递有关参数，设置设备的工作方式。
- 发出I/O命令，如果设备空闲，便立即启动I/O设备去完成指定的I/O操作；如果设备处于忙碌状态，则将请求者的请求块挂在设备队列上等待。
- 及时响应由控制器或通道发来的中断请求，并根据其中断类型调用相应的中断处理程序进行处理。
- 对于设置有通道的计算机系统，驱动程序还应能够根据用户的I/O请求，自动地构成通道程序。

##### 4.2.处理过程

- 将抽象要求转换成具体要求。
- 对服务请求进行校验。
- 检查设备状态，确保设备处于就绪态。
- 传送必要的参数。
- 启动I/O设备。

##### 4.3.对I/O设备的控制方式

I/O控制的宗旨:

- 减少CPU对I/O控制的干预
- 充分利用CPU完成数据处理工作

I/O 控制方式

- 轮询的可编程I/O方式
- 中断驱动I/O方式
- DMA控制方式
- I/O通道控制方式

DMA控制器组成

- 主机与DMA控制器的接口
- DMA控制器与块设备的接口
- I/O控制逻辑

#### 5、与设备无关的I/O软件

##### 5.1.基本概念

含义： 应用程序独立于具体使用的物理设备。

驱动程序是一个与硬件(或设备)紧密相关的软件。为实现设备独立性，须在驱动程序上设置一层软件，称为设备独立性软件。

设备独立性(Device Independence)的优点

- 以物理设备名使用设备
- 引入了逻辑设备名
- 逻辑设备名称到物理设备名称的转换（易于实现I/O重定向）

##### 5.2.与设备无关的软件

- 设备驱动程序的统一接口
- 缓冲管理
- 差错控制
- 对独立设备的分配与回收
- 独立于设备的逻辑数据块

##### 5.3.设备分配

设备分配中的数据结构：

- 设备控制表DCT
- 控制器控制表COCT
- 通道控制表CHCT
- 显然，在有通道的系统中，一个进程只有获得了通道，控制器和所需设备三者之后，才具备了进行I/O操作的物理条件
- 系统设备表SDT
- 逻辑设备表LUT
- 分配的流程，从资源多的到资源紧张的:LUT->SDT->DCT->COCT->CHCT
- 在申请设备的过程中，根据用户请求的I/O设备的逻辑名，查找逻辑设备和物理设备的映射表；以物理设备为索引，查找SDT，找到该设备所连接的DCT；继续查找与该设备连接的COCT和CHCT，就找到了一条通路。

##### 5.4.逻辑设备名到物理设备名映射的实现

略。

#### 6、用户层的I/O软件

##### 6.1.系统调用与库函数

- OS向用户提供的所有功能，用户进程都必须通过系统调用来获取
- 在C语言以及UNIX系统中，系统调用（如read）与各系统调用所使用的库函数（如read）之间几乎是一一对应的。而微软了一套过程，的叫Win 32API的应用程序接口，该接口与实际的系统调用并不一一对应，用户通过调用对用的库函数使用系统调用。

##### 6.2.假脱机系统

spooling技术是对脱机输入/输出系统的模拟。

主要组成：

- 输入/输出井
- 输入/输出缓冲区
- 输入/输出进程
- 井管理程序

特点（体现操作系统的虚拟性）：

- 提高了I/O的速度
  - 对数据所进行的I/O操作，已从对低速设备演变为对输入井或输出井中的数据存取。
- 将独占设备改造为共享设备
  - 实际分给用户进程的不是打印设备，而是共享输出井中的存储区域
- 实现了虚拟设备功能
  - 将独占设备变成多台独占的虚拟设备。

#### 7、缓冲区管理

##### 7.1.缓冲的引入

引入的原因：

- 缓和CPU与I/O设备间速度不匹配的矛盾
- 减少对CPU的中断频率，放宽对CPU中断响应时间的限制
- 解决数据粒度不匹配的问题
- 提高CPU和I/O设备之间的并行性

##### 7.2.单缓冲区和双缓冲区

单缓冲区：即在CPU计算的时候，将数据数据输入到缓冲区(大小取决与T和C的大小)。

双缓冲区：即允许CPU连续工作（T不断）。

##### 7.3.环形缓冲区

（为生产者和消费者打造。）

组成：

- 多个缓冲区
- 多个指针

使用：

- Getbuf过程
- Releasebuf过程

同步问题

##### 7.4.缓冲池

组成：

- 空白缓冲队列（emq）
  - 由空缓冲区链接而成F(emq)，L(emq)分别指向该队列首尾缓冲区
- 输入队列（inq）
  - 由装满输入数据的缓冲区链接而成F(inq)，L(inq)分别指向该队列首尾缓冲区
- 输出队列（outq）
  - 由装满输出数据的缓冲区链接而成F(outq)， L(outq)分别指向该队列首尾缓冲

Getbuf和Putbuf过程

- 收容：缓冲池接收外界数据
- 提取：外界从缓冲池获得数据

缓冲区工作方式（从缓冲区的角度来看）：

- 收容输入
- 提取输入
- 收容输出
- 提取输出

#### 8、磁盘存储器的性能和调度

##### 8.1.磁盘性能简述

数据的组织和格式：略。

磁盘的类型：

- 固定头磁盘（贵）
- 移动头磁盘

磁盘访问的时间（关键）：

- 寻道时间Ts=m*n+s
- 旋转延迟时间Tr
- 传输时间Tt=b/rN
- 总时间Ta=Ts+1/2r+b/rN

##### 8.2.早期的磁盘调度算法

先来先服务（FCFS）

- 优点：公平，简单
- 缺点：可能导致某些进程的请求长期得不到满足

最短寻道时间优先（SSTF）：

- 说明：要求访问的磁道和当前磁头所在的磁道距离最近，以使每次的寻道时间最短

##### 8.3.基于扫描的磁盘调度算法

扫描算法（SCAN）

- 扫描算法不仅考虑到欲访问的磁道与当前磁道间的距离，更优先考虑的是磁道当前的移动方向
- 联想电梯的运行
- 可防止低优先级进程出现“饥饿”的现象

循环扫描算法（CSCAN）

- 算法规定磁头单向移动，例如，只是自里向外移动，当磁头移到最外的磁道并访问后，磁头立即返回到最里的欲访问磁道，亦即将最小磁道号紧接着最大磁道号构成循环，进行循环扫描

NStepScan算法

- N步SCAN算法是将磁盘请求队列分成若干个长度为N的子队列，磁盘调度将按FCFS算法依次这些子队列。

FSCAN算法

- 是Nstepscan算法的简化，将磁盘请求队列分成两个子队列

### 七、文件管理

#### 1、文件和文件系统

##### 1.1.数据项、记录和文件

数据项：最低价的数据组织形式。

- 基本数据项

- 组合数据项

记录：记录是一组相关数据项的集合，用于描述一个对象在某个方面的属性。

文件：指由创建者所定义的具有文件名的一组相关元素集合。

##### 1.2.文件名和类型

文件类型：

- 按用途分类：
  - 系统文件
  - 用户文件
  - 库文件
- 按文件中数据的形式分类：
  - 源文件
  - 目标文件
  - 可执行文件
- 按存取控制属性分类：
  - 只执行文件
  - 只读文件
  - 读写文件
- 按组织形式和处理方式分类：
  - 普通文件
  - 目录文件
  - 特殊文件

##### 1.3.文件系统的层次结构

略

##### 1.4.文件操作

最基本的文件操作：

- 创建文件

- 删除文件

- 读文件

- 写文件

- 设置文件读写的位置

#### 2、文件的逻辑结构

顺序文件

记录寻址

索引文件

索引顺序文件

直接文件和哈希文件

#### 3、文件目录

##### 3.1.文件控制块和索引结点

文件控制块（FCB）：文件名+inode(属性)。



##### 3.2.简单的文件目录

- 单级文件目录
  - 查找慢
  - 不允许重名
  - 不便于实现文件共享
- 两级文件目录
  - 提高检索速度，从M*N到M+N

##### 3.3.树形结构目录

路径名：

- “..”是父目录
- “/”是根目录
- 区别绝对路径和相对路径（../.../.../1/2/3/）

##### 3.4.目录查询技术

略

#### 4、文件共享

##### 4.1.基于邮箱五循环图实现文件共享

略

##### 4.2.利用符号链接实现文件共享

实际上就是“快捷方式”

#### 5、文件保护

略

### 八、磁盘存储器的管理

#### 1、外存的组织方式

外存的组织方式：

- 连续组织方式
- 链接组织方式
- 索引组织方式

连续组织方式：又称连续分配方式，要求为每一个文件分配相临接的盘快。

- 优点：
  - 顺序访问容易
  - 顺序访问速度快
- 缺点：
  - 要求为一个文件分配连续的存储空间。
  - 必须实现知道文件的长度。
  - 不能灵活的插入和删除记录。
  - 针对动态增长的文件，很难为其分配空间。

链接组织方式：

- 优点：
  - 消除磁盘的外部碎片，提供外存利用率。
  - 对插入、删除和修改记录非常容易。
  - 能适应文件的动态增长，无需事先知道文件的大小。
- 链接方式的分类：
  - 隐式链接
  - 显示链接

FAT技术：

- FAT12
- FAT16
- FAT32

NTFS的文件组织方式：以簇作为磁盘空间分配和回收的基本单位。

索引组织方式：

- 单级索引组织方式
- 多级索引组织方式
- 增量式索引组织方式

#### 2、文件存储空间的管理

空闲表法：

空闲链表法：

位示图法：

成组链接法：

#### 3、提高磁盘I/O速度的途径

- 磁盘高速缓存
- 提前读
- 延迟写
- 优化物理块的分布
- 虚拟盘
- 廉价磁盘冗余阵列(RAID)：并行交叉存取
  - RAID共分7级
  - 优点：
    - 可靠性高
    - 磁盘I/O速度高
    - 性能/价格比高

#### 4、提高磁盘可靠性的技术

第一级容错技术SFT-1：

- 双份目录文件和双份文件分配表；
- 热修复重定向和写后读校验。

第二级容错技术SFT-2：

- 磁盘镜像
- 磁盘双工

基于集群技术的容错功能：

- 双机热备份模式；
- 双机互为备份模式；
- 公用磁盘模式。

后备系统：常用的有：

- 磁带机
- 磁盘
- 光盘驱动器

#### 5、数据一致性控制

事务：

事务记录：

- 事务名
- 数据项名
- 旧值
- 新值

恢复算法：

- undo <Ti>：把所有被事务Ti修改过的数据恢复为修改前的值。
- redo <Ti>：把所有被事务Ti修改过的数据设置为新值。

检查点(Check Points)的作用：略

并发控制：

- 利用互斥锁实现“顺序性”
- 利用互斥锁和共享锁实现顺序性

重复数据的数据一致性问题：略

### 九、操作系统接口

#### 1、用户接口

字符显示式联机用户接口

图形化联机用户接口

联机命令的类型：

- 系统访问类
- 文件操作命令
- 目录操作命令
- 其他命令
  - 输入输出重定向命令
  - 管道连接
  - 过滤命令
  - 批命令

#### 2、Shell命令语言

特点：

- 作为命令语言
- 作为程序设计语言
- 作为命令解释器

简单命令的格式：略。

简单命令的分类：

- 系统提供的标准命令
- 用户自定义的命令

根据命令是否包含在Shell内部分为：

- 内部命令
- 外部命令

Shell的种类：

- Bourne Shell
- C Shell
- Korn Shell

简单命令的类型(根据功能的不同)：

- 进入与退出系统
- 文件操作命令
- 目录操作命令
- 系统询问命令

重定向与管道命令：略。

通信命令：

- 信箱通信命令mail：
- 对话通信命令write：
- 允许或拒绝接受消息的mesg命令：

后台命令：略

#### 3、联机命令接口的实现

键盘终端处理程序：

- 字符接收功能
- 字符缓冲功能
- 回送显示
- 屏幕编辑
- 终端字符处理

MS-DOS解释程序：

- 命令解释程序的作用：主要作用是在屏幕上给出提示符，请用户键入命令，然后读入该命令，识别命令，再转到相应命令处理程序的入口地址，把控制权交给该处理程序去执行。
- 组成：
  - 常驻部分
  - 初始化部分
  - 暂存部分
- 工作流程：略

Shell命令的特点：

- 一条命令行中含有多个命令
- 具有不同的分隔符

Linux命令解释程序的工作流程：

- 读取用户键盘输入的命令行
- 对命令进行分析
- 建立相应的子程序
- 等待子进程完成
- 对于"&"型结点，在启动其左子节点执行后，因它是后台命令，不需要等待，因此终端进程不用系统调用Wait4()，而是再执行其右子树。

#### 4、系统调用的概念和类型

计算机系统中的两种状态：

- 系统态
- 用户态

系统调用的类型：

- 进程控制类
- 文件操作类
- 进程通信类

POSIX标准：略。

#### 5、UNIX系统调用

略

#### 6、系统调用的实现

略。

### 十、多处理机操作系统

#### 1、多处理机系统的基本概念

引入的原因：

- 增加系统吞吐量
- 节省投资
- 提高系统可靠性

多处理机系统的类型：

- 紧密耦合MPS和松弛耦合MPS
- 对称处理器系统和非对称处理器系统

#### 2、多处理机系统的结构

略

#### 3、多处理机系统的特征与分类

特征：

- 并行性
- 分布性
- 机间的通信和同步性
- 可重构性

多处理机操作系统的功能：

- 进程管理
- 存储器管理
- 文件管理
- 系统重构

类型：

- 主从式(master-slave)
- 独立监督式
- 浮动监督式

#### 4、进程同步

集中式与分布式同步方式：

- 中心同步实体
- 集中式同步机构
- 集中式与分布式同步算法
- 中心进程方式

自旋锁类型：

- 普通自旋锁
- 读写自旋锁
- 大读者自旋锁

二进制指数补偿算法：

待锁CPU等待队列机构：

定序机构：

- 时间邮戳定序机构
- 事件计数同步机构

面包房算法：略

令牌环算法：略

#### 5、多处理机系统的进程调度

评价调度性能的若干因素：

- 任务流时间
- 调度流时间
- 平均流
- 处理机利用率
- 加速比
- 吞吐率

进程分配方式：

- 对称多处理机系统中的进程分配方式
- 非对称MPS中的进程分配方式

进程（线程）调度方式：

- 自调度方式
- 成组调度方式
- 专用处理机分配
- 动态调度

#### 6、网络操作系统

定义：是在计算机网络环境下，对网络资源进行管理和控制，实现数据通信及对网络资源的共享，为用户提供与网络资源之间接口的一组软件和规程的集合。

特征：

- 硬件独立性
- 接口一致性
- 资源透明性
- 系统可靠性
- 执行并行性

- 通信子网
- 资源子网
- 网络协议

网络操作系统的分类：

- 对等模式
- 工作站/服务器模式
- 客户/服务器模式(Client/Server model)
- 浏览器/服务器模式(Browser/Server model)

功能：

- 数据通信
- 应用互操作
- 网络管理

#### 7、分布式文件系统

分布式系统的特征：

- 分布性
- 透明性
- 同一性
- 全局性

分布式系统的优点：

- 计算能力强
- 易于实现共享
- 方便通信
- 可靠性高
- 可扩充性好

分布式文件系统的实现方式：

- DFS的实现方式
  - 共享文件系统方式
  - 共享磁盘方式

### 十一、多媒体系统

#### 1、多媒体系统简介

略

#### 2、多媒体文件中的各种媒体

略

#### 3、多媒体进程管理中的问题和接纳控制

略

#### 4、多媒体实时调度

略

#### 5、媒体服务器的特征和接纳控制

略

#### 6、多媒体存储器的分配方法

略

#### 7、高速缓存和磁盘调度

略

### 十二、保护和安全

#### 1、安全环境

略

#### 2、数据加密技术

略

#### 3、用户验证

略

#### 4、来自系统内部的攻击

略

#### 5、来自系统外部的攻击

略

#### 6、可信系统

略



### 十三、面试题

#### 1、进程与线程的区别

Ⅰ 拥有资源

进程是资源分配的基本单位，但是线程不拥有资源,而是仅有一点必不可少的、能保证独立运行的资源（如TCB/程序计数器/寄存器和堆栈），线程可以访问隶属进程的资源。

Ⅱ 调度

线程是调度的基本单位，在同一进程中，线程的切换不会引起进程切换，从一个进程中的线程切换到另一个进程中的线程时，会引起进程切换。

Ⅲ 系统开销

由于创建或撤销进程时，系统都要为之分配或回收资源，如内存空间、I/O 设备等，所付出的开销远大于创建或撤销线程时的开销。类似地，在进行进程切换时，涉及当前执行进程 CPU 环境的保存及新调度进程 CPU 环境的设置，而线程切换时只需保存和设置少量寄存器内容，开销很小。

Ⅳ 通信方面

线程间可以通过直接读写同一进程中的数据进行通信，但是进程通信需要借助 IPC（进程间通信）。

应该注意以下内容：

- 只有就绪态和运行态可以相互转换，其它的都是单向转换。就绪状态的进程通过调度算法从而获得 CPU 时间，转为运行状态；而运行状态的进程，在分配给它的 CPU 时间片用完之后就会转为就绪状态，等待下一次调度。
- 阻塞状态是缺少需要的资源从而由运行状态转换而来，但是该资源不包括 CPU 时间，缺少 CPU 时间会从运行态转换为就绪态。

V 并发性：不仅进程之间可以并发执行，同一个进程的多个线程之间也可并发执行，不同进程中线程也能并发执行。

#### 2、进程、线程通信方式

##### 2.1、进程通信方式

1.管道：速度慢，容量有限，只有父子进程能通讯    

2.FIFO：任何进程间都能通讯，但速度慢    

3.消息队列：容量受到系统限制，且要注意第一次读的时候，要考虑上一次没有读完数据的问题    

4.信号量：不能传递复杂消息，只能用来同步    

5.共享内存区：能够很容易控制容量，速度快，但要保持同步，比如一个进程在写的时候，另一个进程要注意读写的问题，相当于线程中的线程安全，当然，共享内存区同样可以用作线程间通讯，不过没这个必要，线程间本来就已经共享了同一进程内的一块内存



---

## 以下为旧版本---

#### 进程与线程

##### 3.区别

Ⅰ 拥有资源

进程是资源分配的基本单位，但是线程不拥有资源，线程可以访问隶属进程的资源。

Ⅱ 调度

线程是独立调度的基本单位，在同一进程中，线程的切换不会引起进程切换，从一个进程中的线程切换到另一个进程中的线程时，会引起进程切换。

Ⅲ 系统开销

由于创建或撤销进程时，系统都要为之分配或回收资源，如内存空间、I/O 设备等，所付出的开销远大于创建或撤销线程时的开销。类似地，在进行进程切换时，涉及当前执行进程 CPU 环境的保存及新调度进程 CPU 环境的设置，而线程切换时只需保存和设置少量寄存器内容，开销很小。

Ⅳ 通信方面

线程间可以通过直接读写同一进程中的数据进行通信，但是进程通信需要借助 IPC（进程间通信）。

应该注意以下内容：

- 只有就绪态和运行态可以相互转换，其它的都是单向转换。就绪状态的进程通过调度算法从而获得 CPU 时间，转为运行状态；而运行状态的进程，在分配给它的 CPU 时间片用完之后就会转为就绪状态，等待下一次调度。
- 阻塞状态是缺少需要的资源从而由运行状态转换而来，但是该资源不包括 CPU 时间，缺少 CPU 时间会从运行态转换为就绪态。

#### 进程调度算法

不同环境的调度算法目标不同，因此需要针对不同环境来讨论调度算法。

##### 1.批处理系统

批处理系统没有太多的用户操作，在该系统中，调度算法目标是保证吞吐量和周转时间（从提交到终止的时间）。

**1.1 先来先服务 first-come first-serverd（FCFS）**

非抢占式的调度算法，按照请求的顺序进行调度。

有利于长作业，但不利于短作业，因为短作业必须一直等待前面的长作业执行完毕才能执行，而长作业又需要执行很长时间，造成了短作业等待时间过长；算法简单，但效率低；有利于CPU繁忙型，不利于I/O繁忙型。

**1.2 短作业优先 shortest job first（SJF）**

非抢占式的调度算法，按估计运行时间最短的顺序进行调度。

长作业有可能会饿死，处于一直等待短作业执行完毕的状态。因为如果一直有短作业到来，那么长作业永远得不到调度；该算法未开率作业的紧迫程度，不能保证紧迫作业被及时处理。

注意：短作业优先调度算法的平均等待时间、平均周转时间最少。

**1.3 最短剩余时间优先 shortest remaining time next（SRTN）**

最短作业优先的抢占式版本，按剩余运行时间的顺序进行调度。 当一个新的作业到达时，其整个运行时间与当前进程的剩余时间作比较。如果新的进程需要的时间更少，则挂起当前进程，运行新的进程。否则新的进程等待。

##### 2.交互式系统

交互式系统有大量的用户交互操作，在该系统中调度算法的目标是快速地进行响应。

**2.1 时间片轮转**

将所有就绪进程按 FCFS 的原则排成一个队列，每次调度时，把 CPU 时间分配给队首进程，该进程可以执行一个时间片。当时间片用完时，由计时器发出时钟中断，调度程序便停止该进程的执行，并将它送往就绪队列的末尾，同时继续把 CPU 时间分配给队首的进程。

时间片轮转算法的效率和时间片的大小有很大关系：

- 因为进程切换都要保存进程的信息并且载入新进程的信息，如果时间片太小，会导致进程切换得太频繁，在进程切换上就会花过多时间。
- 而如果时间片过长，那么实时性就不能得到保证。

**2.2 优先级调度**

为每个进程分配一个优先级，按优先级进行调度。

为了防止低优先级的进程永远等不到调度，可以随着时间的推移增加等待进程的优先级。

**2.3 多级反馈队列**

一个进程需要执行 100 个时间片，如果采用时间片轮转调度算法，那么需要交换 100 次。

多级队列是为这种需要连续执行多个时间片的进程考虑，它设置了多个队列，每个队列时间片大小都不同，例如 1,2,4,8,..。进程在第一个队列没执行完，就会被移到下一个队列。这种方式下，之前的进程只需要交换 7 次。

每个队列优先权也不同，最上面的优先权最高。因此只有上一个队列没有进程在排队，才能调度当前队列上的进程。

可以将这种调度算法看成是时间片轮转调度算法和优先级调度算法的结合。

##### 3.实时系统

实时系统要求一个请求在一个确定时间内得到响应。

分为硬实时和软实时，前者必须满足绝对的截止时间，后者可以容忍一定的超时。

#### 进程同步

##### 3.信号量

信号量（Semaphore）是一个整型变量，可以对其执行 down 和 up 操作，也就是常见的 P 和 V 操作。

- **down** : 如果信号量大于 0 ，执行 -1 操作；如果信号量等于 0，进程睡眠，等待信号量大于 0；
- **up** ：对信号量执行 +1 操作，唤醒睡眠的进程让其完成 down 操作。

down 和 up 操作需要被设计成原语，不可分割，通常的做法是在执行这些操作的时候屏蔽中断。

如果信号量的取值只能为 0 或者 1，那么就成为了 **互斥量（Mutex）** ，0 表示临界区已经加锁，1 表示临界区解锁。

```
typedef int semaphore;
semaphore mutex = 1;
void P1() {
    down(&mutex);
    // 临界区
    up(&mutex);
}

void P2() {
    down(&mutex);
    // 临界区
    up(&mutex);
}
```

**使用信号量实现生产者-消费者问题**

问题描述：使用一个缓冲区来保存物品，只有缓冲区没有满，生产者才可以放入物品；只有缓冲区不为空，消费者才可以拿走物品。

因为缓冲区属于临界资源，因此需要使用一个互斥量 mutex 来控制对缓冲区的互斥访问。

为了同步生产者和消费者的行为，需要记录缓冲区中物品的数量。数量可以使用信号量来进行统计，这里需要使用两个信号量：empty 记录空缓冲区的数量，full 记录满缓冲区的数量。其中，empty 信号量是在生产者进程中使用，当 empty 不为 0 时，生产者才可以放入物品；full 信号量是在消费者进程中使用，当 full 信号量不为 0 时，消费者才可以取走物品。

注意，不能先对缓冲区进行加锁，再测试信号量。也就是说，不能先执行 down(mutex) 再执行 down(empty)。如果这么做了，那么可能会出现这种情况：生产者对缓冲区加锁后，执行 down(empty) 操作，发现 empty = 0，此时生产者睡眠。消费者不能进入临界区，因为生产者对缓冲区加锁了，消费者就无法执行 up(empty) 操作，empty 永远都为 0，导致生产者永远等待下，不会释放锁，消费者因此也会永远等待下去。

```
#define N 100
typedef int semaphore;
semaphore mutex = 1;
semaphore empty = N;
semaphore full = 0;

void producer() {
    while(TRUE) {
        int item = produce_item();
        down(&empty);
        down(&mutex);
        insert_item(item);
        up(&mutex);
        up(&full);
    }
}

void consumer() {
    while(TRUE) {
        down(&full);
        down(&mutex);
        int item = remove_item();
        consume_item(item);
        up(&mutex);
        up(&empty);
    }
}
```

##### 4.管程

使用信号量机制实现的生产者消费者问题需要客户端代码做很多控制，而管程把控制的代码独立出来，不仅不容易出错，也使得客户端代码调用更容易。

c 语言不支持管程，下面的示例代码使用了类 Pascal 语言来描述管程。示例代码的管程提供了 insert() 和 remove() 方法，客户端代码通过调用这两个方法来解决生产者-消费者问题。

管程有一个重要特性：在一个时刻只能有一个进程使用管程。进程在无法继续执行的时候不能一直占用管程，否则其它进程永远不能使用管程。

管程引入了 **条件变量** 以及相关的操作：**wait()** 和 **signal()** 来实现同步操作。对条件变量执行 wait() 操作会导致调用进程阻塞，把管程让出来给另一个进程持有。signal() 操作用于唤醒被阻塞的进程。

#### 经典同步问题

生产者和消费者问题前面已经讨论过了。

##### 1.哲学家进餐

五个哲学家围着一张圆桌，每个哲学家面前放着食物。哲学家的生活有两种交替活动：吃饭以及思考。当一个哲学家吃饭时，需要先拿起自己左右两边的两根筷子，并且一次只能拿起一根筷子。

下面是一种错误的解法，如果所有哲学家同时拿起左手边的筷子，那么所有哲学家都在等待其它哲学家吃完并释放自己手中的筷子，导致死锁。

为了防止死锁的发生，可以设置两个条件：

- 必须同时拿起左右两根筷子；
- 只有在两个邻居都没有进餐的情况下才允许进餐。

##### 2.读者-写者问题

允许多个进程同时对数据进行读操作，但是不允许读和写以及写和写操作同时发生。

一个整型变量 count 记录在对数据进行读操作的进程数量，一个互斥量 count_mutex 用于对 count 加锁，一个互斥量 data_mutex 用于对读写的数据加锁。

#### 进程通信

进程同步与进程通信很容易混淆，它们的区别在于：

- 进程同步：控制多个进程按一定顺序执行；
- 进程通信：进程间传输信息。

进程通信是一种手段，而进程同步是一种目的。也可以说，为了能够达到进程同步的目的，需要让进程进行通信，传输一些进程同步所需要的信息。

##### 1.管道

管道是通过调用 pipe 函数创建的，fd[0] 用于读，fd[1] 用于写。

```
#include <unistd.h>
int pipe(int fd[2]);
```

它具有以下限制：

- 只支持半双工通信（单向交替传输）；
- 只能在父子进程或者兄弟进程中使用。

##### 2.FIFO

也称为命名管道，去除了管道只能在父子进程中使用的限制。

```
#include <sys/stat.h>
int mkfifo(const char *path, mode_t mode);
int mkfifoat(int fd, const char *path, mode_t mode);
```

FIFO 常用于客户-服务器应用程序中，FIFO 用作汇聚点，在客户进程和服务器进程之间传递数据。

##### 3、消息队列

相比于 FIFO，消息队列具有以下优点：

- 消息队列可以独立于读写进程存在，从而避免了 FIFO 中同步管道的打开和关闭时可能产生的困难；
- 避免了 FIFO 的同步阻塞问题，不需要进程自己提供同步方法；
- 读进程可以根据消息类型有选择地接收消息，而不像 FIFO 那样只能默认地接收。

### 死锁

##### 必要条件

- 互斥：每个资源要么已经分配给了一个进程，要么就是可用的。
- 占有和等待：已经得到了某个资源的进程可以再请求新的资源。
- 不可抢占：已经分配给一个进程的资源不能强制性地被抢占，它只能被占有它的进程显式地释放。
- 环路等待：有两个或者两个以上的进程组成一条环路，该环路中的每个进程都在等待下一个进程所占有的资源。

##### 处理方法

主要有以下四种方法：

- 鸵鸟策略
- 死锁检测与死锁恢复
- 死锁预防
- 死锁避免

##### 鸵鸟策略

把头埋在沙子里，假装根本没发生问题。

因为解决死锁问题的代价很高，因此鸵鸟策略这种不采取任务措施的方案会获得更高的性能。

当发生死锁时不会对用户造成多大影响，或发生死锁的概率很低，可以采用鸵鸟策略。

大多数操作系统，包括 Unix，Linux 和 Windows，处理死锁问题的办法仅仅是忽略它。

##### 死锁检测与死锁恢复

不试图阻止死锁，而是当检测到死锁发生时，采取措施进行恢复。

###### 1.每种类型一个资源的死锁检测

上图为资源分配图，其中方框表示资源，圆圈表示进程。资源指向进程表示该资源已经分配给该进程，进程指向资源表示进程请求获取该资源。

图 a 可以抽取出环，如图 b，它满足了环路等待条件，因此会发生死锁。

每种类型一个资源的死锁检测算法是通过检测有向图是否存在环来实现，从一个节点出发进行深度优先搜索，对访问过的节点进行标记，如果访问了已经标记的节点，就表示有向图存在环，也就是检测到死锁的发生。

###### 2.每种资源多个资源的死锁检测

上图中，有三个进程四个资源，每个数据代表的含义如下：

- E 向量：资源总量
- A 向量：资源剩余量
- C 矩阵：每个进程所拥有的资源数量，每一行都代表一个进程拥有资源的数量
- R 矩阵：每个进程请求的资源数量

进程 P1 和 P2 所请求的资源都得不到满足，只有进程 P3 可以，让 P3 执行，之后释放 P3 拥有的资源，此时 A = (2 2 2 0)。P2 可以执行，执行后释放 P2 拥有的资源，A = (4 2 2 1) 。P1 也可以执行。所有进程都可以顺利执行，没有死锁。

算法总结如下：

每个进程最开始时都不被标记，执行过程有可能被标记。当算法结束时，任何没有被标记的进程都是死锁进程。

1. 寻找一个没有标记的进程 Pi，它所请求的资源小于等于 A。
2. 如果找到了这样一个进程，那么将 C 矩阵的第 i 行向量加到 A 中，标记该进程，并转回 1。
3. 如果没有这样一个进程，算法终止。

###### 3.死锁恢复

- 利用抢占恢复：（又称 资源剥夺法）挂起某些死锁进程，并抢占他的资源，将这些资源分配给其他死锁进程。但应防止被挂起的进程长时间得不到资源时，而处于资源匮乏阶段。
- 利用回滚恢复：（又称 进程回退法）让一（多）个进程回退到足以回避死锁的地步，进程回退时自愿释放资源而不是被剥夺。要求系统保持进程的历史信息，设置还原点。
- 通过杀死进程恢复：（又称 撤销进程法）强制撤销部分甚至全部死锁进程并剥夺这些进程的资源。撤销的原则可以按进程优先级和撤销进程代价的高低进行。

##### 死锁预防

在程序运行之前预防发生死锁。

###### 1.破坏互斥条件

例如假脱机打印机技术允许若干个进程同时输出，唯一真正请求物理打印机的进程是打印机守护进程。

###### 2.破坏占有和等待条件

一种实现方式是规定所有进程在开始执行前请求所需要的全部资源。

###### 3.破坏不可等待条件

###### 4.破坏环路条件

给资源统一编号，进程只能按编号顺序来请求资源。

##### 死锁避免

在程序运行时避免发生死锁。

###### 1.安全状态

图 a 的第二列 Has 表示已拥有的资源数，第三列 Max 表示总共需要的资源数，Free 表示还有可以使用的资源数。从图 a 开始出发，先让 B 拥有所需的所有资源（图 b），运行结束后释放 B，此时 Free 变为 5（图 c）；接着以同样的方式运行 C 和 A，使得所有进程都能成功运行，因此可以称图 a 所示的状态时安全的。

定义：如果没有死锁发生，并且即使所有进程突然请求对资源的最大需求，也仍然存在某种调度次序能够使得每一个进程运行完毕，则称该状态是安全的。

安全状态的检测与死锁的检测类似，因为安全状态必须要求不能发生死锁。下面的银行家算法与死锁检测算法非常类似，可以结合着做参考对比。

###### 2.单个资源的银行家算法

一个小城镇的银行家，他向一群客户分别承诺了一定的贷款额度，算法要做的是判断对请求的满足是否会进入不安全状态，如果是，就拒绝请求；否则予以分配。

###### 3.多个资源的银行家算法

上图中有五个进程，四个资源。左边的图表示已经分配的资源，右边的图表示还需要分配的资源。最右边的 E、P 以及 A 分别表示：总资源、已分配资源以及可用资源，注意这三个为向量，而不是具体数值，例如 A=(1020)，表示 4 个资源分别还剩下 1/0/2/0。

检查一个状态是否安全的算法如下：

- 查找右边的矩阵是否存在一行小于等于向量 A。如果不存在这样的行，那么系统将会发生死锁，状态是不安全的。
- 假若找到这样一行，将该进程标记为终止，并将其已分配资源加到 A 中。
- 重复以上两步，直到所有进程都标记为终止，则状态时安全的。

如果一个状态不是安全的，需要拒绝进入这个状态。

###### 4.银行家算法的另一种描述

思想：把操作系统看作是银行家，操作系统管理的资源相当于银行家管理的资金，进程向操作系统请求分配资源相当于用户向银行家贷款。操作系统按照银行家制定的规则为进程分配资源，当进程首次申请资源时，要测试该进程对资源的最大需求量，若系统现存的资源可以满足它的最大需求量则按当前的申请量分配资源，否则推迟分配。当进程在执行中申请资源时，先测试该进程已占用的资源数与本次申请的资源数之和是否超过了该进程对资源的最大需求量。若超过则拒绝分配资源，若没有超过则再测试系统现存资源能否满足进程尚需的最大资源量，若能满足则按当前申请量分配资源，否则推迟分配。

### 内存管理

#### 虚拟内存

虚拟内存的目的是为了让物理内存扩充成更大的逻辑内存，从而让程序获得更多的可用内存。

为了更好的管理内存，操作系统将内存抽象成地址空间。每个程序拥有自己的地址空间，这个地址空间被分割成多个块，每一块称为一页。这些页被映射到物理内存，但不需要映射到连续的物理内存，也不需要所有页都必须在物理内存中。当程序引用到不在物理内存中的页时，由硬件执行必要的映射，将缺失的部分装入物理内存并重新执行失败的指令。

从上面的描述中可以看出，虚拟内存允许程序不用将地址空间中的每一页都映射到物理内存，也就是说一个程序不需要全部调入内存就可以运行，这使得有限的内存运行大程序成为可能。例如有一台计算机可以产生 16 位地址，那么一个程序的地址空间范围是 0~64K。该计算机只有 32KB 的物理内存，虚拟内存技术允许该计算机运行一个 64K 大小的程序。

#### 分页系统地址映射

内存管理单元（MMU）管理着地址空间和物理内存的转换，其中的页表（Page table）存储着页（程序地址空间）和页框（物理内存空间）的映射表。

一个虚拟地址分成两个部分，一部分存储页面号，一部分存储偏移量。

#### 页面置换算法

在程序运行过程中，如果要访问的页面不在内存中，就发生缺页中断从而将该页调入内存中。此时如果内存已无空闲空间，系统必须从内存中调出一个页面到磁盘对换区中来腾出空间。

页面置换算法和缓存淘汰策略类似，可以将内存看成磁盘的缓存。在缓存系统中，缓存的大小有限，当有新的缓存到达时，需要淘汰一部分已经存在的缓存，这样才有空间存放新的缓存数据。

页面置换算法的主要目标是使页面置换频率最低（也可以说缺页率最低）。

##### 1.最佳置换算法

> OPT, Optimal replacement algorithm

所选择的被换出的页面将是最长时间内不再被访问，通常可以保证获得最低的缺页率。

是一种理论上的算法，因为无法知道一个页面多长时间不再被访问。

##### 2.最近最久未使用

> LRU, Least Recently Used

虽然无法知道将来要使用的页面情况，但是可以知道过去使用页面的情况。LRU 将最近最久未使用的页面换出。

为了实现 LRU，需要在内存中维护一个所有页面的链表。当一个页面被访问时，将这个页面移到链表表头。这样就能保证链表表尾的页面是最近最久未访问的。

因为每次访问都需要更新链表，因此这种方式实现的 LRU 代价很高。

##### 3.最近未使用

> NRU, Not Recently Used

每个页面都有两个状态位：R 与 M，当页面被访问时设置页面的 R=1，当页面被修改时设置 M=1。其中 R 位会定时被清零。可以将页面分成以下四类：

- R=0，M=0
- R=0，M=1
- R=1，M=0
- R=1，M=1

当发生缺页中断时，NRU 算法随机地从类编号最小的非空类中挑选一个页面将它换出。

NRU 优先换出已经被修改的脏页面（R=0，M=1），而不是被频繁使用的干净页面（R=1，M=0）。

##### 4.先进先出

> FIFO, First In First Out

选择换出的页面是最先进入的页面。

该算法会将那些经常被访问的页面也被换出，从而使缺页率升高。

##### 5.第二次机会算法

FIFO 算法可能会把经常使用的页面置换出去，为了避免这一问题，对该算法做一个简单的修改：

当页面被访问 (读或写) 时设置该页面的 R 位为 1。需要替换的时候，检查最老页面的 R 位。如果 R 位是 0，那么这个页面既老又没有被使用，可以立刻置换掉；如果是 1，就将 R 位清 0，并把该页面放到链表的尾端，修改它的装入时间使它就像刚装入的一样，然后继续从链表的头部开始搜索。

##### 6.时钟置换算法

> Clock

第二次机会算法需要在链表中移动页面，降低了效率。时钟算法使用环形链表将页面连接起来，再使用一个指针指向最老的页面。

#### 分段

虚拟内存采用的是分页技术，也就是将地址空间划分成固定大小的页，每一页再与内存进行映射。

下图为一个编译器在编译过程中建立的多个表，有 4 个表是动态增长的，如果使用分页系统的一维地址空间，动态增长的特点会导致覆盖问题的出现。

分段的做法是把每个表分成段，一个段构成一个独立的地址空间。每个段的长度可以不同，并且可以动态增长。

#### 段页式

程序的地址空间划分成多个拥有独立地址空间的段，每个段上的地址空间划分成大小相同的页。这样既拥有分段系统的共享和保护，又拥有分页系统的虚拟内存功能。

#### 分页与分段的比较

- 对程序员的透明性：分页透明，但是分段需要程序员显式划分每个段。
- 地址空间的维度：分页是一维地址空间，分段是二维的。
- 大小是否可以改变：页的大小不可变，段的大小可以动态改变。
- 出现的原因：分页主要用于实现虚拟内存，从而获得更大的地址空间；分段主要是为了使程序和数据可以被划分为逻辑上独立的地址空间并且有助于共享和保护。

### 设备管理

#### 磁盘结构

- 盘面（Platter）：一个磁盘有多个盘面；
- 磁道（Track）：盘面上的圆形带状区域，一个盘面可以有多个磁道；
- 扇区（Track Sector）：磁道上的一个弧段，一个磁道可以有多个扇区，它是最小的物理储存单位，目前主要有 512 bytes 与 4 K 两种大小；
- 磁头（Head）：与盘面非常接近，能够将盘面上的磁场转换为电信号（读），或者将电信号转换为盘面的磁场（写）；
- 制动手臂（Actuator arm）：用于在磁道之间移动磁头；
- 主轴（Spindle）：使整个盘面转动。

#### 磁盘调度算法

读写一个磁盘块的时间的影响因素有：

- 旋转时间（主轴转动盘面，使得磁头移动到适当的扇区上）
- 寻道时间（制动手臂移动，使得磁头移动到适当的磁道上）
- 实际的数据传输时间

其中，寻道时间最长，因此磁盘调度的主要目标是使磁盘的平均寻道时间最短。

##### 1.先来先服务

> FCFS, First Come First Served

按照磁盘请求的顺序进行调度。

优点是公平和简单。缺点也很明显，因为未对寻道做任何优化，使平均寻道时间可能较长。

##### 2.最短寻道时间优先

> SSTF, Shortest Seek Time First

优先调度与当前磁头所在磁道距离最近的磁道。

虽然平均寻道时间比较低，但是不够公平。如果新到达的磁道请求总是比一个在等待的磁道请求近，那么在等待的磁道请求会一直等待下去，也就是出现饥饿现象。具体来说，两端的磁道请求更容易出现饥饿现象。

##### 3.电梯算法

> SCAN

电梯总是保持一个方向运行，直到该方向没有请求为止，然后改变运行方向。

电梯算法（扫描算法）和电梯的运行过程类似，总是按一个方向来进行磁盘调度，直到该方向上没有未完成的磁盘请求，然后改变方向。

因为考虑了移动方向，因此所有的磁盘请求都会被满足，解决了 SSTF 的饥饿问题。

### 链接

#### 编译系统

以下是一个 hello.c 程序：

```
#include <stdio.h>

int main()
{
    printf("hello, world\n");
    return 0;
}
```

在 Unix 系统上，由编译器把源文件转换为目标文件。

```
gcc -o hello hello.c
```

这个过程大致如下：

- 预处理阶段：处理以 # 开头的预处理命令；
- 编译阶段：翻译成汇编文件；
- 汇编阶段：将汇编文件翻译成可重定位目标文件；
- 链接阶段：将可重定位目标文件和 printf.o 等单独预编译好的目标文件进行合并，得到最终的可执行目标文件。

#### 静态链接

静态链接器以一组可重定位目标文件为输入，生成一个完全链接的可执行目标文件作为输出。链接器主要完成以下两个任务：

- 符号解析：每个符号对应于一个函数、一个全局变量或一个静态变量，符号解析的目的是将每个符号引用与一个符号定义关联起来。
- 重定位：链接器通过把每个符号定义与一个内存位置关联起来，然后修改所有对这些符号的引用，使得它们指向这个内存位置。

#### 目标文件

- 可执行目标文件：可以直接在内存中执行；
- 可重定位目标文件：可与其它可重定位目标文件在链接阶段合并，创建一个可执行目标文件；
- 共享目标文件：这是一种特殊的可重定位目标文件，可以在运行时被动态加载进内存并链接；

#### 动态链接

静态库有以下两个问题：

- 当静态库更新时那么整个程序都要重新进行链接；
- 对于 printf 这种标准函数库，如果每个程序都要有代码，这会极大浪费资源。

共享库是为了解决静态库的这两个问题而设计的，在 Linux 系统中通常用 .so 后缀来表示，Windows 系统上它们被称为 DLL。它具有以下特点：

- 在给定的文件系统中一个库只有一个文件，所有引用该库的可执行目标文件都共享这个文件，它不会被复制到引用它的可执行文件中；
- 在内存中，一个共享库的 .text 节（已编译程序的机器代码）的一个副本可以被不同的正在运行的进程共享。







### 计算机操作系统参考资料

- Tanenbaum A S, Bos H. Modern operating systems[M]. Prentice Hall Press, 2014.
- 汤子瀛, 哲凤屏, 汤小丹. 计算机操作系统[M]. 西安电子科技大学出版社, 2001.
- Bryant, R. E., & O’Hallaron, D. R. (2004). 深入理解计算机系统.
- 史蒂文斯. UNIX 环境高级编程 [M]. 人民邮电出版社, 2014.
- [Operating System Notes](https://applied-programming.github.io/Operating-Systems-Notes/)
- [Operating-System Structures](https://www.cs.uic.edu/~jbell/CourseNotes/OperatingSystems/2_Structures.html)
- [Processes](http://cse.csusb.edu/tongyu/courses/cs460/notes/process.php)
- [Inter Process Communication Presentation[1\]](https://www.slideshare.net/rkolahalam/inter-process-communication-presentation1)
- [Decoding UCS Invicta – Part 1](https://blogs.cisco.com/datacenter/decoding-ucs-invicta-part-1)

