# 面试问题整理



[TOC]



### Redis

------

#### 应用场景

1.缓存

2.共享Session

3.消息队列系统

4.分布式锁



#### 单线程的Redis为什么快

1.纯内存操作

2.单线程操作，避免了频繁的上下文切换

3.合理高效的数据结构

4.采用了非阻塞的I/O多路复用机制



#### Redis的数据结构及使用场景

1.String字符串：字符串类型是Redis最基础的数据结构，首先键都是字符串类型，且其他几种数据结构都是在字符串类型基础上构建的，我们常使用的set key value命令就是字符串（语句没读懂？）。常用在缓存、技术、共享Session、限速等。

2.Hash哈希：在Redis中，哈希类型是指键值本身又是一个键值对结构，哈希可用来存放用户信息，如实现购物车（如何实现？）。

3.List列表（双向链表）：列表（list）类型是用来存储多个有序的字符串。可以做简单的消息队列的功能。

4.Set集合：集合（set）类型也是用来保存多个的字符串元素，但和列表类型不一样的是，集合中不允许有重复元素，且集合中的元素是无序的，不能通过索引下标获取元素。利用Set的交集、并集、差集等操作，可以计算共同喜好，全部的喜好，自己独有的喜好等功能。

5.Sorted Set有序集合（跳表实现）：Sorted Set多了一个权重参数Score，集合中的元素能够按Score进行排列。可以做排行榜应用，取TOP N操作。

| 数据类型 | 可以存储的值           | 操作                                                         |
| -------- | ---------------------- | ------------------------------------------------------------ |
| STRING   | 字符串、整数或浮点数   | 对整个字符串或字符串的其中一部分执行操作；对整数和浮点数执行自增或自减操作 |
| LIST     | 列表                   | 从两端压入或者弹出元素；对单个或者多个元素进行修剪，只保留一个范围内的元素 |
| SET      | 无序集合               | 添加、获取、移除单个元素；检查一个元素是否存在于集合中；计算交集、并集、差集从集合里面随机获取元素 |
| HASH     | 包含键值对的无序散列表 | 添加、获取、移除单个键值对；获取所有键值对；检查某个键是否存在 |
| ZSET     | 有序集合               | 添加、获取、删除元素；根据分支范围或者成员来获取元素；计算一个键的排名 |
|          | ··                     |                                                              |

#### Redis的数据过期策略

Redis中数据过期策略采用定期删除+惰性删除策略

- 定期删除策略：Redis启用一个定时器定时监视所有的key，判断key是否过期，过期的话就删除。这种策略可以保证过期的key最终都会被删除，但是也存在严重的缺点：每次都遍历内存中所有的数据，非常消耗CPU资源，并且当key已过期，但是定时器还处于未唤起状态，这段时间内key仍然可以用。

- 惰性删除策略：在获取key是时，先判断key是否过期，如果过期则删除。缺点：如果这个key一直未被使用，那么它一直在内存中，其实它已经过期了，会浪费大量的空间。

- 这两种策略天然的互补，结合起来之后，定时删除策略就发生了一些改变，不再是每次扫描全部的key了，而是随机抽取一部分key进行检查，这样就降低了对CPU资源的损耗，惰性删除策略互补了为检查到的key，基本上满足了所有要求（语句不太通顺？）。但有时候比较巧，既没有被定时器抽取到，又没有被使用，只写数据如何从内存中消失？此时我们有内存淘汰机制，当内存不够用时，内存淘汰机制就会上场。淘汰策略分为：

  ​	当内存不足以容纳新写入数据时，

  - 新写入操作会报错（Redis默认策略）

  - 在键空间中，移除最近最少使用的Key。（LRU推荐使用）

  - 在键空间中，随机移除某个Key。

  - 在设置了过期时间的键空间中，移除最近最少使用的Key。这种情况一般是把Redis即当缓存，又做持久化存储时才用。

  - 在设置了过期时间的键空间中，随机移除某个Key。

  - #### 在设置了过期时间的键空间中，有更早过期时间的Key优先移除



#### Redis的LRU具体实现：

传统的LRU是使用栈的形式，每次都将最新使用的移入栈顶，但是用栈的形式会导致select *的时候产生大量非热点数据占领头部数据（没看懂），故需要改进。Redis每次按key获取一个值的时候，都会更新value的lru字段为当前秒级别的时间戳。Redis初始的实现算法很简单，随机从dict中取出五个key，淘汰一个lru字段值最小的。在3.0的时候，改进了算法，首先第一次随机选取的key都会放入一个pool中（poll的大小为16），pool中的key是按lru的大小顺序排列的。接下来每次随机选取的key的lru的值必须小于pool中最小的lru才会继续放入，直到将pool放满。放满之后，每次如果有新的key需要放入，需要将pool中lru最大的一个key取出。淘汰的时候，直接从pool中选取一个lru最小的值然后将其淘汰。



#### 如何解决Redis缓存雪崩的问题

1.使用Redis高可用架构：使用Redis集群来保证Redis服务不会挂掉。

2.缓存时间不一致，给缓存的失效时间加上一个随机值，避免集体失效。

3.限流降级策略：有一定的备案，比如个性推荐服务不可用了，换成热点数据推荐服务。



#### 如何解决Redis缓存穿透问题

（TODO 什么是缓存穿透？）

1.在接口做校验

2.存null值（缓存击穿加锁）

3.布隆过滤器拦截：将所有可能的查询key先映射到布隆过滤器中，查询时先判断key是否存在布隆过滤器中，存在才继续向下执行，若不存在，则直接返回。布隆过滤器将值进行多次哈希bit存储，布隆过滤器说某个元素存在，可能会被误判，布隆过滤器说某个元素不存在，则一定不存在。



#### Redis的持久化机制

Redis为了保证效率，数据缓存在了内存中，但会周期性的把更新的数据写入磁盘或者把修改操作写入追加的记录文件中，以保证数据的持久化。

Redis的持久化策略有两种：

1. RDB（快照持久化）：加个某个时间点的所有数据都写入到磁盘里面；可以将快照复制到其他服务器从而创建具有相同数据的服务器副本；如果系统发生故障，将会丢失最后一次创建快照之后的数据；若数据量很大，保存快照的时间会很长。当Redis需要做持久化时，Redis会fock一个子进程，子进程将数据写到磁盘上的一个临时RDB文件中。当子进程完成写临时文件后，将原来的RDB替换掉。

2. AOF（只追加文件）：将写命令添加到AOF文件（Append Only File）的末尾。使用AOF持久化需要设置同步选项，从而确保写命令同步到磁盘文件上的时机。因为对文件进行写入并不会马上将内容同步到磁盘上，而是先存储到缓冲区，然后由操作系统决定何时同步到磁盘。有以下同步选项：

   | 选项     | 同步频率               |
   | -------- | ---------------------- |
   | always   | 每个写命令都同步       |
   | everysec | 每秒同步一次           |
   | no       | 让操作系统决定何时同步 |

   - always选项会眼中降低服务器的性能；
   - everyse选项比较合适，可以保证系统崩溃时只会丢失一秒左右的数据，且Redis每秒执行一次同步对服务器性能几乎没有任何影响；
   - no选项并不能给服务器性能带来多大提升，且会增加系统崩溃时数据丢失的数量。

随着服务器写请求的增多，AOF文件会越来越大。Redis提供了一只能怪将AOF重写的特性，能够去除AOF文件中冗余写命令。

这两种持久化方法既可以同时使用，又可以单独使用，在某些情况下甚至可以都不使用，具体选择哪种持久化方法需要根据用户的数据及应用来决定。



#### Redis和memcached的区别

相同点：两者都是菲关系型内存键值数据库；

不同点：

​	1.数据类型：memcached仅支持字符串类型，而Redis支持五种不同的数据类型，可以更灵活的解决问题。

​	2.数据持久化：Redis支持两种持久化策略，RDS快照和AOF日志，而Memcached不支持持久化。

​	3.分布式：Memcached不支持分布式，只能通过在客户端使用一致性哈希来实现分布式存储，这种方式在存储和查询时都需要先在客户端计算一次数据所在的节点；Redis Cluster实现了分布式的支持。

​	4.内存管理机制：在Redis中，并不是所有数据都一直存储在内存中的，可以将一些很久没用的value交换到磁盘，而Memcached的数据则会一直在内存中；Memcached将内存分割成特定长度的块来存储数据，以完全解决内存碎片的问题。但这种方式使得内存的利用率不高，如块的大小为128bytes，只存储100bytes的数据，剩下的28bytes就浪费掉了。



#### Redis并发竞争key的解决方案

（TODO看不懂）

1.分布式锁+时间戳

2.利用消息队列



#### Redis与MySQL双写一致性方案

先更新数据库，再删除缓存。数据库的读操作，要远快于写操作，所以脏数据很难出现。可以对异步延时删除策略，保证读请求完成以后，再进行删除操作。（TODO没看懂）



#### Redis的管道pipeline

对于单线程阻塞式的Redis，pipeline可以满足批量的操作，把多个命令连续的发送给Redis Server，然后一一解析响应结果。Pipelining可以提高批量处理性能，提升原因主要是TCP连接中减少了“交互往返”的时间。pipeline底层是通过把所有的操作封装成流，redis有定义自己的出入输出流（TODO不通顺？）。在sync()方法执行操作，每次请求放在队列里面，解析响应包。



#### Redis的底层数据结构

（TODO不太理解，同时需要完善）

1.字典：

dictht是一个散列表结构，使用拉链法解决哈希冲突。

```
/* This is our hash table structure. Every dictionary has two of this as we
 * implement incremental rehashing, for the old to the new table. */
typedef struct dictht {
    dictEntry **table;
    unsigned long size;
    unsigned long sizemask;
    unsigned long used;
} dictht;
```

```
typedef struct dictEntry {
    void *key;
    union {
        void *val;
        uint64_t u64;
        int64_t s64;
        double d;
    } v;
    struct dictEntry *next;
} dictEntry;
```

Redis的字典dict中包含两个哈希表dictht，这是为了方便进行rehash操作。在扩容时，将其中一个dictht上的键值对rehash到另一个dictht上面，完成之后释放空间并交换两个dictht的角色。

```
typedef struct dict {
    dictType *type;
    void *privdata;
    dictht ht[2];
    long rehashidx; /* rehashing not in progress if rehashidx == -1 */
    unsigned long iterators; /* number of iterators currently running */
} dict;
```

rehash操作不熟一次性完成的，而是采用渐进放手，这是为了避免一次性执行过多的rehash操作给服务器带来过大的负担。

渐进式rehash通过记录dict的rehashidx完成，他从0开始，然后每执行一次rehash都会递增。如在一次rehash中，要把dict[0] rehash到dict[1]。这一次会把dict[0]上的table[rehashidx]的键值对rehash到dct[1]上，dict[0]的table[rehashidx]指向null，并领rehashidx++。

在rehash期间，每次对字典执行添加、删除、查找或者更新操作时，都会执行一次渐进式rehash。

采用渐进式rehas会导致字典中的数据分散在两个dictht上，因此对字典的查找操作也需要到对应的dictht去执行。

```
/* Performs N steps of incremental rehashing. Returns 1 if there are still
 * keys to move from the old to the new hash table, otherwise 0 is returned.
 *
 * Note that a rehashing step consists in moving a bucket (that may have more
 * than one key as we use chaining) from the old to the new hash table, however
 * since part of the hash table may be composed of empty spaces, it is not
 * guaranteed that this function will rehash even a single bucket, since it
 * will visit at max N*10 empty buckets in total, otherwise the amount of
 * work it does would be unbound and the function may block for a long time. */
int dictRehash(dict *d, int n) {
    int empty_visits = n * 10; /* Max number of empty buckets to visit. */
    if (!dictIsRehashing(d)) return 0;

    while (n-- && d->ht[0].used != 0) {
        dictEntry *de, *nextde;

        /* Note that rehashidx can't overflow as we are sure there are more
         * elements because ht[0].used != 0 */
        assert(d->ht[0].size > (unsigned long) d->rehashidx);
        while (d->ht[0].table[d->rehashidx] == NULL) {
            d->rehashidx++;
            if (--empty_visits == 0) return 1;
        }
        de = d->ht[0].table[d->rehashidx];
        /* Move all the keys in this bucket from the old to the new hash HT */
        while (de) {
            uint64_t h;

            nextde = de->next;
            /* Get the index in the new hash table */
            h = dictHashKey(d, de->key) & d->ht[1].sizemask;
            de->next = d->ht[1].table[h];
            d->ht[1].table[h] = de;
            d->ht[0].used--;
            d->ht[1].used++;
            de = nextde;
        }
        d->ht[0].table[d->rehashidx] = NULL;
        d->rehashidx++;
    }

    /* Check if we already rehashed the whole table... */
    if (d->ht[0].used == 0) {
        zfree(d->ht[0].table);
        d->ht[0] = d->ht[1];
        _dictReset(&d->ht[1]);
        d->rehashidx = -1;
        return 0;
    }

    /* More to rehash... */
    return 1;
}
```

2、跳跃表

是有序集合的地城实现之一。

跳跃表是基于多指针有序链表实现的，可以看成多个有序链表。

（TODO缺少图片）

在查找时，从上层指针开始查找，找到对应的区间后再到下一层去查找。如图所示（TODO 图挂掉了）

与红黑树等平衡树相比，跳跃表具有以下优点：

- 插入速度非常快，因为不需要进行旋转灯操作来维护平衡性；
- 易实现；
- 支持无锁操作。



#### 使用场景

##### 1、计数器

可以对String进行自增自减操作，实现计数器功能。

Redis这种内存型数据库的读写性能非常高，很适合存储频繁读写的计数量。

##### 2、缓存

将热点数据放在内存中，设置内存的最大使用量以及淘汰策略来保证缓存的命中率。

##### 3、查找表

如DNS记录就很适合使用Redis进行存错。

查找表和缓存类似，也是利用Redis快速的查找特性。但是查找表的内容不能失效，而缓存的内容可以失效，因为缓存不作为可靠的数据来源。

##### 4、消息队列

List是一个双向链表，可以通过lpush和rpop写入和读取消息。

不过最好使用RocketMQ等消息中间件。

##### 5、会话缓存

可以使用Redis统一存储多态应用服务器的会话信息。

当应用服务器不再存储用户的会话信息，也就不再具有状态，一个用户可以氢气任意一个应用服务器，从而更容易实现高可用性及可伸缩性。

##### 6、分布式锁实现

在分布式场景下，无法使用单机环境下的锁来对多个节点的进程进行同步。

可以使用Redis自带的SETNX命令来实现分布式锁，除此之外，还可以使用官方提供的RedLock分布式锁实现。

##### 7、其他

Set可以实现交集、并集等操作，从而实现共同好友等功能。

ZSet可以实现有序性操作，从而实现排行榜等功能。



#### 事务

一个事务包含了多个命令，服务器在执行事务期间，不会改去执行其它客户端的命令请求。

事务中的多个命令被一次性发送给服务器，而不是一条一条发送，这种方式被称为流水线，它可以减少客户端与服务器之间的网络通信次数从而提升性能。

Redis最简单的事务实现方式是使用MULTI和EXEC命令将事务操作包围起来。





### MySQL

------

#### 事务的基本要素

事务指满足ACID特性的一组操作，可以通过Commit提交一个事务，也可以使用Rollback进行回滚。

1.原子性（Atomicity）：事务是一个原子操作单元，其对数据的修改，要么全部执行，要么全部不执行。

​	回滚可以用回滚日志（Undo Log）来实现，回滚日志记录着事务所执行的修改操作，在回滚时反向执行这些修改即可。

2.一致性（Consistency）：数据库在事务执行前后都保持一致性状态。在一致性状态下，所有事务对同一个数据的读取结果都是相同的。

3.隔离性（Isolation）：一个事务所做的修改在最终提交前，对其他事务是不可见的。

4.持久性：事务提交后，其所做的修改将会永远保存到数据库中。即使系统发生崩溃，事务执行的结果也不能丢失。

事务的ACID特性概念简单，但不是很好理解，主要是因为这几个特性不是一种平级关系：

- 只有满足一致性，事务的执行结果才是正确的。
- 在无并发的情况下，事务串行执行，隔离性一定能满足。此时只要能满足原子性，就一定能满足一致性。
- 在无并发的情况下，多个事务并行执行，事务不仅要满足满足原子性还要满足隔离性，才能满足一致性。
- 事务满足持久化是为了能应对系统崩溃的情况。

#### 事务的并发问题

0.丢失修改：T1和T2两个事务都对一个数据修改，T1先修改，T2随后修改，T2的修改覆盖了T1的修改。

1.脏读：事务A读取事务B更新的数据，然后B回滚操作，则A读取到的数据是脏数据。

2.不可重复读：事务A多次读取同一数据，事务B在事务A多次读取的过程中，对数据作了更新并提交，导致事务A多次读取同一数据时，结果不一致。

3.幻读：A事务读取了B事务已经提交的新增数据。注意和不可重复读的区别，这是是新增，不可重复是更改（或删除）。select某记录是否存在，不存在，准备插入此记录，但执行insert时发现此记录已存在，无法插入，此时就发生了幻读。



#### MySQL事务隔离级别

| 事务隔离级别 | 脏读 | 不可重复读 | 幻读 |
| ------------ | ---- | ---------- | ---- |
| 读未提交     | 是   | 是         | 是   |
| 不可重复读   | 否   | 是         | 是   |
| 可重复读     | 否   | 否         | 是   |
| 串行化       | 否   | 否         | 否   |

在MySQL可重复的隔离级别中并不是完全解决了幻读的问题，而是解决了读数据情况下的幻读问题。而对于修改的操作依旧存在幻读问题，就是说MVCC对于幻读的解决是不彻底的。通过索引枷锁，间隙锁，next  key lock可以解决幻读的问题。



#### MySQL的逻辑结构

- 最上层的服务类似其他CS结构，比如连接处理，授权处理。
- 第二层是MySQL的服务层，包括SQL的解析分析优化，存储过程触发器视图等也在这一层实现。
- 最后一层是存储引擎等实现，类似于Java接口的实现，MySQL的执行器在执行SQL的时候只会关注API的调用，完全屏蔽了不同引擎实现间的差异。如Select语句，先会判断当前用户是否拥有全新，其次到缓存（内存）查询是否有响应的结果集，如果没有，再执行解析SQL，优化生成执行计划，调用API执行。



#### SQL执行顺序

SQL的执行顺序：from---where---group by --- having---select --- order by



#### MVCC,redolog,undolog,binlog

- undolog 也就是我们常说的回滚日志文件 主要用于事务中执行失败，进行回滚，以及MVCC中对于数据历史版本的查看。由引擎层的InnoDB引擎实现，是逻辑日志...（TODO 略过，后面再补，参考：https://github.com/yuanguangxin/LeetCode/blob/master/Rocket.md）。
- redoLog 是重做日志文件是记录数据修改之后的值（TODO语句不通顺？）用于持久化到磁盘中。redo log包括两部分：一是内存中的日志缓冲（redo log buffer），概不负责日志是易失性的；二是磁盘上的重做日志文件（redo log file），该部分是持久的。...（TODO 略过，后面再补，参考：https://github.com/yuanguangxin/LeetCode/blob/master/Rocket.md）。
- MVCC多版本并发控制是MySQL中基于乐观锁理论实现隔离级别的方式，用于读已提交和可重复读取隔离级别的实现。在MySQL中，会在表中每一条数据后面添加两个字段：最近修改该行的事务ID，指向该行（undolog表中）回滚段的指针。...（TODO 略过，后面再补，参考：https://github.com/yuanguangxin/LeetCode/blob/master/Rocket.md）。
- binlog由MySQL的Server层实现，是逻辑日志，记录的是SQL语句的原始逻辑。...（TODO 略过，后面再补，参考：https://github.com/yuanguangxin/LeetCode/blob/master/Rocket.md）。



#### binlog和redolog的区别

1.redolog是在InnoDB存储引擎层产生的，而binlog是MySQL数据库的上层服务层产生的。（TODO不够细致）

2.两种日志记录的内容形式不同。MySQL的binlog是逻辑日志文件，其记录是对应的SQL语句。而innodb存储引擎层面的重做日志是物理日志（TODO没读懂）。

...（TODO 略过，后面再补，参考：https://github.com/yuanguangxin/LeetCode/blob/master/Rocket.md）。

#### MySql如何保证一致性和持久性

（TODO 略过，后面再补，参考：https://github.com/yuanguangxin/LeetCode/blob/master/Rocket.md）。



#### InnoDB的行锁模式

（TODO 略过，后面再补，参考：https://github.com/yuanguangxin/LeetCode/blob/master/Rocket.md）。



#### 为什么选择B+树作为索引结构

- Hash索引：底层哈希表，哈希表是一种以key-value形式存储数据的结构，多个数据在存储关系上是完全没有任何顺序关系，故对于区间查询是无法通过索引查询的，需要全表扫描。所以，哈希索引只适用于等值查询的场景。而B+树是一种多路平衡查找树，所以他们的节点是天然有序的（左子节点小于父节点，父节点小于右子节点），对于范围查询的时候不需要做全表扫描。

- 二叉查找树：解决了排序的基本问题，但是无法保证平衡，可能退化为链表。

- 平衡二叉树：通过旋转姐姐了平衡的问题，但是旋转操作效率太低。

- 红黑树：通过舍弃严格的平衡和引入红黑节点，解决了AVL旋转效率过低的问题，但是在磁盘等场景下，树仍然太过，IO次数太多。

- B+树：在B树的基础上，将非叶节点改造为不存储数据的纯索引节点，进一步降低了树的高度；此外将叶节点使用指针接成链表，范围查询更加高效。与红黑树相比较：

  - 更少的查找的次数：平衡树查找操作的时间复杂度和树高（h）相关，O（h）=O
    $$
    (\log_d{N})
    $$
    其中d为每个节点的出度。

  - 利用磁盘的预读特性：为了减少磁盘I/O操作，磁盘往往不是严格按需读取，而是每次都会预读。预读过程中，磁盘进行顺序读取，顺序读取不需要进行磁盘寻道，且只需要很短的磁盘旋转时间，速度非常快；操作系统一般将内存和磁盘分割成固定大小的块，每一块称为一页，内存与磁盘以页为单位交换数据。数据库系统将索引的一个节点的大小设置为页的大小，使得一次I/O就能完全，使得一次I/O就能完全载入一个节点，并且可以利用预读特性，相邻节点也能被预先载入。



#### 什么是B+ Tree？

1.数据结构

B Tree指的是Balance Tree，也就是平衡树。平衡树是一颗查找树，并且所有叶子节点位于同一层。

B+ Tree是基于B Tree和叶子节点顺序访问指针进行实现的，它具有B Tree的平衡性，并且通过顺序访问指针来提高区间查询的性能。

在B+ Tree中，一个节点中的key从左到右非递减排列，如果某个指针的左右相邻key分别为 keyi 和keyi+1，且不为null，则该指针指向节点的所有key大于等于keyi且小于等于keyi+1。

2.操作

进行查找操作时，首先在根节点进行二分查找，找到一个key所在的指针，然后递归地在指针所指向的节点进行查找。直到查找到叶子节点，然后在叶子节点进行二分查找，找出key所对应的data。

插入删除操作会破坏平衡树的平衡性，因此在插入删除操作之后，需要对树进行一个分裂、合并、旋转灯操作来维护平衡性。



#### B+树的叶子节点都可以存哪些东西

可能存储的是整行数据，也有可能是主键的值。B+树的叶子节点存储了整行数据的是主键索引，也被称为聚簇索引。而索引B+树的叶子节点存储了主键的值是非主键索引，也被称之为非聚簇索引。



#### 覆盖索引

指一个查询语句的执行只用从索引中就能够取得，不必从数据表中读取。也可以称之为实现了索引覆盖。



#### 索引的优点

- 大大减少了服务器需要扫描的数据行数
- 帮助服务器进行排序和分组，以及避免创建临时表（B+ Tree索引是有序的，可以用于ORDER BY 和GROUP BY操作。临时表主要是在排序和分组过程中创建，不需要排序和分组，也就不需要创建临时表）。
- 所及I/O变为顺序I/O（B+ Tree索引是有序的，会将相邻的数据都存储在一起）。



#### 索引的使用条件

- 对于非常小的表，大部分情况下简单的全表扫描比建立索引更高效；
- 对于中到大型的表，索引就非常有效。
- 但是对于特大型的表，建立和维护索引的代价将会随之增长。这种情况下，需要用到一种技术可以直接区分出需要查询的一组数据，而不是一条记录一条记录地匹配，例如可以使用分区技术。



#### 查询在什么时候不走（预期中的）索引

1.模糊查询 %like

2.索引列参与计算，使用了函数

3.非最左前缀顺序

4.where对null判断

5.where不等于

6.or操作有至少一个字段没有索引

7.需要回表的查询结果集过大（超过配置的范围）



#### 数据库优化指南

1.创建并使用正确的索引

2.只返回需要的字段：最好不要使用SELECT *语句。

3.减少交互次数（批量提交）

4.设置合理的Fetch Size（数据每次返回给客户端的条数）

5.使用Explain进行分析：Explain用来分析SELECT语句，开发人员可以通过分析Explain结果来优化查询语句。比较重要的字段有：

- select_type：查询类型，有见地查询、联合查询、子查询等。
- key：使用的索引
- rows：扫描的行数



#### InnoDB和MyISAM

##### 两者比较

- 事务：InnoDB是事务型的，可以使用Commit和Rollback语句。
- 并发：MyISAM只支持表级锁，而InnoDB还支持行级锁。
- 外键：InnoDB支持外键。
- 备份：InnoDB支持在线热备份。
- 崩溃恢复：MyISAM崩溃后发生损坏的概率比InnoDB高很多，且恢复速度也更慢。
- 其他特性：MyISAM支持压缩表和空间数据索引。

##### InnoDB

是MySQL默认的事务型存储引擎，只有在需要它不支持的特性时，才考虑使用其他存储引擎。

实现了四个标准的隔离级别，默认级别是可重复度（REPEATABLE READ）。在可重复读隔离级别下，通过多版本并发控制（MVCC）+Next-Key Locking防止幻读。

主索引是聚簇索引，在索引中保存了数据，从而避免直接读取磁盘，因此对查询性能有跟大的提升。

内部做了很多优化，包括从磁盘读取数据时采用可预测性读、能够加快读操作并且自动创建的自适应哈希索引、能够枷锁插入查找的插入缓冲区等，

支持真正的在线热备份。其他存储引擎不支持在线热备份，要获取一致性视图需要停止对所有表的写入，而在读写混合场景中，停止写入可能也意味着停止读取。

##### MyISAM

设计简单，数据以紧密格式存储。对于只读数据，或者表比较小、可以容忍修复操作，则依然可以使用它。

提供了大量的特性，包括压缩表、空间数据索引等。

不支持事务。

不支持行级锁，只能对整张表枷锁，读取时会对需要读到的所有表加共享锁，写入时则对表加排他锁。但在表有读取操作的同时，也可以往表中插入新的记录，哲别称为并发插入（CONCURRENT INSERT）。

可以手动或者自动执行检查和修复操作，但和事务恢复及崩溃恢复不同，可能导致一些数据丢失，而且修复操作是非常慢的。

若指定了DELAY_KEY_WRITE选项，在每次修改完成时，不会立即将修改的索引数据写入磁盘，而是写到内存中的缓冲区，只有在清理缓冲区或者关闭表的时候才会将对应的索引块写入磁盘。这种方式可以极大的提升写入性能，但是在数据库或者主机崩溃时，会造成索引损坏，需要执行修复操作。



### JDK源码分析

------



#### HashMap

##### 1.是什么

实现O(1)存取效率的key-value对数据结构

##### 2.如何使用

```java
public class HashMapTest
{
    public static void main(String[] args)
    {
        HashMap<String, Object> map = new HashMap<>();
        map.put("key1", "value1");

        System.out.println(map.get("key1"));
        map.remove("key1");

        map.containsKey("key1");
    }
}
```

##### 3.原理分析

- ##### uml：

  - 可克隆，可序列化，实现了Map

- ##### 构造方法：

  ```java
  public class HashMap<K,V> extends AbstractMap<K,V>
      implements Map<K,V>, Cloneable, Serializable {
      //使用Node数组实现，使用链地址法解决Hash冲突
      transient Node<K,V>[] table;
      //默认的初始容量
      static final int DEFAULT_INITIAL_CAPACITY = 1 << 4; // aka 16
      //最大容量
      static final int MAXIMUM_CAPACITY = 1 << 30;
      //默认的加载因子
      static final float DEFAULT_LOAD_FACTOR = 0.75f;
      //链表转树的长度
      static final int TREEIFY_THRESHOLD = 8;
      //树转回链表的长度
      static final int UNTREEIFY_THRESHOLD = 6;
  
      static final int MIN_TREEIFY_CAPACITY = 64; 
  
      public HashMap() {
      //设置默认加载因子
      //table中已有的元素个数/table所有元素的个数，当这个比值>=0.75的时候需要扩容
      //或者说使用的容量到达16*0.75=12时需要扩容
      this.loadFactor = DEFAULT_LOAD_FACTOR; // all other fields defaulted
      }
  }
  ```

- put方法

  总体伪算法如下：

  ​	1.计算key的hash值

  ​	2.使用hash值&（数组长度-1）计算该数据存放的位置i

  ​		2.1 table为空，进行扩容

  ​		2.2 如果位置i不为空，那么用（key,vaue） 存入该位置

  ​		2.3 如果位置i不为空

  ​			2.3.1 比较该位置的key与新位置的key是否相等，是则存入该位置

  ​			2.3.2 否则

  ​				2.3.2.1 如果是树节点，调用红黑树的插入操作

  ​				2.3.2.2 如果是链表节点，那么遍历链表

  ​					2.3.2.2.1 如果找到了key相同的节点，替换value

  ​					2.3.2.2.2 否则插入链表尾部

  ​	3.插入完毕之后比较size是否大于容量*加载因子，是则需要扩容

  ​		3.1 容量为原来的两倍

  ​		3.2 创建一个新的node数据，原来数组的元素迁移到这个数组中

  4. put

     ```java
     public V put(K key, V value) {
         return putVal(hash(key), key, value, false, true);
     }
     ```

  3.1 计算key的hash值

  1.hash

  ```java
  //hash函数
  static final int hash(Object key) {
      int h;
      //hashCode 异或 hashCode 右移16bit
      return (key == null) ? 0 : (h = key.hashCode()) ^ (h >>> 16);
  }
  ```

  2.putVal

  ```java
  final V putVal(int hash, K key, V value, boolean onlyIfAbsent,
                 boolean evict) {
      Node<K,V>[] tab; Node<K,V> p; int n, i;
  	//table为空或者长度为0
      if ((tab = table) == null || (n = tab.length) == 0)
      	//第一次扩容
          n = (tab = resize()).length;
      //使用hash至以及数组长度计算下标，如果table[下标]为空，即没有元素，直接赋值即可
      if ((p = tab[i = (n  1) & hash]) == null)
          tab[i] = newNode(hash, key, value, null);
      //否则说明table[下标]有元素
      else {
          Node<K,V> e; K k;
          //头节点不仅hash值相同，key也equals（即头节点就是要找的节点），那么保存这个节点以便后续使用
          if (p.hash == hash &&
              ((k = p.key) == key || (key != null && key.equals(k))))
              e = p;
          //头节点不是要找的节点，同时是个TreeNode，那么转调tree的操作
          else if (p instanceof TreeNode)
              e = ((TreeNode<K,V>)p).putTreeVal(this, tab, hash, key, value);
          //头节点不是要找的节点，同时是普通的链表
          else {
          	//遍历链表找，同时记录遍历了几个元素存到bitCount里。
              for (int binCount = 0; ; ++binCount) {
              	//到达链表的尾部
                  if ((e = p.next) == null) {
                      p.next = newNode(hash, key, value, null);
                      //判断bitCount是否达到树化的限度，是则树化
                      if (binCount >= TREEIFY_THRESHOLD  1) // 1 for 1st
                          treeifyBin(tab, hash);
                      break;
                  }
                  //找到了相等的节点
                  if (e.hash == hash &&
                      ((k = e.key) == key || (key != null && key.equals(k))))
                      break;
                  p = e;
              }
          }
          //如果有找到相等的节点，那么e保存的就是这个节点的引用，直接替换value即可
          if (e != null) { // existing mapping for key
              V oldValue = e.value;
              if (!onlyIfAbsent || oldValue == null)
                  e.value = value;
              afterNodeAccess(e);
              return oldValue;
          }
      }
      ++modCount;
      //加入这个节点后超过了threshold，那么resize
      if (++size > threshold)
          resize();
      afterNodeInsertion(evict);
      return null;
  }
  ```

  ##### 3.2 第一次进来table肯定为空，那么扩容

  ```java
  final Node<K,V>[] resize() {
  	//保存旧的table，capacity，threshold
      Node<K,V>[] oldTab = table;
      int oldCap = (oldTab == null) ? 0 : oldTab.length;
      int oldThr = threshold;
      //新的capacity和threshold初始化为0
      int newCap, newThr = 0;
      if (oldCap > 0) {
      	//旧的capacity比int MAXIMUM_CAPACITY = 1 << 30还要大，那么更新threshold为Integer.MAX_VALUE，并且直接返回旧的table（即不进行扩容）
          if (oldCap >= MAXIMUM_CAPACITY) {
              threshold = Integer.MAX_VALUE;
              return oldTab;
          }
          //新的capacity为旧的capacity的两倍（即新的capacity为16*2=32）
          //如果32 < MAXIMUM_CAPACITY 并且 oldCap >= DEFAULT_INITIAL_CAPACITY
          else if ((newCap = oldCap << 1) < MAXIMUM_CAPACITY &&
                   oldCap >= DEFAULT_INITIAL_CAPACITY)
           	//则把threshold也更新为旧的2倍（即新的threshold为12*2=24）
              newThr = oldThr << 1; // double threshold
      }
      //新的capacity就为threshold
      else if (oldThr > 0) // initial capacity was placed in threshold
          newCap = oldThr;
      //第一次初始化。
      else { // zero initial threshold signifies using defaults
          newCap = DEFAULT_INITIAL_CAPACITY;
          newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY);
      }
      if (newThr == 0) {
          float ft = (float)newCap * loadFactor;
          newThr = (newCap < MAXIMUM_CAPACITY && ft < (float)MAXIMUM_CAPACITY ?
                    (int)ft : Integer.MAX_VALUE);
      }
      threshold = newThr;
      @SuppressWarnings({"rawtypes","unchecked"})
      //创建新的table，大小为newCapacity
      Node<K,V>[] newTab = (Node<K,V>[])new Node[newCap];
      table = newTab;
      if (oldTab != null) {
      	//遍历旧table中的每一个链表
          for (int j = 0; j < oldCap; ++j) {
              Node<K,V> e;
              if ((e = oldTab[j]) != null) {
                  //置为null让gc及时回收，当然oldTab[j]已经保存到局部变量e中了
                  oldTab[j] = null;
                  //第一种情况：如果链表中只有一个节点
                  if (e.next == null)
                  	//那么重新计算位置（e.hash & (newCap  1)），并放入新的table
                      newTab[e.hash & (newCap  1)] = e;
                  //第二种情况：链表中有多个节点，同时第一个节点为TreeNode，那么转调树的操作
                  else if (e instanceof TreeNode)
                      ((TreeNode<K,V>)e).split(this, newTab, j, oldCap);
                  //第三种情况：链表中有多个节点，且是普通链表
                  else { // preserve order
                      //旧table的链表，rehash后在新table中的位置
                          //要么跟旧table中的位置一样-----------（1）
                          //要么是旧table中的位置+oldCap-------（2）
                      //其实就是把原来的链表分成两部分，所以
                          //loXXX代表（1）
                          //hiXXX代表（2）
                      Node<K,V> loHead = null, loTail = null;
  
                      Node<K,V> hiHead = null, hiTail = null;
                      Node<K,V> next;
                      do {
                          next = e.next;
                        	//高位是0，那么这个元素在新table中的位置跟在旧table一样
                          if ((e.hash & oldCap) == 0) {
                              if (loTail == null)
                                  loHead = e;
                              else
                                  loTail.next = e;
                              loTail = e;
                          }
                          //高位是1，那么这个元素在新table中的位置是旧table的位置+oldCap
                          else {
                              if (hiTail == null)
                                  hiHead = e;
                              else
                                  hiTail.next = e;
                              hiTail = e;
                          }
                      } while ((e = next) != null);
                      //上面的循环把链表瓜分完了，下面开始赋值到新table了
                      if (loTail != null) {
                          loTail.next = null;
                          //（1）
                          newTab[j] = loHead;
                      }
                      if (hiTail != null) {
                          hiTail.next = null;
                          //（2）
                          newTab[j + oldCap] = hiHead;
                      }
                  }
              }
          }
      }
      return newTab;
  }
  ```

  ##### 3.3 使用hash数值&（数组长度-1）计算该数据存放的位置i

  ```java
  i = (n  1) & hash
  ```

  ##### 3.4 第二次进来，如果位置i位置为空，那么用（key,value）存入该位置

  ```java
  //使用hash至以及数组长度计算下标，如果table[下标]为空，即没有元素，直接赋值即可
  if ((p = tab[i = (n  1) & hash]) == null)
      tab[i] = newNode(hash, key, value, null);
  
  ```

  ##### 3.5 第三次进来如果位置i不为空，那么遍历链表或红黑树找到key相等的节点替换value

  ```java
  //否则说明table[下标]有元素
  else {
      Node<K,V> e; K k;
      //头节点不仅hash值相同，key也equals（即头节点就是要找的节点），那么保存这个节点以便后续使用
      if (p.hash == hash &&
          ((k = p.key) == key || (key != null && key.equals(k))))
          e = p;
      //头节点不是要找的节点，同时是个TreeNode，那么转调tree的操作
      else if (p instanceof TreeNode)
          e = ((TreeNode<K,V>)p).putTreeVal(this, tab, hash, key, value);
      //头节点不是要找的节点，同时是普通的链表
      else {
      	//遍历链表找，同时记录遍历了几个元素存到bitCount里。
          for (int binCount = 0; ; ++binCount) {
          	//到达链表的尾部
              if ((e = p.next) == null) {
                  p.next = newNode(hash, key, value, null);
                  //判断bitCount是否达到树化的限度，是则树化
                  //这里binCount为TREEIFY_THRESHOLD - 1，也就是7的时候
                  //也就是这个链表中的节点（不包括头节点）个数为8的时候
                  if (binCount >= TREEIFY_THRESHOLD - 1) // 1 for 1st
                      treeifyBin(tab, hash);
                  break;
              }
              //找到了相等的节点
              if (e.hash == hash &&
                  ((k = e.key) == key || (key != null && key.equals(k))))
                  break;
              p = e;
          }
      }
      //如果有找到相等的节点，那么e保存的就是这个节点的引用，直接替换value即可
      if (e != null) { // existing mapping for key
          V oldValue = e.value;
          if (!onlyIfAbsent || oldValue == null)
              e.value = value;
          afterNodeAccess(e);
          return oldValue;
      }
  }
  ```

   3.5.1 怎么转换为红黑树的

  - treeifyBin

    ```java
    final void treeifyBin(Node<K,V>[] tab, int hash) {
        int n, index; Node<K,V> e;
        //这里table的长度<64的时候并不进行树化，而是进行扩容
        //也就是说链表转换成红黑树的条件是 链表中元素个数为8个 并且 table长度为64
        if (tab == null || (n = tab.length) < MIN_TREEIFY_CAPACITY)//MIN_TREEIFY_CAPACITY是64
            resize();
        //下面的操作是把链表中的节点（Node）转换成树中的节点（TreeNode）
        else if ((e = tab[index = (n - 1) & hash]) != null) {
            TreeNode<K,V> hd = null, tl = null;
            //这个循环遍历链表
            do {
                //传入链表中的当前节点以及下一个节点，转换成TreeNode
                TreeNode<K,V> p = replacementTreeNode(e, null);
                //tail为空，就是说现在是树中的第一个元素
                if (tl == null)
                    //那么同时得初始化head为当前节点
                    hd = p;
                //不是树中的第一个元素，那么插入到树的末尾
                else {
                    //这里的树节点怎么感觉像是个双向链表？？？
                    p.prev = tl;
                    tl.next = p;
                }
                tl = p;
            } while ((e = e.next) != null);
            if ((tab[index] = hd) != null)
                //上面仅是构造了TreeNode为节点的双向链表，这里才是真正的树化操作
                hd.treeify(tab);
        }
    }
    ```

    3.5.1.1 Node -> TreeNode

    - replacementTreeNode

      ```java
      TreeNode<K,V> replacementTreeNode(Node<K,V> p, Node<K,V> next) {
          //就是把当前节点的hash、key、value初始化成TreeNode的hash、key、value
          //把下一个节点初始化为TreeNode.next
          return new TreeNode<>(p.hash, p.key, p.value, next);
      }
      
      ```

    - TreeNode

      ```java
      static final class TreeNode<K,V> extends LinkedHashMap.Entry<K,V> {
          TreeNode<K,V> parent;  // red-black tree links
          TreeNode<K,V> left;
          TreeNode<K,V> right;
          TreeNode<K,V> prev;    // needed to unlink next upon deletion
          boolean red;
          //这个构造方法其实就是HashMap的Node的构造方法，没什么特殊的
          TreeNode(int hash, K key, V val, Node<K,V> next) {
          //LinkedHashMap.Entry
              super(hash, key, val, next);
          }
      ```

      

    - LinkedHashMap.Entry

      ```java
      static class Entry<K,V> extends HashMap.Node<K,V> {
          Entry<K,V> before, after;
          Entry(int hash, K key, V value, Node<K,V> next) {
          //HashMap.Node
              super(hash, key, value, next);
          }
      }
      ```

      

    - HashMap.Node

      ```java
      static class Node<K,V> implements Map.Entry<K,V> {
          final int hash;
          final K key;
          V value;
          Node<K,V> next;
      
          Node(int hash, K key, V value, Node<K,V> next) {
              this.hash = hash;
              this.key = key;
              this.value = value;
              this.next = next;
          }
      ```

      

    3.5..1.2 树化

    - treeify

      ```java
      final void treeify(Node<K,V>[] tab) {
          TreeNode<K,V> root = null;
          for (TreeNode<K,V> x = this, next; x != null; x = next) {
              next = (TreeNode<K,V>)x.next;
              x.left = x.right = null;
              if (root == null) {
                  x.parent = null;
                  x.red = false;
                  root = x;
              }
              else {
                  K k = x.key;
                  int h = x.hash;
                  Class<?> kc = null;
                  for (TreeNode<K,V> p = root;;) {
                      int dir, ph;
                      K pk = p.key;
                      if ((ph = p.hash) > h)
                          dir = -1;
                      else if (ph < h)
                          dir = 1;
                      else if ((kc == null &&
                                (kc = comparableClassFor(k)) == null) ||
                               (dir = compareComparables(kc, k, pk)) == 0)
                          dir = tieBreakOrder(k, pk);
      
                      TreeNode<K,V> xp = p;
                      if ((p = (dir <= 0) ? p.left : p.right) == null) {
                          x.parent = xp;
                          if (dir <= 0)
                              xp.left = x;
                          else
                              xp.right = x;
                          root = balanceInsertion(root, x);
                          break;
                      }
                  }
              }
          }
          moveRootToFront(tab, root);
      }
      ```

      

- getf方法

  总体伪算法如下：

  - 计算key的hash值
  - 使用hash值&（数组长度-1）计算该数据存放的位置i
    - 如果位置i不为空，比较key是否相等，是则返回
      - 如果是树，调红黑树的的查询
      - 若是链表，遍历链表查找key相等的node
    - 否则，直接返回null。

  ```java
  public V get(Object key) {
      Node<K,V> e;
      //通过key的hash值+key本身寻找node
      return (e = getNode(hash(key), key)) == null ? null : e.value;
  }
  //hash函数
  static final int hash(Object key) {
      int h;
      //hashCode 异或 hashCode 右移16bit
      return (key == null) ? 0 : (h = key.hashCode()) ^ (h >>> 16);
  }
  final Node<K,V> getNode(int hash, Object key) {
      Node<K,V>[] tab; Node<K,V> first, e; int n; K k;
      //通过hash&(table长度1)计算下标
      if ((tab = table) != null && (n = tab.length) > 0 &&
          (first = tab[(n  1) & hash]) != null) {
          //找到了：当前节点与table[下标]相等hash相等且key相等
          if (first.hash == hash && // always check first node
              ((k = first.key) == key || (key != null && key.equals(k))))
              return first;
          //继续寻找
          if ((e = first.next) != null) {
          	//TreeNode，转调树
              if (first instanceof TreeNode)
                  return ((TreeNode<K,V>)first).getTreeNode(hash, key);
              do {
              	//遍历链表寻找相等的节点
                  if (e.hash == hash &&
                      ((k = e.key) == key || (key != null && key.equals(k))))
                      return e;
              } while ((e = e.next) != null);
          }
      }
      return null;
  }
  ```

  

- ### containsKey方法

  ```java
  public boolean containsKey(Object key) {
      //也是调用的getNode方法判断是否为空
      return getNode(hash(key), key) != null;
  }
  ```

  

- ### remove方法

  总体伪算法如下：

  - 计算key的hash值

  - 使用hash值&（数组长度-1）计算该位置存放的位置i

  - 如果i位置不为空，对比key是否相等，相等则改变头节点指向下一个

  - 否则

    - 若是树节点，调红黑树的删除接口
    - 若是链表节点，遍历链表找到key相等的节点，把前一个节点的next指向该节点的next

  - remove

    ```java
    public V remove(Object key) {
        Node<K,V> e;
        return (e = removeNode(hash(key), key, null, false, true)) == null ?
            null : e.value;
    }
    //hash函数
    static final int hash(Object key) {
        int h;
        //hashCode 异或 hashCode 右移16bit
        return (key == null) ? 0 : (h = key.hashCode()) ^ (h >>> 16);
    }
    final Node<K,V> removeNode(int hash, Object key, Object value,
                               boolean matchValue, boolean movable) {
        Node<K,V>[] tab; Node<K,V> p; int n, index;
        if ((tab = table) != null && (n = tab.length) > 0 &&
        	//计算第一个节点的位置
            (p = tab[index = (n  1) & hash]) != null) {
            Node<K,V> node = null, e; K k; V v;
            //第一个节点就是要找的节点
            if (p.hash == hash &&
                ((k = p.key) == key || (key != null && key.equals(k))))
                node = p;
            //不是则继续寻找
            else if ((e = p.next) != null) {
            	//是个TreeNode，转调树
                if (p instanceof TreeNode)
                    node = ((TreeNode<K,V>)p).getTreeNode(hash, key);
                //遍历链表直到找到相等的节点
                else {
                    do {
                        if (e.hash == hash &&
                            ((k = e.key) == key ||
                             (key != null && key.equals(k)))) {
                            node = e;
                            break;
                        }
                        p = e;
                    } while ((e = e.next) != null);
                }
            }
            //有找到节点
            if (node != null && (!matchValue || (v = node.value) == value ||
                                 (value != null && value.equals(v)))) {
                //转调树
                if (node instanceof TreeNode)
                    ((TreeNode<K,V>)node).removeTreeNode(this, tab, movable);
                //链表的第一个元素
                else if (node == p)
                    tab[index] = node.next;
                //链表的非第一个元素
                else
                    p.next = node.next;
                ++modCount;
                size;
                afterNodeRemoval(node);
                return node;
            }
        }
        return null;
    }
    ```

- ### containsValue方法

  - 效率
    $$
    O(N^2)
    $$

    ```java
    public boolean containsValue(Object value) {
        Node<K,V>[] tab; V v;
        if ((tab = table) != null && size > 0) {
            //遍历数组的每个元素
            for (int i = 0; i < tab.length; ++i) {
                //链表的每个元素
                for (Node<K,V> e = tab[i]; e != null; e = e.next) {
                    if ((v = e.value) == value ||
                        (value != null && value.equals(v)))
                        return true;
                }
            }
        }
        return false;
    }
    ```

4. ##### 问题

   4.1 相对于JDK1.7的区别

   - 使用了红黑树

     JDK1.8的内部实现是数组+链表+红黑树；

     1.8之前是数组+链表实现。对于一个key，先计算其hash值再对数组大小取模决定放在哪个元素上，再通过连地址发解决hash冲突；

     如果很多key映射到了同一个元素上，那么效率退化成O(N)，因此，JDK1.8在链表超过阈值的时候会转成红黑树，效率为O（logN）

   - 解决了并发时resize时的死循环

     保留了顺序，使用的尾插法而不是头插法。

   4.2 如何解决并发时resize时的死循环

   ​	保留了顺序，使用的尾插法而不是头插法。

   4.3 什么时候扩容

   ​	size > 容量*负载因子

   4.4 怎么扩容的

   ​	参考putVla方法

   

   









### TODO的题目

------

#### 基础题目

1、Java线程的状态

2、进程和线程的区别，进程间如何通讯，线程间如何通讯

3、HashMap的数据结构是什么？如何实现的。和HashTable、ConcurrentHashMap的区别

4、Cookie和Session的区别

5、索引有什么用？如何创建索引？

6、ArrayList是如何实现的，ArrayList和LinkedList的区别？ArrayList如何实现扩容。

7、equals方法实现

8、面向对象

9、线程状态，BLOCKED和WAITING有什么区别

10、JVM如何加装字节码文件

11、JVM GC，GC算法

12、什么情况会出现Full GC，什么情况会出现yong GC。

13、JVM内存模型

14、Java运行时数据区

15、事务的实现原理



#### 技术深度

1、有没有看过JDK源码，看过的类实现原理是什么

2、HTTP协议

3、TCP协议

4、一致性Hash算法

5、JVM如何加载字节码文件

6、类加载器如何卸载字节码

7、IO和NIO的区别，NIO的有点

8、Java线程池的实现原理，keepliveTime等参数的作用

9、HTTP连接池实现原理

10、数据库连接池的实现原理

11、数据库的实现原理



#### 技术框架

1、看过哪些开源框架的源码

2、为什么要用Redis，Redis有哪些优缺点

3、Neety是如何使用线程池的，为什么这么使用

4、为什么要使用Spring，Spring的优缺点有哪些

5、Spirng的IOC容器初始化流程

6、Spring的IOC容器实现原理，为什么可以通过byName和byTipe找到Bean

7、Spring AOP实现原理

8、消息中间件是如何实现的，技术难点有哪些



#### 系统架构

1、如何搭建一个高可用系统

2、哪些设计模式可以增加系统的可扩展性

3、介绍设计模式，如模板模式，命令模式，策略模式，适配器模式，桥接模式、装饰模式，观察者模式，状态模式，访问者模式。

4、抽象能力，怎么提高研发效率。

5、什么是高内聚低耦合，请举例子如何实现

6、什么情况用接口，什么情况用消息

7、如果AB两个系统互相依赖，如何解除依赖

8、如何写一篇设计文档，目录是什么

9、什么场景应该拆分系统，什么场景应该合并系统

10、系统和模块的区别，分别在什么场景下使用



#### 分布式系统

1、分布式事务，两阶段提交

2、如何实现分布式锁

3、如何实现分布式Session

4、如何保证消息的一致性

5、负载均衡

6、正向代理（客户端代理）和反向代理（服务端代理）

7、CDN实现原理

8、怎么提升系统的QPS和吞吐量



#### 实战能力

1、有没有处理过线上问题？出现内存泄漏，CPU利用率标高，应用无响应时如何处理的

2、开发中有没有遇到什么技术问题？如何解决的？

3、若有几十亿的白名单，每天白天需要高并发查询，晚上需要更新一次，如何设计这个功能。

4、新浪微博是如何实现把微博推给订阅者

5、Google是如何在一秒内把搜索结果返回给用户的

6、12306网站的订票系统如何实现，如何保证票不会被超卖。

7、如何实现一个秒杀系统，保证只有几位用户能买到某件商品。



#### 软能力

1、如何学习一项新技术，比如学习Java的，重点学习什么

2、有关注哪些新的技术

3、工作任务非常多非常杂时如何处理

4、项目出现延迟如何处理

5、和同事的设计思路不一样怎么处理

6、如何保证开发质量

7、职业规划是什么？短期，长期目标是什么

8、团队的规划是什么

9、能介绍下从工作到现在自己的成长在那里